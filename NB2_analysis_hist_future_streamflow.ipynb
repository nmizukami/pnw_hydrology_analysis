{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB2: Analysis of streamlfow simulations (non-bias corrected) from SUMMA+mizuRoute forced by ICAR downscaled meteorological data\n",
    "\n",
    "1. Evaluation of Historical simulation compared to retrospective simulation and naturalized flow data\n",
    "2. Future changes in various flow metrics and time series plots \n",
    "\n",
    "!!!! WARNING !!!!\n",
    "\n",
    "There are cells that produce per-site plots (hundreds of sites) at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os,sys\n",
    "import glob\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import scale as mscale\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import cartopy.crs as ccrs\n",
    "from scipy import stats\n",
    "\n",
    "import scripts.metrics as metrics\n",
    "from scripts.utility import PPFScale\n",
    "from scripts.utility import AutoVivification\n",
    "from scripts.utility import base_map\n",
    "import scripts.colors as ccmap\n",
    "mscale.register_scale(PPFScale)\n",
    "\n",
    "print(\"\\nThe Python version: %s.%s.%s\" % sys.version_info[:3])\n",
    "print(xr.__name__, xr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dataset(ds, siteID):\n",
    "    # extract the reachID orders\n",
    "    x = ds['site'].values\n",
    "    # Find the indices of the reordered array\n",
    "    # From: https://stackoverflow.com/questions/8251541/numpy-for-every-element-in-one-array-find-the-index-in-another-array\n",
    "    index = np.argsort(x)\n",
    "    sorted_x = x[index]\n",
    "    sorted_index = np.searchsorted(sorted_x, siteID)\n",
    "\n",
    "    remap_order = np.take(index, sorted_index, mode=\"clip\")\n",
    "\n",
    "    # Reorder pio according to the orginal\n",
    "    ds_reorder = ds.isel(dict(site=remap_order))\n",
    "    return ds_reorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "main_path  = '/glade/campaign/ral/hap/mizukami/archive/pnw_hydrology/final_archive_v1' # !!! This is top directory of the dataset.\n",
    "geo_path   = os.path.join(main_path, 'ancillary_data','geospatial_data')\n",
    "nrni_path  = os.path.join(main_path, 'ancillary_data')\n",
    "figure_path = 'NB2_figures'\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(figure_path, 'per_site'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mete dictironaries\n",
    "gcm_runs = {\n",
    "            'CanESM5':             {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},\n",
    "            'CMCC-CM2-SR5':        {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},    \n",
    "            'NorESM2-MM':          {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},\n",
    "            'MIROC-ES2L':          {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},\n",
    "            'MPI-M.MPI-ESM1-2-LR': {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},\n",
    "            'CanESM2':             {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "            'CCSM4':               {'scen':['hist', 'rcp85'], 'cmip':5},\n",
    "            'CMCC-CM':             {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "            'CNRM-CM5':            {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "            'MIROC5':              {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "            'MRI-CGCM3':           {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "           }\n",
    "\n",
    "retro_runs = {\n",
    "            'GMET':{'period':'control'}\n",
    "            }\n",
    "\n",
    "scens = {\n",
    "         'hist':   {'time':slice('1950-01-01', '2004-12-31'), 'period':['control']},\n",
    "         'ssp245': {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "         'ssp370': {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "         'ssp585': {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "         'rcp45':  {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "         'rcp85':  {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "        }\n",
    "\n",
    "periods = {\n",
    "         'control':  {'name':'WY1980-2004', 'time':slice('1980-10-01', '2004-09-30'), 'lc':'xkcd:blue'},\n",
    "         '2040s':    {'name':'WY2030-2060', 'time':slice('2029-10-01', '2060-09-30'), 'lc':'xkcd:orange'},\n",
    "         '2080s':    {'name':'WY2070-2099', 'time':slice('2069-10-01', '2099-09-30'), 'lc':'xkcd:magenta'},\n",
    "          }\n",
    "\n",
    "ensembles = {\n",
    "             'cmip-hist':     {'cmip':[5,6], 'scen':['hist']},\n",
    "             'cmip6-hist':    {'cmip':[6],   'scen':['hist']},\n",
    "             'cmip5-hist':    {'cmip':[5],   'scen':['hist']},\n",
    "             'cmip6-ssp370':  {'cmip':[6],   'scen':['hist', 'ssp370']},\n",
    "             'cmip6-ssp245':  {'cmip':[6],   'scen':['hist', 'ssp245']},\n",
    "             'cmip6-ssp585':  {'cmip':[6],   'scen':['hist', 'ssp585']},\n",
    "             'cmip5-rcp85':   {'cmip':[5],   'scen':['hist', 'rcp85']},\n",
    "             'cmip6':         {'cmip':[6],   'scen':['hist', 'ssp245', 'ssp370', 'ssp585']},\n",
    "             'cmip5':         {'cmip':[5],   'scen':['hist', 'rcp45','rcp85']},\n",
    "             'low_high-emission': {'cmip':[5,6], 'scen':['ssp245','rcp45','ssp585','rcp85']},\n",
    "             'high-emission': {'cmip':[5,6], 'scen':['ssp585','rcp85']},\n",
    "            }\n",
    "\n",
    "sims   =  {**retro_runs, **gcm_runs}\n",
    "gcm_names   = list(gcm_runs.keys())\n",
    "retro_names = list(retro_runs.keys())\n",
    "sim_names   = list(sims.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 geopackage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_site  = gpd.read_file(os.path.join(geo_path, 'PNW_flow_site.gpkg'))\n",
    "df_reach = gpd.read_file(os.path.join(geo_path, 'rivEndoMERITpfaf_PNW.gpkg'))\n",
    "df_huc12 = gpd.read_file(os.path.join(geo_path, 'HUC12_MERIT_PNW.gpkg'))\n",
    "df_huc12['geometry'] = df_huc12.geometry.simplify(0.05) # simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Link between river network reach ID and site name\n",
    "reach id co-located with flow site has less probably because some reach has more than one sites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merit_id = pd.read_csv(os.path.join(geo_path, 'PNW_flow_site.csv'))\n",
    "df_merit_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Naturalized flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nrni = xr.open_dataset(os.path.join(nrni_path,'PNW_unimpaired_flow_1951-2018_latlon.nc')).sel(time=scens['hist']['time'])\n",
    "nrni_site = ds_nrni.site.values\n",
    "print('Number of nrni sites: %d'%len(nrni_site))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Read mizuRoute outputs\n",
    "\n",
    "Read mizuRoute output into xarray dataset and put it dictionary ds_route[gcm_case][scen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get GCM sim\n",
    "ds_route = AutoVivification()\n",
    "for gcm_name, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        analysis_period = scens[scen]['time']\n",
    "\n",
    "        if scen=='hist' and meta['cmip']==5: # for cmip5 historical period, use rcp85 data\n",
    "            case = f'{gcm_name}_rcp85'\n",
    "        elif scen=='hist' and meta['cmip']==6: # for cmip6 historical period, use ssp585 data\n",
    "            case = f'{gcm_name}_ssp585'\n",
    "        else: # for future period\n",
    "            case = f'{gcm_name}_{scen}'\n",
    "        \n",
    "        nclist=glob.glob(os.path.join(main_path, case, f'{case}_mizuRoute_daily_site.nc'))\n",
    "        ds_tmp = xr.open_mfdataset(nclist, data_vars='minimal').sel(time=analysis_period)\n",
    "        ds_route[gcm_name][scen] = ds_tmp.load()\n",
    "        ds_route[gcm_name][scen] = ds_route[gcm_name][scen].assign_coords(seg=ds_route[gcm_name][scen]['site'])\n",
    "        ds_route[gcm_name][scen] = ds_route[gcm_name][scen].drop_vars('site')\n",
    "        ds_route[gcm_name][scen] = ds_route[gcm_name][scen].rename({'seg':'site'})\n",
    "        ds_route[gcm_name][scen] = reorder_dataset(ds_route[gcm_name][scen], df_merit_id['location_name'].values)\n",
    "        print(f'{case}')\n",
    "\n",
    "flow_site = ds_route[gcm_name][scen].site.values\n",
    "route_reachID = ds_route[gcm_name][scen].reachID.values\n",
    "print('Number of routing sites: %d'%len(route_reachID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get retro sim and add it to ds_route dictionary\n",
    "for retro_name, meta in retro_runs.items():\n",
    "    scen='hist'\n",
    "    analysis_period = scens[scen]['time']\n",
    "    nclist=glob.glob(os.path.join(main_path, f'{retro_name}_hist','mizuRoute_daily_site.nc'))\n",
    "    ds_tmp = xr.open_mfdataset(nclist, data_vars='minimal').sel(time=analysis_period)\n",
    "    ds_route[retro_name][scen] = ds_tmp.load()\n",
    "    ds_route[retro_name][scen] = ds_route[retro_name][scen].assign_coords(seg=ds_route[retro_name][scen]['site'])\n",
    "    ds_route[retro_name][scen] = ds_route[retro_name][scen].drop_vars('site')\n",
    "    ds_route[retro_name][scen] = ds_route[retro_name][scen].rename({'seg':'site'})\n",
    "    ds_route[retro_name][scen] = reorder_dataset(ds_route[retro_name][scen], df_merit_id['location_name'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reformat xarray dataset to panda dataframe\n",
    "Find site where naturalized flow exist (summa site has all the sites in the meta data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common site between summa site (include all the sites) and nrni_site (site from naturalized flow data)\n",
    "common_site = np.asarray(list(set(flow_site).intersection(nrni_site)))\n",
    "num_site = len(common_site)\n",
    "common_site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select common sites only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flow site meta dataframe\n",
    "df_site_selected = df_site.loc[df_site['location_name'].isin(common_site)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select common sites from NRNI data\n",
    "ds_nrni_selected = ds_nrni.where(ds_nrni.site.isin(common_site), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCM simulations\n",
    "ds_qsim_selected = AutoVivification()\n",
    "for gcm_name, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        ds_qsim_selected[gcm_name][scen] = ds_route[gcm_name][scen].where(ds_route[gcm_name][scen].site.isin(common_site), drop=True)\n",
    "        # match order of site with order of NRNI data\n",
    "        ds_qsim_selected[gcm_name][scen] = reorder_dataset(ds_qsim_selected[gcm_name][scen], ds_nrni_selected.site.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retro simulations\n",
    "for sim_name, meta in retro_runs.items():\n",
    "    scen = 'hist'\n",
    "    ds_qsim_selected[retro_name][scen] = ds_route[retro_name][scen].where(ds_route[retro_name][scen].site.isin(common_site), drop=True)\n",
    "    # match order of site with order of NRNI data\n",
    "    ds_qsim_selected[retro_name][scen] = reorder_dataset(ds_qsim_selected[retro_name][scen], ds_nrni_selected.site.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 4. Compute flow metrics\n",
    "\n",
    "- mean annual cycle at daily step (ds_seasona_flow)\n",
    "- annual maximum flow and day of year per wyr\n",
    "- annual minimum flow and day of year per wyr\n",
    "- annual centroid - \n",
    "- high flow at 90%\n",
    "- low flow at 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# compute long term annual cycle at daily step\n",
    "ds_seasonal_flow = AutoVivification()\n",
    "for gcm in sim_names:\n",
    "    for scen in ds_qsim_selected[gcm].keys():\n",
    "        for period in scens[scen]['period']:\n",
    "            ds_seasonal_flow[gcm][scen][period] = ds_qsim_selected[gcm][scen]['streamflow'].sel(time=periods[period]['time']).groupby('time.dayofyear').mean()\n",
    "\n",
    "ds_seasonal_flow['obs'] = ds_nrni_selected['streamflow'].sel(time=periods['control']['time']).groupby('time.dayofyear').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_flow_metrics = AutoVivification()\n",
    "\n",
    "ds_flow_metrics['annual_max']['obs']      = metrics.annual_max(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']).rolling(time=7, center=True).mean())\n",
    "ds_flow_metrics['annual_min']['obs']      = metrics.annual_min(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']).rolling(time=7, center=True).mean())\n",
    "ds_flow_metrics['ctr']['obs']             = metrics.annual_centroid(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']))\n",
    "ds_flow_metrics['BFI']['obs']             = metrics.BFI(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']))\n",
    "ds_flow_metrics['FMS']['obs']             = metrics.FMS(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']))\n",
    "ds_flow_metrics['FHV']['obs']             = metrics.FHV(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']),percent=0.98)\n",
    "ds_flow_metrics['FLV']['obs']             = metrics.FLV(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']))\n",
    "ds_flow_metrics['high_q_freq_dur']['obs'] = metrics.high_q_freq_dur(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']))\n",
    "ds_flow_metrics['low_q_freq_dur']['obs']  = metrics.low_q_freq_dur(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']))\n",
    "ds_flow_metrics['season_mean']['obs']     = metrics.season_mean(ds_nrni_selected['streamflow'].sel(time=periods['control']['time']))\n",
    "ds_flow_metrics['annual_mean']['obs']     = ds_nrni_selected['streamflow'].sel(time=periods['control']['time']).resample(time='YS').mean('time').to_dataset(name='annual_mean')\n",
    "ds_flow_metrics['annual_mean']['obs']     = ds_flow_metrics['annual_mean']['obs'].assign_coords(time=ds_flow_metrics['annual_mean']['obs']['time'].dt.year).rename({'time': 'year'})\n",
    "\n",
    "for gcm in sim_names:\n",
    "    for scen in ds_qsim_selected[gcm].keys():\n",
    "        for period in scens[scen]['period']:\n",
    "            ds1 = ds_qsim_selected[gcm][scen]['streamflow'].sel(time=periods[period]['time'])\n",
    "            \n",
    "            ds_flow_metrics['annual_max'][gcm][scen][period]      = metrics.annual_max(ds1.rolling(time=7, center=True).mean())\n",
    "            ds_flow_metrics['annual_min'][gcm][scen][period]      = metrics.annual_min(ds1.rolling(time=7, center=True).mean())\n",
    "            ds_flow_metrics['ctr'][gcm][scen][period]             = metrics.annual_centroid(ds1)\n",
    "            ds_flow_metrics['BFI'][gcm][scen][period]             = metrics.BFI(ds1)\n",
    "            ds_flow_metrics['FMS'][gcm][scen][period]             = metrics.FMS(ds1)\n",
    "            ds_flow_metrics['FHV'][gcm][scen][period]             = metrics.FHV(ds1,percent=0.98)\n",
    "            ds_flow_metrics['FLV'][gcm][scen][period]             = metrics.FLV(ds1)\n",
    "            ds_flow_metrics['high_q_freq_dur'][gcm][scen][period] = metrics.high_q_freq_dur(ds1)\n",
    "            ds_flow_metrics['low_q_freq_dur'][gcm][scen][period]  = metrics.low_q_freq_dur(ds1)\n",
    "            ds_flow_metrics['season_mean'][gcm][scen][period]     = metrics.season_mean(ds1)\n",
    "            ds_flow_metrics['annual_mean'][gcm][scen][period]     = ds1.resample(time='YS').mean('time').to_dataset(name='annual_mean')\n",
    "            ds_flow_metrics['annual_mean'][gcm][scen][period]     = ds_flow_metrics['annual_mean'][gcm][scen][period].assign_coords(time=ds_flow_metrics['annual_mean'][gcm][scen][period]['time'].dt.year).rename({'time': 'year'})\n",
    "        print(f'{gcm}-{scen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# annual flood frequency for two longer periods\n",
    "for gcm in sim_names:\n",
    "    for scen in ds_qsim_selected[gcm].keys():\n",
    "        if scen=='hist':\n",
    "            ds1 = ds_qsim_selected[gcm][scen]['streamflow'].sel(time=slice('1954-10-01', '2004-09-30'))\n",
    "        else:\n",
    "            ds1 = ds_qsim_selected[gcm][scen]['streamflow'].sel(time=slice('2049-10-01', '2099-09-30'))\n",
    "        ds_flow_metrics['aff'][gcm][scen] = metrics.lp3_flood(ds1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Error in metrics during control period\n",
    "\n",
    "- bais at each site\n",
    "- seasonal bias at each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "error_metric = {\n",
    "                'annual_centroid': np.zeros((num_site, len(sim_names))),\n",
    "                'annual_min_day' : np.zeros((num_site, len(sim_names))),\n",
    "                'annual_max_day' : np.zeros((num_site, len(sim_names))),\n",
    "                'annual_min_flow': np.zeros((num_site, len(sim_names))),\n",
    "                'annual_max_flow': np.zeros((num_site, len(sim_names))),\n",
    "                'pbiasFHV'       : np.zeros((num_site, len(sim_names))),\n",
    "                'pbiasFLV'       : np.zeros((num_site, len(sim_names))),\n",
    "                'mean_high_q_dur': np.zeros((num_site, len(sim_names))),\n",
    "                'freq_high_q'    : np.zeros((num_site, len(sim_names))),\n",
    "                'alpha'          : np.zeros((num_site, len(sim_names))),\n",
    "                'beta'           : np.zeros((num_site, len(sim_names))),\n",
    "                'corr_seas'      : np.zeros((num_site, len(sim_names))),\n",
    "                'corr'           : np.zeros((num_site, len(sim_names))),\n",
    "                'kge'            : np.zeros((num_site, len(sim_names))),\n",
    "                'pbias_djf'      : np.zeros((num_site, len(sim_names))),\n",
    "                'pbias_mam'      : np.zeros((num_site, len(sim_names))),\n",
    "                'pbias_jja'      : np.zeros((num_site, len(sim_names))),\n",
    "                'pbias_son'      : np.zeros((num_site, len(sim_names))), \n",
    "               }\n",
    "\n",
    "for r, site in enumerate(common_site):\n",
    "    # nrni\n",
    "    sr_obs = ds_nrni_selected.sel(time=periods['control']['time'], site=site)['streamflow'].values\n",
    "    sr_obs = np.where(sr_obs<0.0, 1.0e-7,sr_obs)\n",
    "\n",
    "    sr_seas_obs = ds_seasonal_flow['obs'].sel(site=site).values\n",
    "    \n",
    "    sr_obs_centroid = ds_flow_metrics['ctr']['obs'].sel(site=site)['ann_centroid_day'].values\n",
    "    sr_obs_max_day  = ds_flow_metrics['annual_max']['obs'].sel(site=site)['ann_max_day'].values\n",
    "    sr_obs_max_flow = ds_flow_metrics['annual_max']['obs'].sel(site=site)['ann_max_flow'].values\n",
    "    sr_obs_min_day  = ds_flow_metrics['annual_min']['obs'].sel(site=site)['ann_min_day'].values\n",
    "    sr_obs_min_flow = ds_flow_metrics['annual_min']['obs'].sel(site=site)['ann_min_flow'].values\n",
    "    sr_obs_mean_high_q_dur = ds_flow_metrics['high_q_freq_dur']['obs'].sel(site=site)['mean_high_q_dur'].values\n",
    "    sr_obs_freq_high_q     = ds_flow_metrics['high_q_freq_dur']['obs'].sel(site=site)['freq_high_q'].values\n",
    "    sr_obs_FHV      = ds_flow_metrics['FHV']['obs'].sel(site=site)['FHV'].values\n",
    "    sr_obs_FLV      = ds_flow_metrics['FLV']['obs'].sel(site=site)['FLV'].values\n",
    "    sr_obs_djf      = ds_flow_metrics['season_mean']['obs'].sel(site=site, season='DJF').values\n",
    "    sr_obs_mam      = ds_flow_metrics['season_mean']['obs'].sel(site=site, season='MAM').values\n",
    "    sr_obs_jja      = ds_flow_metrics['season_mean']['obs'].sel(site=site, season='JJA').values\n",
    "    sr_obs_son      = ds_flow_metrics['season_mean']['obs'].sel(site=site, season='SON').values\n",
    "    \n",
    "    for c, sim_name in enumerate(sim_names): # sim_names is merge of retro and gcms\n",
    "       \n",
    "        # simulated flow series\n",
    "        sr_sim = ds_qsim_selected[sim_name]['hist'].sel(time=periods['control']['time'], site=site)['streamflow'].values\n",
    "        sr_sim = np.where(sr_sim<0.0, 1.0e-7,sr_sim)\n",
    "        \n",
    "        sr_seas_sim = ds_seasonal_flow[sim_name]['hist']['control'].sel(site=site).values\n",
    "        \n",
    "        sr_centroid = ds_flow_metrics['ctr'][sim_name]['hist']['control'].sel(site=site)['ann_centroid_day'].values\n",
    "        sr_max_day  = ds_flow_metrics['annual_max'][sim_name]['hist']['control'].sel(site=site)['ann_max_day'].values\n",
    "        sr_max_flow = ds_flow_metrics['annual_max'][sim_name]['hist']['control'].sel(site=site)['ann_max_flow'].values\n",
    "        sr_min_day  = ds_flow_metrics['annual_min'][sim_name]['hist']['control'].sel(site=site)['ann_min_day'].values\n",
    "        sr_min_flow = ds_flow_metrics['annual_min'][sim_name]['hist']['control'].sel(site=site)['ann_min_flow'].values\n",
    "        sr_mean_high_q_dur = ds_flow_metrics['high_q_freq_dur'][sim_name]['hist']['control'].sel(site=site)['mean_high_q_dur'].values\n",
    "        sr_freq_high_q     = ds_flow_metrics['high_q_freq_dur'][sim_name]['hist']['control'].sel(site=site)['freq_high_q'].values\n",
    "        sr_FHV      = ds_flow_metrics['FHV'][sim_name]['hist']['control'].sel(site=site)['FHV'].values\n",
    "        sr_FLV      = ds_flow_metrics['FLV'][sim_name]['hist']['control'].sel(site=site)['FLV'].values\n",
    "        sr_djf      = ds_flow_metrics['season_mean'][sim_name]['hist']['control'].sel(site=site, season='DJF').values\n",
    "        sr_mam      = ds_flow_metrics['season_mean'][sim_name]['hist']['control'].sel(site=site, season='MAM').values\n",
    "        sr_jja      = ds_flow_metrics['season_mean'][sim_name]['hist']['control'].sel(site=site, season='JJA').values\n",
    "        sr_son      = ds_flow_metrics['season_mean'][sim_name]['hist']['control'].sel(site=site, season='SON').values\n",
    "        \n",
    "        # compute error in flow metrics\n",
    "        error_metric['annual_centroid'][r,c] = metrics.bias(sr_obs_centroid, sr_centroid)\n",
    "        error_metric['annual_max_day'][r,c]  = metrics.bias(sr_obs_max_day, sr_max_day)\n",
    "        error_metric['annual_max_flow'][r,c] = metrics.pbias(sr_obs_max_flow, sr_max_flow)*100\n",
    "        error_metric['annual_min_day'][r,c]  = metrics.bias(sr_obs_min_day, sr_min_day)\n",
    "        error_metric['annual_min_flow'][r,c] = metrics.pbias(sr_obs_min_flow, sr_min_flow)*100\n",
    "        error_metric['mean_high_q_dur'][r,c] = metrics.bias(sr_obs_mean_high_q_dur, sr_mean_high_q_dur)\n",
    "        error_metric['freq_high_q'][r,c]     = metrics.bias(sr_obs_freq_high_q, sr_freq_high_q)\n",
    "        error_metric['pbiasFHV'][r,c]        = metrics.pbias(sr_obs_FHV, sr_FHV)*100\n",
    "        error_metric['pbiasFLV'][r,c]        = metrics.pbias(sr_obs_FLV, sr_FLV)*100\n",
    "        \n",
    "        error_metric['alpha'][r,c] = metrics.alpha(sr_obs, sr_sim)\n",
    "        error_metric['beta'][r,c]  = metrics.beta(sr_obs, sr_sim)\n",
    "        error_metric['corr'][r,c]  = metrics.corr(sr_obs, sr_sim)\n",
    "        error_metric['kge'][r,c]   = metrics.kge(sr_obs, sr_sim)\n",
    "\n",
    "        error_metric['corr_seas'][r,c]  = metrics.corr(sr_seas_obs, sr_seas_sim)\n",
    "        \n",
    "        error_metric['pbias_djf'][r,c]  = metrics.pbias(sr_obs_djf, sr_djf)*100\n",
    "        error_metric['pbias_mam'][r,c]  = metrics.pbias(sr_obs_mam, sr_mam)*100\n",
    "        error_metric['pbias_jja'][r,c]  = metrics.pbias(sr_obs_jja, sr_jja)*100\n",
    "        error_metric['pbias_son'][r,c]  = metrics.pbias(sr_obs_son, sr_son)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. GCM analysis during control period\n",
    "\n",
    "- bais at each site\n",
    "- seasonal bias at each site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig1. Maps of seasonal bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%matplotlib agg\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 7 \n",
    "mpl.rcParams['ytick.labelsize'] = 7 \n",
    "mpl.rcParams['axes.labelsize'] = 8 \n",
    "mpl.rcParams['axes.titlesize'] = 8 \n",
    "\n",
    "ncols=2\n",
    "nrows=2\n",
    "\n",
    "for case in sim_names: # sim_names is merge of retro and gcms\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5.5, 5), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100,)\n",
    "    fig.subplots_adjust(left=0.025, bottom=0.025, right=0.965, top=0.90, wspace=0.10, hspace=0.125)\n",
    "\n",
    "    for ix, season in enumerate(['djf','mam','jja','son']):\n",
    "        row = ix // ncols\n",
    "        col = ix % ncols\n",
    "    \n",
    "        df_stat = pd.DataFrame(data=error_metric[f'pbias_{season}'], index=common_site, columns=sim_names)\n",
    "        df_stat.reset_index(level=0, inplace=True)\n",
    "        df_stat.rename(columns={'index':'location_name'},inplace=True)\n",
    "        df_stat_final = df_site_selected.merge(df_stat, on=\"location_name\", how = 'inner')\n",
    "        \n",
    "        base_map(ax[row,col],df_huc12)\n",
    "        ax1 = df_stat_final.plot(ax=ax[row,col], column=case, markersize=15, cmap=ccmap.cmap_bias2, norm=ccmap.norm_bias2, legend=True, zorder=2, \n",
    "                           legend_kwds={'extend':'both', 'pad':0.02, 'shrink': 0.90});\n",
    "        ax[row,col].set_title(f'{season}', fontsize=8)\n",
    "        \n",
    "    fig.suptitle(f'{case} seasonal %bias [%]', fontsize=9, y=0.975)\n",
    "    fig.savefig(os.path.join(figure_path, f'./Fig1_seasonal_pbias_map_{case}.png'), dpi=200)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig2. Maps of error - high flow frequency [count] and duration [days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%matplotlib agg\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 7 \n",
    "mpl.rcParams['ytick.labelsize'] = 7 \n",
    "mpl.rcParams['axes.labelsize'] = 8 \n",
    "mpl.rcParams['axes.titlesize'] = 8\n",
    "\n",
    "metric_list = {\n",
    "    'freq_high_q':{'unit':'-','norm':ccmap.norm_freq_high_q, 'cmap_diff':ccmap.cmap_freq_high_q_diff, 'norm_diff':ccmap.norm_freq_high_q_diff}, \n",
    "    'mean_high_q_dur':{'unit':'day','norm':ccmap.norm_freq_high_dur,'cmap_diff':ccmap.cmap_freq_high_dur_diff, 'norm_diff':ccmap.norm_freq_high_dur_diff},\n",
    "}\n",
    "\n",
    "for case in sim_names: # sim_names is merge of retro and gcms\n",
    "    fig, axs = plt.subplots(ncols=len(metric_list), nrows=2, figsize=(6.0, 5.0), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=150,)\n",
    "    fig.subplots_adjust(left=0.025, bottom=0.025, right=0.965, top=0.90, wspace=0.10, hspace=0.125)\n",
    "    \n",
    "    for ix, (metric_name, meta) in enumerate(metric_list.items()):\n",
    "        #obs map - top rows\n",
    "        df_obs = ds_flow_metrics['high_q_freq_dur']['obs'][metric_name].mean(dim='year').to_dataframe()\n",
    "        df_obs.index.rename('location_name',inplace=True)\n",
    "        df_obs_final = df_site_selected.merge(df_obs, on=\"location_name\", how = 'inner')\n",
    "\n",
    "        base_map(axs[0,ix],df_huc12)\n",
    "        df_obs_final.plot(ax=axs[0,ix], column=metric_name, markersize=15, cmap='turbo', norm=meta['norm'], zorder=2, \n",
    "                          legend=True, legend_kwds={'extend':'max', 'pad':0.02, 'shrink': 0.85});\n",
    "        axs[0,ix].text(0.5, 1.125, '%s [%s]'%(metric_name, meta['unit']), transform=axs[0,ix].transAxes, ha='center', fontsize=9)\n",
    "        axs[0,ix].text(0.5, 1.025, 'Reference flow', transform=axs[0,ix].transAxes, ha='center', fontsize=8)\n",
    "\n",
    "        base_map(axs[1,ix],df_huc12)\n",
    "        df_err = pd.DataFrame(data=error_metric[metric_name], index=common_site, columns=sim_names)\n",
    "        df_err.reset_index(level=0, inplace=True)\n",
    "        df_err.rename(columns={'index':'location_name'},inplace=True)\n",
    "        df_err_final = df_site_selected.merge(df_err, on=\"location_name\", how = 'inner')\n",
    "        df_err_final.plot(ax=axs[1,ix], column=case, markersize=10, cmap=meta['cmap_diff'], norm=meta['norm_diff'], zorder=2,\n",
    "                          legend=True, legend_kwds={'extend':'both', 'pad':0.02, 'shrink': 0.875});\n",
    "        axs[1,ix].text(0.5, 1.025, 'error %s [%s]'%(case,meta['unit']), transform=axs[1,ix].transAxes, ha='center', fontsize=8)\n",
    "    fig.savefig(os.path.join(figure_path, f'Fig2_high_q_event_map_{case}.png'), dpi=200)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 3. Maps of timing error - centroid, annual_max_day, annual_min_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%matplotlib agg\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 7 \n",
    "mpl.rcParams['ytick.labelsize'] = 7 \n",
    "mpl.rcParams['axes.labelsize'] = 8 \n",
    "mpl.rcParams['axes.titlesize'] = 8\n",
    "\n",
    "metric_list = {\n",
    "    'annual_centroid': {'vname':'ann_centroid_day','unit':'day','cmap_diff':ccmap.cmap_centroid_diff, 'norm_diff':ccmap.norm_centroid_diff}, \n",
    "    'annual_max_day':  {'vname':'ann_max_day','unit':'day','cmap_diff':ccmap.cmap_max_day_diff, 'norm_diff':ccmap.norm_max_day_diff}, \n",
    "    'annual_min_day':  {'vname':'ann_min_day','unit':'day','cmap_diff':ccmap.cmap_min_day_diff, 'norm_diff':ccmap.norm_min_day_diff},\n",
    "}\n",
    "\n",
    "for case in sim_names: # sim_names is merge of retro and gcms\n",
    "    fig, axs = plt.subplots(ncols=len(metric_list), nrows=2, figsize=(6.5, 4.5), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=150,)\n",
    "    fig.subplots_adjust(left=0.025, bottom=0.025, right=0.965, top=0.90, wspace=0.10, hspace=0.125)\n",
    "    \n",
    "    for ix, (metric_name, meta) in enumerate(metric_list.items()):\n",
    "        if metric_name == 'annual_max_day':\n",
    "            ds_plot = ds_flow_metrics['annual_max'].copy()\n",
    "        elif metric_name == 'annual_min_day':\n",
    "            ds_plot = ds_flow_metrics['annual_min'].copy()\n",
    "        elif metric_name == 'annual_centroid':\n",
    "            ds_plot = ds_flow_metrics['ctr'].copy()\n",
    "\n",
    "        #obs map - top rows\n",
    "        df_obs = ds_plot['obs'][meta['vname']].mean(dim='year').to_dataframe()\n",
    "        df_obs.index.rename('location_name',inplace=True)\n",
    "        df_obs_final = df_site_selected.merge(df_obs, on=\"location_name\", how = 'inner')\n",
    "\n",
    "        base_map(axs[0,ix],df_huc12)\n",
    "        df_obs_final.plot(ax=axs[0,ix], column=meta['vname'], markersize=10, cmap='turbo', zorder=2, \n",
    "                          legend=True, legend_kwds={'extend':'neither', 'pad':0.02, 'shrink': 0.825});\n",
    "        axs[0,ix].text(0.5, 1.125, '%s [%s]'%(metric_name, meta['unit']), transform=axs[0,ix].transAxes, ha='center', fontsize=9)\n",
    "        axs[0,ix].text(0.5, 1.025, 'Reference flow', transform=axs[0,ix].transAxes, ha='center', fontsize=8)\n",
    "\n",
    "        base_map(axs[1,ix],df_huc12)\n",
    "        df_err = pd.DataFrame(data=error_metric[metric_name], index=common_site, columns=sim_names)\n",
    "        df_err.reset_index(level=0, inplace=True)\n",
    "        df_err.rename(columns={'index':'location_name'},inplace=True)\n",
    "        df_err_final = df_site_selected.merge(df_err, on=\"location_name\", how = 'inner')\n",
    "        df_err_final.plot(ax=axs[1,ix], column=case, markersize=10, cmap=meta['cmap_diff'], norm=meta['norm_diff'], zorder=2,\n",
    "                          legend=True, legend_kwds={'extend':'both', 'pad':0.02, 'shrink': 0.85});\n",
    "        axs[1,ix].text(0.5, 1.025, 'error %s [%s]'%(case,meta['unit']), transform=axs[1,ix].transAxes, ha='center', fontsize=8)\n",
    "    fig.savefig(os.path.join(figure_path, f'Fig3_timing_map_{case}.png'), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figs 4-6: Boxplots of errors - KGE and its component, and FLV and FHV during control period for all GCMs and gmet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for paper\n",
    "%matplotlib inline\n",
    "removed_sim=['']\n",
    "sim_included = [s for s in sim_names if s not in removed_sim]\n",
    "\n",
    "patch_colors=[]\n",
    "for sim in sims:\n",
    "    if sim in gcm_runs:\n",
    "        if gcm_runs[sim]['cmip']==5:\n",
    "            c='b'\n",
    "        elif gcm_runs[sim]['cmip']==6:\n",
    "            c='b'\n",
    "    if sim in retro_runs:\n",
    "        c='k'\n",
    "    patch_colors.append(c)\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 7 \n",
    "mpl.rcParams['ytick.labelsize'] = 7 \n",
    "mpl.rcParams['axes.labelsize'] = 8 \n",
    "mpl.rcParams['axes.titlesize'] = 8\n",
    "\n",
    "error_metric_list = {\n",
    "    'alpha':{'range':[0.5,1,1.5],'header':r'a) flow variability ratio ($\\alpha$) [-]'},\n",
    "    'beta':{'range':[0.5,1,1.5],'header':r'b) mean flow ratio ($\\beta$) [-]'},\n",
    "    'pbiasFHV':{'range':[-50,0,50],'header':'c) %bias Flow >98% in FDC [%]'}, \n",
    "    'pbiasFLV':{'range':[-100,0,100],'header':'d) %bias Flow <10% in FDC [%]'},\n",
    "    'corr_seas':{'range':[0.5,0.5,1],'header':'e) seasonal correlation (r) [-]'},\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(error_metric_list), ncols=1, figsize=(6.75, 7.5), dpi=100)\n",
    "fig.subplots_adjust(left=0.075, bottom=0.175, right=0.965, top=0.95, wspace=0.10, hspace=0.3)\n",
    "\n",
    "df_describe = {}\n",
    "for ix, (error_name, meta) in enumerate(error_metric_list.items()):\n",
    "    mask = (~np.isnan(error_metric[error_name]) & ~np.isinf(error_metric[error_name]))\n",
    "    filtered_data = [d[m] for s, d, m in zip(sim_included, error_metric[error_name].T, mask.T) if s not in removed_sim]\n",
    "    #axs[ix].violinplot(filtered_data, showextrema=True, showmedians=True)\n",
    "    bplot = axs[ix].boxplot(filtered_data, showfliers=False, patch_artist=True)\n",
    "    axs[ix].axhline(y=meta['range'][1], color='k', linestyle='--', lw=0.5)\n",
    "\n",
    "    # fill with colors\n",
    "    for patch, color in zip(bplot['boxes'], patch_colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axs[ix].set_title(meta['header'])\n",
    "    axs[ix].set_ylim([meta['range'][0], meta['range'][2]])\n",
    "    axs[ix].set_xlabel('')\n",
    "    if ix==len(error_metric_list)-1:\n",
    "        axs[ix].set_xticklabels(sim_included, rotation=90);\n",
    "    else:\n",
    "        axs[ix].set_xticklabels('');\n",
    "    df_describe[error_name] = pd.DataFrame({name:data for name, data in zip(sim_included, filtered_data)}).describe()\n",
    "fig.savefig(os.path.join(figure_path, f'Fig4_gcm_error_summary_ppt_paper.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary statistics for each metrics\n",
    "error_name = 'beta' # alpha, beta, pbiasFHV, pbiasFLV\n",
    "df_describe[error_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors in high and low flow event metrics\n",
    "\n",
    "removed_sim=['']\n",
    "sim_included = [s for s in sim_names if s not in removed_sim]\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 6.5 \n",
    "mpl.rcParams['ytick.labelsize'] = 7 \n",
    "mpl.rcParams['axes.labelsize'] = 8 \n",
    "mpl.rcParams['axes.titlesize'] = 9 \n",
    "\n",
    "error_metric_list = {\n",
    "    'annual_centroid': {'range':[-50,0,50],'header':r'annual centroid [day]'},\n",
    "    'annual_max_day':{'range':[-50,0,50],'header':r'annual max flow day [day]'},\n",
    "    'annual_min_day':{'range':[-200,0,160],'header':r'annual min flow day [day]'},\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(error_metric_list), ncols=1, figsize=(5.0, 6.0), dpi=100)\n",
    "fig.subplots_adjust(left=0.075, bottom=0.225, right=0.975, top=0.95, wspace=0.10, hspace=0.25)\n",
    "  \n",
    "for ix, (error_name, meta) in enumerate(error_metric_list.items()):\n",
    "    mask = (~np.isnan(error_metric[error_name]) & ~np.isinf(error_metric[error_name]))\n",
    "    filtered_data = [d[m] for s, d, m in zip(sim_included, error_metric[error_name].T, mask.T) if s not in removed_sim]\n",
    "    #axs[ix].violinplot(filtered_data, showextrema=True, showmedians=True)\n",
    "    bplot = axs[ix].boxplot(filtered_data, showfliers=False, patch_artist=True)\n",
    "    axs[ix].axhline(y=meta['range'][1], color='k', linestyle='--', lw=0.5)\n",
    "\n",
    "    # fill with colors\n",
    "    for patch, color in zip(bplot['boxes'], patch_colors):\n",
    "        patch.set_facecolor(color)    \n",
    "        \n",
    "    axs[ix].set_title(meta['header'])\n",
    "    axs[ix].set_ylim([meta['range'][0], meta['range'][2]])\n",
    "    axs[ix].set_xlabel('')\n",
    "    if ix==len(error_metric_list)-1:\n",
    "        axs[ix].set_xticklabels(sim_included, rotation=90);\n",
    "    else:\n",
    "        axs[ix].set_xticklabels('');\n",
    "fig.savefig(os.path.join(figure_path, f'Fig5_gcm_timing_error_summary.png'), dpi=300)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors in event metrics\n",
    "\n",
    "removed_sim=['']\n",
    "sim_included = [s for s in sim_names if s not in removed_sim]\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 6.5 \n",
    "mpl.rcParams['ytick.labelsize'] = 7 \n",
    "mpl.rcParams['axes.labelsize'] = 8 \n",
    "mpl.rcParams['axes.titlesize'] = 9 \n",
    "\n",
    "metric_list = {'freq_high_q':    {'range':[-5,0,5],'header':r'annual high flow frequency'}, \n",
    "               'mean_high_q_dur':{'range':[-30,0,30],'header':r'mean high flow duration'}\n",
    "              }\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(metric_list), ncols=1, figsize=(6.5, 4.0), dpi=100)\n",
    "fig.subplots_adjust(left=0.075, bottom=0.225, right=0.975, top=0.95, wspace=0.10, hspace=0.25)\n",
    "\n",
    "for ix, (error_name, meta) in enumerate(metric_list.items()):\n",
    "    mask = (~np.isnan(error_metric[error_name]) & ~np.isinf(error_metric[error_name]))\n",
    "    filtered_data = [d[m] for s, d, m in zip(sim_included, error_metric[error_name].T, mask.T) if s not in removed_sim]\n",
    "  \n",
    "    bplot = axs[ix].boxplot(filtered_data, showfliers=False, patch_artist=True)\n",
    "    axs[ix].axhline(y=meta['range'][1], color='k', linestyle='--', lw=0.5)\n",
    "    \n",
    "    # fill with colors\n",
    "    for patch, color in zip(bplot['boxes'], patch_colors):\n",
    "        patch.set_facecolor(color)    \n",
    "    #axs[ix].boxplot(filtered_data, showfliers=False)\n",
    "    #axs[ix].axhline(y=0.0, color='k', linestyle='--', lw=0.5)\n",
    "    \n",
    "    axs[ix].set_title(meta['header'])\n",
    "    axs[ix].set_ylim([meta['range'][0], meta['range'][2]])\n",
    "    axs[ix].set_xlabel('')\n",
    "    if ix==len(metric_list)-1:\n",
    "        axs[ix].set_xticklabels(sim_included, rotation=90);\n",
    "    else:\n",
    "        axs[ix].set_xticklabels('');\n",
    "\n",
    "fig.savefig(os.path.join(figure_path, f'Fig6_gcm_event_error_summary.png'), dpi=300)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 7.Changes in flow metrics for future periods compared to control period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fig 7. Each GCM and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_flow_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import Normalize\n",
    "cmap_mean_flow_diff = LinearSegmentedColormap.from_list('custom1', \n",
    "                                             [(0.0,      'xkcd:red'),\n",
    "                                              (100/1600, 'xkcd:white'),\n",
    "                                              (1.0,      'xkcd:blue')], N=255)\n",
    "cmap_mean_flow_diff.set_over('xkcd:dark blue')\n",
    "cmap_mean_flow_diff.set_under('xkcd:dark red')\n",
    "norm_mean_flow_diff=mpl.colors.Normalize(vmin=-100, vmax=1500)\n",
    "\n",
    "# percent diff\n",
    "cmap_mean_flow_pdiff = LinearSegmentedColormap.from_list('custom1', \n",
    "                                             [(0.0,      'xkcd:red'),\n",
    "                                              (40/100, 'xkcd:white'),\n",
    "                                              (1.0,      'xkcd:blue')], N=255)\n",
    "cmap_mean_flow_pdiff.set_over('xkcd:dark blue')\n",
    "cmap_mean_flow_pdiff.set_under('xkcd:dark red')\n",
    "norm_mean_flow_pdiff=mpl.colors.Normalize(vmin=-40, vmax=60)\n",
    "\n",
    "# annual mean flow\n",
    "norm_mean_flow = mpl.colors.LogNorm(vmin=1, vmax=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For individual GCM, change due to ssp/rcp and periods\n",
    "\n",
    "%matplotlib inline\n",
    "# CMIP6: 'CanESM5' 'CMCC-CM2-SR5' 'MIROC-ES2L' 'NorESM2-MM'\n",
    "# CMIP5: 'CanESM2' 'CMCC-CM' 'CNRM-CM5' 'MIROC5' 'MRI-CGCM3' 'CCSM4' 'GFDL-CM3'\n",
    "# retro: 'gmet'\n",
    "\n",
    "flow_metric  = 'FHV'   #annual_mean ann_centroid_day, ann_max_day, ann_max_flow, ann_min_day, ann_min_flow\n",
    "gcm          = 'NorESM2-MM' \n",
    "percent_change = False\n",
    "\n",
    "if flow_metric == 'annual_mean':\n",
    "    ds_plot = ds_flow_metrics['annual_mean'].copy()\n",
    "    unit='m3/s'\n",
    "    norm_flow=norm_mean_flow\n",
    "    if percent_change:\n",
    "        cmap_diff=cmap_mean_flow_pdiff\n",
    "        norm_diff=norm_mean_flow_pdiff\n",
    "    else:\n",
    "        cmap_diff=cmap_mean_flow_diff\n",
    "        norm_diff=norm_mean_flow_diff\n",
    "elif flow_metric == 'ann_max_day':\n",
    "    ds_plot = ds_flow_metrics['annual_max'].copy()\n",
    "    unit='day since 10/1'\n",
    "    cmap_diff=ccmap.cmap_max_day_diff\n",
    "    norm_diff=ccmap.norm_max_day_diff\n",
    "elif flow_metric == 'ann_min_day':\n",
    "    ds_plot = ds_flow_metrics['annual_min'].copy()\n",
    "    unit='day since 10/1'\n",
    "    cmap_diff=ccmap.cmap_min_day_diff\n",
    "    norm_diff=ccmap.norm_min_day_diff\n",
    "elif flow_metric == 'ann_centroid_day':\n",
    "    ds_plot = ds_flow_metrics['ctr'].copy()\n",
    "    unit='day since 10/1'\n",
    "    cmap_diff=ccmap.cmap_centroid_diff\n",
    "    norm_diff=ccmap.norm_centroid_diff\n",
    "elif flow_metric == 'ann_max_flow':\n",
    "    ds_plot = ds_flow_metrics['annual_max'].copy()\n",
    "    unit='m3/s'\n",
    "    norm_flow=ccmap.norm_max_flow\n",
    "    if percent_change:\n",
    "        cmap_diff=ccmap.cmap_max_flow_pdiff\n",
    "        norm_diff=ccmap.norm_max_flow_pdiff\n",
    "    else:\n",
    "        cmap_diff=ccmap.cmap_max_flow_diff\n",
    "        norm_diff=ccmap.norm_max_flow_diff\n",
    "elif flow_metric == 'ann_min_flow':\n",
    "    ds_plot = ds_flow_metrics['annual_min'].copy()\n",
    "    unit='m3/s'\n",
    "    cmap_diff=ccmap.cmap_min_flow_diff\n",
    "    norm_diff=ccmap.norm_min_flow_diff\n",
    "    norm_flow=ccmap.norm_min_flow\n",
    "elif flow_metric == 'freq_high_q':  # annual high flow frequency\n",
    "    ds_plot = ds_flow_metrics['high_q_freq_dur'].copy()\n",
    "    unit='counts/yr'\n",
    "    cmap_diff=ccmap.cmap_freq_high_q_diff\n",
    "    norm_diff=ccmap.norm_freq_high_q_diff\n",
    "    norm_flow=ccmap.norm_freq_high_q\n",
    "elif flow_metric == 'mean_high_q_dur': # annual mean high flow duration \n",
    "    ds_plot = ds_flow_metrics['high_q_freq_dur'].copy()\n",
    "    unit='days'\n",
    "    cmap_diff=ccmap.cmap_freq_high_dur_diff\n",
    "    norm_diff=ccmap.norm_freq_high_dur_diff\n",
    "    norm_flow=ccmap.norm_freq_high_dur\n",
    "elif flow_metric == 'FHV': # annual mean high flow duration\n",
    "    ds_plot = ds_flow_metrics['FHV'].copy()\n",
    "    unit='m3/s'\n",
    "    norm_flow=ccmap.norm_max_flow\n",
    "    if percent_change:\n",
    "        cmap_diff=ccmap.cmap_max_flow_pdiff\n",
    "        norm_diff=ccmap.norm_max_flow_pdiff\n",
    "    else:\n",
    "        cmap_diff=ccmap.cmap_max_flow_diff\n",
    "        norm_diff=ccmap.norm_max_flow_diff\n",
    "\n",
    "ncols = 3\n",
    "nrows = 3\n",
    "top=0.925\n",
    "shrink=0.875\n",
    "figsize=(6.5, 6.25)\n",
    "if gcm_runs[gcm]['cmip'] == 5: \n",
    "    nrows = 2\n",
    "    top=0.925\n",
    "    shrink=0.725\n",
    "    figsize=(6.5, 4.75)\n",
    "cbar_kwrgs = {\"orientation\":\"vertical\", \"shrink\":shrink, \"pad\":0.02, 'extend':'both'}\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100,)\n",
    "fig.subplots_adjust(left=0.025, bottom=0.025, right=0.965, top=top, wspace=0.10, hspace=0.125)\n",
    "\n",
    "for ix, period in enumerate(['control','2040s','2080s']):\n",
    "    for jx, scen in enumerate([item for item in gcm_runs[gcm]['scen'] if item!='hist']):\n",
    "\n",
    "        if jx>0 and ix==0:\n",
    "            continue\n",
    "            \n",
    "        base_map(ax[jx,ix],df_huc12)\n",
    "\n",
    "        if ix==0 and jx==0:\n",
    "            if 'year' in ds_plot[gcm_name]['hist']['control'].variables:\n",
    "                df_control = ds_plot[gcm]['hist']['control'].mean(dim='year').to_dataframe()\n",
    "            else:\n",
    "                df_control = ds_plot[gcm]['hist']['control'].to_dataframe()\n",
    "            df_control.index.rename('location_name',inplace=True)\n",
    "            df_control_final = df_site_selected.merge(df_control, on=\"location_name\", how = 'inner')\n",
    " \n",
    "            if flow_metric in ['ann_min_flow', 'ann_max_flow', 'FHV', 'annual_mean']:\n",
    "                df_control_final.plot(ax=ax[jx,ix], column=flow_metric, markersize=5, cmap='turbo_r', norm=norm_flow, legend=False, zorder=2,)\n",
    "            elif flow_metric in ['freq_high_q']:\n",
    "                cbar_kwrgs['extend']='max'\n",
    "                df_control_final.plot(ax=ax[jx,ix], column=flow_metric, markersize=5, cmap='turbo_r', norm=norm_flow, legend=False, zorder=2,)\n",
    "            else:\n",
    "                df_control_final.plot(ax=ax[jx,ix], column=flow_metric, markersize=5, cmap='turbo', legend=False, zorder=2,)\n",
    "            ax[jx, ix].set_title(f'{period} [{unit}]', fontsize=8)           \n",
    "            print(f'{period}')\n",
    "        else:\n",
    "            if 'year' in ds_plot[gcm_name]['hist']['control'].variables:\n",
    "                if percent_change:  # use % change\n",
    "                    df_change = (100*(ds_plot[gcm][scen][period].mean(dim='year') - ds_plot[gcm]['hist']['control'].mean(dim='year'))/ds_plot[gcm]['hist']['control'].mean(dim='year')).to_dataframe()\n",
    "                else:\n",
    "                    df_change = (ds_plot[gcm][scen][period].mean(dim='year') - ds_plot[gcm]['hist']['control'].mean(dim='year')).to_dataframe()\n",
    "            else:\n",
    "                if percent_change:  # use % change\n",
    "                    df_change = (100*(ds_plot[gcm][scen][period] - ds_plot[gcm]['hist']['control'])/ds_plot[gcm]['hist']['control']).to_dataframe()\n",
    "                else:\n",
    "                    df_change = (ds_plot[gcm][scen][period] - ds_plot[gcm]['hist']['control']).to_dataframe()\n",
    "            if flow_metric in ['annual_max_day', 'ann_min_day', 'ann_centroid_day']:\n",
    "                unit='days'\n",
    "            if percent_change:  # use % change\n",
    "                unit='%'\n",
    "            df_change.index.rename('location_name',inplace=True)\n",
    "            df_change_final = df_site_selected.merge(df_change, on=\"location_name\", how = 'inner')\n",
    "            df_change_final.plot(ax=ax[jx,ix], column=flow_metric, markersize=5, cmap=cmap_diff, norm=norm_diff, legend=False, zorder=2,)       \n",
    "            ax[jx, ix].set_title(f'{scen} {period} [{unit}]', fontsize=8)\n",
    "            print(f'{scen}-{period}')\n",
    "            \n",
    "        points = ax[jx,ix].collections[-1]\n",
    "        cbar = plt.colorbar(points, ax=ax[jx,ix], **cbar_kwrgs);\n",
    "        cbar.ax.tick_params(labelsize=6) \n",
    "\n",
    "for kx in range(1,nrows):\n",
    "    fig.delaxes(ax[kx][0])\n",
    "\n",
    "fig.suptitle(f'{gcm} {flow_metric} change', fontsize=9, y=0.985);\n",
    "if percent_change:\n",
    "    fig.savefig(os.path.join(figure_path, f'Fig7_{flow_metric}_{gcm}_pcnt_change.png'), dpi=300)\n",
    "else:\n",
    "    fig.savefig(os.path.join(figure_path, f'Fig7_{flow_metric}_{gcm}_change.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 8. Ensemble of GCMs and scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For change in flow metrics for ensembles of GCMs/scnearios \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "flow_metric   = 'ann_max_flow'   #annual_mean, ann_centroid_day, ann_max_day, ann_max_flow, ann_min_day, ann_min_flow, FHV\n",
    "ensemble_name = 'high-emission' \n",
    "percent_change = True\n",
    "\n",
    "if flow_metric == 'ann_max_day':\n",
    "    ds_plot = ds_flow_metrics['annual_mean'].copy()\n",
    "    unit='m3/s'; metric_name = 'Annual mean flow'\n",
    "    norm_flow=norm_mean_flow\n",
    "    if percent_change:\n",
    "        cmap_diff=cmap_mean_flow_pdiff\n",
    "        norm_diff=norm_mean_flow_pdiff\n",
    "    else:\n",
    "        cmap_diff=cmap_mean_flow_diff\n",
    "        norm_diff=norm_mean_flow_diff\n",
    "elif flow_metric == 'ann_max_day':\n",
    "    ds_plot = ds_flow_metrics['annual_max'].copy()\n",
    "    unit='day since 10/1'; metric_name = 'Annual maximum flow day'\n",
    "    cmap_diff=ccmap.cmap_max_day_diff\n",
    "    norm_diff=ccmap.norm_max_day_diff\n",
    "elif flow_metric == 'ann_min_day':\n",
    "    ds_plot = ds_flow_metrics['annual_min'].copy()\n",
    "    unit='day since 10/1'; metric_name = 'Annual minimum flow day'\n",
    "    cmap_diff=ccmap.cmap_min_day_diff\n",
    "    norm_diff=ccmap.norm_min_day_diff\n",
    "elif flow_metric == 'ann_centroid_day':\n",
    "    ds_plot = ds_flow_metrics['ctr'].copy()\n",
    "    unit='day since 10/1'; metric_name = 'Annual centroid'\n",
    "    cmap_diff=ccmap.cmap_centroid_diff\n",
    "    norm_diff=ccmap.norm_centroid_diff\n",
    "elif flow_metric == 'ann_max_flow':\n",
    "    ds_plot = ds_flow_metrics['annual_max'].copy()\n",
    "    unit='m3/s'; metric_name = 'Annual maximum flow'\n",
    "    if percent_change:\n",
    "        cmap_diff=cmap_mean_flow_pdiff #ccmap.cmap_max_flow_pdiff\n",
    "        norm_diff=norm_mean_flow_pdiff #ccmap.norm_max_flow_pdiff\n",
    "        norm_flow=ccmap.norm_max_flow\n",
    "    else:\n",
    "        cmap_diff=ccmap.cmap_max_flow_diff\n",
    "        norm_diff=ccmap.norm_max_flow_diff\n",
    "        norm_flow=ccmap.norm_max_flow\n",
    "elif flow_metric == 'ann_min_flow':\n",
    "    ds_plot = ds_flow_metrics['annual_min'].copy()\n",
    "    unit='m3/s'; metric_name = 'Annual minimum flow'\n",
    "    cmap_diff=ccmap.cmap_min_flow_diff\n",
    "    norm_diff=ccmap.norm_min_flow_diff\n",
    "    norm_flow=ccmap.norm_min_flow\n",
    "elif flow_metric == 'freq_high_q':  # annual high flow frequency\n",
    "    ds_plot = ds_flow_metrics['high_q_freq_dur'].copy()\n",
    "    unit='counts/yr'; metric_name = 'Annual high flow frequency'\n",
    "    cmap_diff=ccmap.cmap_freq_high_q_diff\n",
    "    norm_diff=ccmap.norm_freq_high_q_diff\n",
    "    norm_flow=ccmap.norm_freq_high_q\n",
    "elif flow_metric == 'mean_high_q_dur': # annual mean high flow duration \n",
    "    ds_plot = ds_flow_metrics['high_q_freq_dur'].copy()\n",
    "    unit='days'; metric_name = 'Annual mean high flow duration'\n",
    "    cmap_diff=ccmap.cmap_freq_high_dur_diff\n",
    "    norm_diff=ccmap.norm_freq_high_dur_diff\n",
    "    norm_flow=ccmap.norm_freq_high_dur\n",
    "elif flow_metric == 'FHV': # annual mean high flow duration\n",
    "    ds_plot = ds_flow_metrics['FHV'].copy() \n",
    "    unit='m3/s'; metric_name = 'Flow>90% in FDC'\n",
    "    if percent_change:\n",
    "        cmap_diff=ccmap.cmap_max_flow_pdiff\n",
    "        norm_diff=ccmap.norm_max_flow_pdiff\n",
    "        norm_flow=ccmap.norm_max_flow\n",
    "    else:\n",
    "        cmap_diff=ccmap.cmap_max_flow_diff\n",
    "        norm_diff=ccmap.norm_max_flow_diff\n",
    "        norm_flow=ccmap.norm_max_flow        \n",
    "    \n",
    "# -------------------\n",
    "print('Computing ensemble mean.....')\n",
    "# -------------------\n",
    "gcm_plots = {}\n",
    "for gcm, meta in gcm_runs.items():\n",
    "    if meta['cmip'] in ensembles[ensemble_name]['cmip']:\n",
    "        gcm_plots[gcm] = [scen for scen in meta['scen'] if scen in ensembles[ensemble_name]['scen']]\n",
    "print(gcm_plots)\n",
    "\n",
    "dr_metric_cat = {}\n",
    "count = 0 \n",
    "for gcm_name, scen_list in gcm_plots.items():\n",
    "    if count==0:\n",
    "        dr_metric_cat['control'] = ds_plot[gcm_name]['hist']['control'][flow_metric]\n",
    "    else:\n",
    "        dr_metric_cat['control'] =  xr.concat([dr_metric_cat['control'], ds_plot[gcm_name]['hist']['control'][flow_metric]], \"gcm\")\n",
    "    count+=1\n",
    "\n",
    "count = 0 \n",
    "for gcm_name, scen_list in gcm_plots.items():\n",
    "    for scen in scen_list:\n",
    "        if scen=='hist':\n",
    "            continue\n",
    "        if count==0:\n",
    "            dr_metric_cat['2040s']  = ds_plot[gcm_name][scen]['2040s'][flow_metric]\n",
    "            dr_metric_cat['2080s']  = ds_plot[gcm_name][scen]['2080s'][flow_metric]\n",
    "        else:\n",
    "            dr_metric_cat['2040s']  = xr.concat([dr_metric_cat['2040s'], ds_plot[gcm_name][scen]['2040s'][flow_metric]], \"gcm\")\n",
    "            dr_metric_cat['2080s']  = xr.concat([dr_metric_cat['2080s'], ds_plot[gcm_name][scen]['2080s'][flow_metric]], \"gcm\")\n",
    "        count+=1\n",
    "\n",
    "# -------------------\n",
    "print('plotting.....')\n",
    "# -------------------\n",
    "ncols = 3\n",
    "nrows = 1\n",
    "shrink=0.65\n",
    "figsize=(6.25, 2.5)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=150,)\n",
    "fig.subplots_adjust(left=0.025, bottom=0.025, right=0.965, top=0.965, wspace=0.10, hspace=0.125)\n",
    "\n",
    "for ix, period in enumerate(['control','2040s','2080s']):\n",
    "    \n",
    "    cbar_kwrgs = {\"orientation\":\"vertical\", \"shrink\":shrink, \"pad\":0.02, 'extend':'both'}\n",
    "    \n",
    "    print(f'{ix}. {period}')\n",
    "    \n",
    "    base_map(ax[ix],df_huc12)\n",
    "\n",
    "    if period=='control':\n",
    "        if 'year' in dr_metric_cat[period].coords:\n",
    "            df_control = dr_metric_cat[period].mean(dim=['year','gcm']).to_dataframe()\n",
    "            #hist_test = ds_metric_cat[period].sel(year=slice('1980','2005'))[flow_metric] # array for student t-test for mean difference\n",
    "            hist_test = dr_metric_cat[period].mean(dim='year') # array for student t-test for mean difference\n",
    "        else:\n",
    "            df_control = dr_metric_cat[period].mean(dim='gcm').to_dataframe()\n",
    "            hist_test = dr_metric_cat[period]\n",
    "        df_control.index.rename('location_name',inplace=True)\n",
    "        df_control_final = df_site_selected.merge(df_control, on=\"location_name\", how = 'inner')\n",
    "        if flow_metric in ['ann_min_flow', 'ann_max_flow', 'FHV', 'annual_mean']:\n",
    "            df_control_final.plot(ax=ax[ix], column=flow_metric, markersize=3, cmap='turbo_r', norm=norm_flow, legend=False, zorder=2,)\n",
    "        elif flow_metric in ['freq_high_q']:\n",
    "            cbar_kwrgs['extend']='max'\n",
    "            df_control_final.plot(ax=ax[ix], column=flow_metric, markersize=2, cmap='turbo_r', norm=norm_flow, legend=False, zorder=2,)\n",
    "        else:\n",
    "            df_control_final.plot(ax=ax[ix], column=flow_metric, markersize=2, cmap='turbo', legend=False, zorder=2,)\n",
    "        ax[ix].set_title(f\"{periods[period]['name']}\", fontsize=8)\n",
    "        if flow_metric=='ann_centroid_day':\n",
    "            ax[ix].text(0.5, 1.145, f'{metric_name}', horizontalalignment='center', transform=ax[0].transAxes, fontsize=9.5)\n",
    "        else:\n",
    "            ax[ix].text(0.6, 1.145, f'{metric_name} [{unit}]', horizontalalignment='center', transform=ax[0].transAxes, fontsize=9.5)\n",
    "    else:\n",
    "        if percent_change:  # use % change\n",
    "            if 'year' in dr_metric_cat[period].coords:\n",
    "                dr_change = 100*(dr_metric_cat[period].mean(dim=['year','gcm']) - dr_metric_cat['control'].mean(dim=['year','gcm']))/dr_metric_cat['control'].mean(dim=['year','gcm'])\n",
    "            else:\n",
    "                dr_change = 100*(dr_metric_cat[period].mean(dim='gcm') - dr_metric_cat['control'].mean(dim='gcm'))/dr_metric_cat['control'].mean(dim='gcm')\n",
    "            unit='%'\n",
    "        else:\n",
    "            if 'year' in dr_metric_cat[period].coords:\n",
    "                dr_change = dr_metric_cat[period].mean(dim=['year','gcm']) - dr_metric_cat['control'].mean(dim=['year','gcm'])\n",
    "            else:\n",
    "                dr_change = dr_metric_cat[period].mean(dim='gcm') - dr_metric_cat['control'].mean(dim='gcm')\n",
    "            if flow_metric in ['annual_max_day', 'ann_min_day', 'ann_centroid_day']:\n",
    "                unit='days'\n",
    "\n",
    "        # statistical test for mean difference between two periods\n",
    "        if 'year' in dr_metric_cat[period].coords: \n",
    "            fut  = dr_metric_cat[period].mean(dim='year')\n",
    "        else:\n",
    "            fut  = dr_metric_cat[period]\n",
    "        pvalue = stats.ttest_ind(hist_test,fut, axis=0, equal_var=False).pvalue\n",
    "        \n",
    "        df_change = dr_change.to_dataframe()\n",
    "        df_change.index.rename('location_name',inplace=True)\n",
    "        df_change['pvalue'] = pvalue\n",
    "        df_change_final = df_site_selected.merge(df_change, on=\"location_name\", how = 'inner')\n",
    "\n",
    "        if len(df_change_final[df_change_final['pvalue']>0.05])>0:\n",
    "            df_change_final[df_change_final['pvalue']>0.05].plot(ax=ax[ix], column=flow_metric, marker='^', markersize=4, edgecolor=\"black\", linewidth=0.1, cmap=cmap_diff, norm=norm_diff, legend=False, zorder=2,)\n",
    "        if len(df_change_final[df_change_final['pvalue']<0.05])>0:  \n",
    "            df_change_final[df_change_final['pvalue']<0.05].plot(ax=ax[ix], column=flow_metric, markersize=4, edgecolor=\"black\", linewidth=0.1, cmap=cmap_diff, norm=norm_diff, legend=False, zorder=2,)\n",
    "        ax[ix].set_title(f\"{periods[period]['name']}\", fontsize=8)\n",
    "        if ix==1:\n",
    "            if percent_change:\n",
    "                ax[1].text(0.5, 1.145, f'%change in {metric_name} [{unit}]', transform=ax[1].transAxes, fontsize=9.5)\n",
    "            else:\n",
    "                ax[1].text(0.5, 1.145, f'Change in {metric_name} [{unit}]', transform=ax[1].transAxes, fontsize=9.5)\n",
    "    points = ax[ix].collections[-1]\n",
    "    cbar = plt.colorbar(points, ax=ax[ix], **cbar_kwrgs);\n",
    "    if flow_metric=='ann_centroid_day' and period=='control':\n",
    "        cbar.set_ticks([124, 152, 183, 213, 244])\n",
    "        cbar.set_ticklabels(['2/1','3/1','4/1','5/1','6/1'])    \n",
    "    cbar.ax.tick_params(labelsize=6)\n",
    "    \n",
    "if percent_change:\n",
    "    fig.savefig(os.path.join(figure_path,f'Fig8_{flow_metric}_{ensemble_name}_ensemble_pcnt_change.png'), dpi=300)\n",
    "else:\n",
    "    fig.savefig(os.path.join(figure_path,f'Fig8_{flow_metric}_{ensemble_name}_ensemble_change.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 9. Changes in annual flow magnitude for a return period compared to control period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_max_flow_pdiff = LinearSegmentedColormap.from_list('custom1', \n",
    "                                             [(0.0,      'xkcd:red'),\n",
    "                                              (20/100,   'xkcd:white'),\n",
    "                                              (1.0,      'xkcd:blue')], N=255)\n",
    "cmap_max_flow_pdiff.set_over('xkcd:blue')\n",
    "cmap_max_flow_pdiff.set_under('xkcd:red')\n",
    "norm_max_flow_pdiff=mpl.colors.Normalize(vmin=-20, vmax=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "flow_metric   = 'aff'   # only aff\n",
    "return_period = 20\n",
    "ensemble_name = 'high-emission' \n",
    "percent_change = True\n",
    "\n",
    "ds_plot = ds_flow_metrics[flow_metric].copy()\n",
    "unit='m3/s'; metric_name = f'{return_period}-yr annual peak flow'\n",
    "if percent_change:\n",
    "    cmap_diff=ccmap.cmap_max_flow_pdiff\n",
    "    norm_diff=ccmap.norm_max_flow_pdiff\n",
    "    norm_flow=ccmap.norm_max_flow\n",
    "else:\n",
    "    cmap_diff=ccmap.cmap_max_flow_diff\n",
    "    norm_diff=ccmap.norm_max_flow_diff\n",
    "    norm_flow=ccmap.norm_max_flow\n",
    "    \n",
    "# -------------------\n",
    "print('Computing ensemble mean.....')\n",
    "# -------------------\n",
    "gcm_plots = {}\n",
    "for gcm, meta in gcm_runs.items():\n",
    "    if meta['cmip'] in ensembles[ensemble_name]['cmip']:\n",
    "        gcm_plots[gcm] = [scen for scen in meta['scen'] if scen in ensembles[ensemble_name]['scen']]\n",
    "print(gcm_plots)\n",
    "\n",
    "ds_metric_cat = {}\n",
    "count = 0 \n",
    "for gcm_name, scen_list in gcm_plots.items():\n",
    "    if count==0:\n",
    "        ds_metric_cat['hist'] = ds_plot[gcm_name]['hist'].sel(return_period=return_period, method='nearest')\n",
    "    else:\n",
    "        ds_metric_cat['hist'] = xr.concat([ds_metric_cat['hist'], ds_plot[gcm_name]['hist'].sel(return_period=return_period, method='nearest')], \"gcm\")\n",
    "    count+=1\n",
    "\n",
    "count = 0 \n",
    "for gcm_name, scen_list in gcm_plots.items():\n",
    "    for scen in scen_list:\n",
    "        if scen=='hist':\n",
    "            continue\n",
    "        if count==0:\n",
    "            ds_metric_cat['2050-2099']  = ds_plot[gcm_name][scen].sel(return_period=return_period, method='nearest')\n",
    "        else:\n",
    "            ds_metric_cat['2050-2099']  = xr.concat([ds_metric_cat['2050-2099'], ds_plot[gcm_name][scen].sel(return_period=return_period, method='nearest')], \"gcm\")\n",
    "        count+=1\n",
    "\n",
    "# -------------------\n",
    "print('plotting.....')\n",
    "# -------------------\n",
    "ncols = 2\n",
    "nrows = 1\n",
    "shrink=0.85\n",
    "figsize=(6.0, 3.00)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=150,)\n",
    "fig.subplots_adjust(left=0.025, bottom=0.025, right=0.965, top=0.90, wspace=0.05, hspace=0.125)\n",
    "\n",
    "for ix, period in enumerate(['hist','2050-2099']):\n",
    "    \n",
    "    cbar_kwrgs = {\"orientation\":\"vertical\", \"shrink\":shrink, \"pad\":0.02, 'extend':'both'}\n",
    "    \n",
    "    print(f'{ix}. {period}')\n",
    "    \n",
    "    base_map(ax[ix],df_huc12)\n",
    "\n",
    "    if period=='hist':\n",
    "        hist_test = ds_metric_cat[period][flow_metric]\n",
    "        df_hist = ds_metric_cat[period].mean(dim='gcm').to_dataframe()\n",
    "        df_hist.index.rename('location_name',inplace=True)\n",
    "        df_hist_final = df_site_selected.merge(df_hist, on=\"location_name\", how = 'inner')\n",
    "        df_hist_final.plot(ax=ax[ix], column=flow_metric, markersize=3, cmap='turbo_r', norm=norm_flow, legend=False, zorder=2,)\n",
    "        cbar_kwrgs['extend']='max'\n",
    "        ax[ix].set_title(f'{period}', fontsize=7)\n",
    "        ax[ix].text(0.075, 1.1, f'{metric_name} [{unit}]', transform=ax[0].transAxes, fontsize=8.0)\n",
    "    else:\n",
    "        if percent_change:  # use % change\n",
    "            ds_change = 100*(ds_metric_cat[period].mean(dim='gcm') - ds_metric_cat['hist'].mean(dim='gcm'))/ds_metric_cat['hist'].mean(dim='gcm')\n",
    "            unit='%'\n",
    "        else:\n",
    "            ds_change = ds_metric_cat[period].mean(dim='gcm') - ds_metric_cat['hist'].mean(dim='gcm')\n",
    "\n",
    "        # statistical test for mean difference between two periods\n",
    "        fut  = ds_metric_cat[period][flow_metric]\n",
    "        pvalue = stats.ttest_ind(hist_test, fut, axis=0, equal_var=False).pvalue\n",
    "         \n",
    "        df_change = ds_change.to_dataframe()\n",
    "        df_change.index.rename('location_name',inplace=True)\n",
    "        df_change['pvalue'] = pvalue\n",
    "        df_change_final = df_site_selected.merge(df_change, on=\"location_name\", how = 'inner')\n",
    "\n",
    "        if len(df_change_final[df_change_final['pvalue']>0.05])>0:\n",
    "            df_change_final[df_change_final['pvalue']>0.05].plot(ax=ax[ix], column=flow_metric, marker='^', markersize=5, edgecolor=\"black\", linewidth=0.1,cmap=cmap_diff, norm=norm_diff, legend=False, zorder=2,)\n",
    "        if len(df_change_final[df_change_final['pvalue']<0.05])>0:  \n",
    "            df_change_final[df_change_final['pvalue']<0.05].plot(ax=ax[ix], column=flow_metric, markersize=5, edgecolor=\"black\", linewidth=0.1, cmap=cmap_diff, norm=norm_diff, legend=False, zorder=2,)\n",
    "        ax[ix].set_title(f'{period}', fontsize=7)\n",
    "        if ix==1:\n",
    "            if percent_change:\n",
    "                ax[1].text(0.0, 1.1, f'%change in {metric_name} [{unit}]', transform=ax[1].transAxes, fontsize=8.0)\n",
    "            else:\n",
    "                ax[1].text(0.0, 1.1, f'Change in {metric_name} [{unit}]', transform=ax[1].transAxes, fontsize=8.0)\n",
    "    points = ax[ix].collections[-1]\n",
    "    cbar = plt.colorbar(points, ax=ax[ix], **cbar_kwrgs);\n",
    "    cbar.ax.tick_params(labelsize=6) \n",
    "    \n",
    "if percent_change:\n",
    "    fig.savefig(os.path.join(figure_path,f'Fig9_{flow_metric}_{ensemble_name}_ensemble_pcnt_change.png'), dpi=300)\n",
    "else:\n",
    "    fig.savefig(os.path.join(figure_path,f'Fig9_{flow_metric}_{ensemble_name}_ensemble_change.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 10. Changes in a future return period of historical flow magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_future_aff = AutoVivification()\n",
    "for gcm in sim_names:\n",
    "    for scen in ds_qsim_selected[gcm].keys():\n",
    "        if scen=='hist':\n",
    "            continue\n",
    "        else:\n",
    "            print(f'{gcm}-{scen}')\n",
    "            ds1 = ds_qsim_selected[gcm][scen]['streamflow'].sel(time=slice('2049-10-01', '2099-09-30'))\n",
    "            ds_future_aff[gcm][scen] = metrics.lp3_flood_return_period(ds1, ds_flow_metrics['aff'][gcm]['hist'].sel(return_period=20, method='nearest')['aff'].drop_vars('return_period'))\n",
    "            ds_future_aff[gcm][scen] = 1.0/(1.0-ds_future_aff[gcm][scen])\n",
    "            ds_future_aff[gcm][scen] = ds_future_aff[gcm][scen].rename({'cdf':'return_period'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "vals0=np.arange(1,17,1)\n",
    "cmap0 = plt.get_cmap('turbo', (len(vals0)))\n",
    "#cmap0.set_under('cyan')\n",
    "#cmap = mpl.colors.ListedColormap(mpl.cm.Spectral_r(np.arange(9)))\n",
    "norm0 = mpl.colors.BoundaryNorm(vals0, cmap0.N)\n",
    "\n",
    "ensemble_name = 'high-emission' \n",
    "\n",
    "# -------------------\n",
    "print('Computing ensemble mean.....')\n",
    "# -------------------\n",
    "gcm_plots = {}\n",
    "for gcm, meta in gcm_runs.items():\n",
    "    if meta['cmip'] in ensembles[ensemble_name]['cmip']:\n",
    "        gcm_plots[gcm] = [scen for scen in meta['scen'] if scen in ensembles[ensemble_name]['scen']]\n",
    "print(gcm_plots)\n",
    "\n",
    "ds_metric_cat = {}\n",
    "count = 0 \n",
    "for gcm_name, scen_list in gcm_plots.items():\n",
    "    for scen in scen_list:\n",
    "        if scen=='hist':\n",
    "            continue\n",
    "        if count==0:\n",
    "            ds_metric_cat['2050-2099']  = ds_future_aff[gcm_name][scen]\n",
    "        else:\n",
    "            ds_metric_cat['2050-2099']  = xr.concat([ds_metric_cat['2050-2099'], ds_future_aff[gcm_name][scen]], \"gcm\")\n",
    "        count+=1\n",
    "        \n",
    "# -------------------\n",
    "print('plotting.....')\n",
    "# -------------------\n",
    "ncols = 1\n",
    "nrows = 1\n",
    "shrink=0.75\n",
    "figsize=(4.5, 5.00)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=150,)\n",
    "fig.subplots_adjust(left=0.025, bottom=0.025, right=0.965, top=0.975, wspace=0.05, hspace=0.125)\n",
    "cbar_kwrgs = {\"orientation\":\"horizontal\", \"shrink\":shrink, \"pad\":0.02, 'extend':'neither'}\n",
    "base_map(ax,df_huc12)\n",
    "df_metric = ds_metric_cat['2050-2099'].median(dim='gcm').to_dataframe()\n",
    "df_metric.index.rename('location_name',inplace=True)\n",
    "df_metric_final = df_site_selected.merge(df_metric, on=\"location_name\", how = 'inner')\n",
    "df_metric_final.plot(ax=ax, column='return_period', markersize=10, edgecolor=\"None\", linewidth=0.1, cmap=cmap0, norm=norm0, legend=False, zorder=2,) #'YlGnBu_r'\n",
    "#ax.set_title('Change in return period of 20-yr annual max. flow estimated during 1954-2004', fontsize='xx-small')\n",
    "points = ax.collections[-1]\n",
    "cbar = plt.colorbar(points, ax=ax, **cbar_kwrgs);\n",
    "cbar.ax.tick_params(labelsize=7)\n",
    "\n",
    "# this is an inset axes over the main axes\n",
    "ins = ax.inset_axes([0.725,0.775,0.25,0.2])\n",
    "df_metric.plot.hist(ax=ins, bins=range(1,17), legend=False)\n",
    "ins.set_xlabel('future return period [yr]', fontsize=6)\n",
    "ins.set_xlim([1,16])\n",
    "ins.set_ylabel('# of sites', fontsize=6)\n",
    "ins.xaxis.set_major_locator(ticker.MultipleLocator(5)) # set BIG ticks\n",
    "ins.xaxis.set_minor_locator(ticker.MultipleLocator(1)) # set small ticks\n",
    "ins.tick_params(labelsize=5)\n",
    "\n",
    "fig.savefig(os.path.join(figure_path,f'Fig10_return_period_{ensemble_name}_change.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 11. Historical and future empriacal annual flood frequency curves at selected site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'MROW'\n",
    "\n",
    "p = 1-1/ds_flow_metrics['aff'][gcm_name]['hist']['return_period'].values\n",
    "\n",
    "obs_flow = ds_nrni_selected['streamflow'].sel(site=site, time=slice('1954-10-01','2004-09-30')).rolling(time=7).mean()\n",
    "ann_max_obs = obs_flow.resample(time=\"YS\").max().values\n",
    "ann_max_obs_sort =  ann_max_obs[np.argsort(ann_max_obs)]\n",
    "obs_prob=np.arange(1,float(len(ann_max_obs)+1))/(1+len(ann_max_obs))#*100  #probability\n",
    "#plt.plot(obs_prob, ann_max_obs_sort, 'o', markersize=3, c='k')\n",
    "#aff_obs = metrics.lp3_flood(obs_flow)\n",
    "#plt.plot(p, aff_obs['aff'].values, ls=':', c='k', label='hist')\n",
    "\n",
    "hist_ann_max_sort=np.ones((len(gcm_plots),50))*np.nan\n",
    "fut_ann_max_sort=np.ones((len(gcm_plots),50))*np.nan\n",
    "hist_sim_prob=np.arange(1,float(hist_ann_max_sort.shape[1]+1))/(1+hist_ann_max_sort.shape[1])#*100  #probability\n",
    "fut_sim_prob=np.arange(1,float(fut_ann_max_sort.shape[1]+1))/(1+fut_ann_max_sort.shape[1])#*100  #probability\n",
    "\n",
    "for ix, (gcm_name, scen_list) in enumerate(gcm_plots.items()):\n",
    "    ds1 = ds_qsim_selected[gcm_name]['hist']['streamflow'].sel(site=site, time=slice('1954-10-01', '2004-09-30')).rolling(time=7).mean()\n",
    "    ann_max = ds1.resample(time=\"YS-OCT\").max().values\n",
    "    hist_ann_max_sort[ix,:] =  ann_max[np.argsort(ann_max)]\n",
    "    \n",
    "    if 'ssp585' in scen_list:\n",
    "        ds1 = ds_qsim_selected[gcm_name]['ssp585']['streamflow'].sel(site=site, time=slice('2049-10-01', '2099-09-30')).rolling(time=7).mean()     \n",
    "        ann_max = ds1.resample(time=\"YS-OCT\").max().values\n",
    "        fut_ann_max_sort[ix,:] = ann_max[np.argsort(ann_max)]\n",
    "    else:\n",
    "        ds1 = ds_qsim_selected[gcm_name]['rcp85']['streamflow'].sel(site=site, time=slice('2049-10-01', '2099-09-30')).rolling(time=7).mean()     \n",
    "        ann_max = ds1.resample(time=\"YS-OCT\").max().values\n",
    "        fut_ann_max_sort[ix,:] = ann_max[np.argsort(ann_max)]\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(4.5, 3.5), dpi=100,)\n",
    "ax.plot(1/(1-hist_sim_prob), np.median(hist_ann_max_sort, axis=0), 'o-', markersize=3, color='b')\n",
    "ax.plot(1/(1-fut_sim_prob), np.median(fut_ann_max_sort, axis=0), 'o-', markersize=3, color='r')\n",
    "ax.fill_between(1/(1-hist_sim_prob), np.percentile(hist_ann_max_sort, 25, axis=0), np.percentile(hist_ann_max_sort, 75, axis=0), alpha=0.3, color='b', label='WY1955-2004')\n",
    "ax.fill_between(1/(1-fut_sim_prob), np.percentile(fut_ann_max_sort, 25, axis=0), np.percentile(fut_ann_max_sort, 75, axis=0), alpha=0.3, color='r', label='WY2050-2099')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "#plt.grid(False, linestyle='--', linewidth=0.7, alpha=0.6)\n",
    "plt.xticks([1,10,50],[1,10,50])\n",
    "plt.xlim([0.95,55])\n",
    "ax.set_yscale('linear')\n",
    "ax.set_xlabel('return period [yr]')\n",
    "ax.set_ylabel('Annual maximum flow [m3/s]')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(figure_path, f'Fig11_return_period_{ensemble_name}_{site}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fig 12. Annual time seriese plots for 150 years at a specified site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plots of simulations based on different bias corrected CanESM SUMMA forcing (bc1: \n",
    "site='DWR' #MROW\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(6.5, 2.5), dpi=150)\n",
    "ds_nrni_selected['streamflow'].sel(site=site, time=periods['control']['time']).resample(time=\"YS-OCT\").mean().plot(ax=axs, c='k',ls='--',lw=1.5)\n",
    "\n",
    "slope_ave = 0\n",
    "intsect_ave = 0\n",
    "count = 0\n",
    "for case, meta in retro_runs.items():\n",
    "    c='k'\n",
    "    lw=1\n",
    "    ds_qsim_selected[case]['hist']['streamflow'].sel(site=site, time=periods['control']['time']).resample(time=\"YS-OCT\").mean().plot(ax=axs, lw=lw, color=c, label=case, zorder=0)\n",
    "    \n",
    "for case, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        if scen=='hist':\n",
    "            c='xkcd:gray'; lw=0.15            \n",
    "        elif scen=='ssp245' or scen=='rcp45':\n",
    "            c='#005AB5'; lw=0.15\n",
    "        elif scen=='ssp370':\n",
    "            continue\n",
    "            c='xkcd:green'; lw=0.15\n",
    "        elif scen=='ssp585' or scen=='rcp85':\n",
    "            c='#DC3220'; lw=0.15\n",
    "            \n",
    "        if scen == 'hist':\n",
    "            ds_qsim_selected[case][scen]['streamflow'].sel(site=site, time=periods['control']['time']).resample(time=\"YS-OCT\").mean().plot(ax=axs, lw=lw, color=c, label=case, zorder=0)\n",
    "        else:\n",
    "            count +=1\n",
    "            dr_ann_q = ds_qsim_selected[case][scen]['streamflow'].sel(site=site).resample(time=\"YS-OCT\").mean()\n",
    "            dr_ann_q.plot(ax=axs, lw=lw, color=c, label=case)\n",
    "            years = np.arange(len(dr_ann_q.time))\n",
    "            slope, intsect = np.polyfit(years, dr_ann_q.values, 1)\n",
    "            slope_ave += slope\n",
    "            intsect_ave += intsect\n",
    "slope_ave /= count\n",
    "intsect_ave /= count\n",
    "trend = xr.DataArray(\n",
    "    slope_ave * years + intsect_ave,\n",
    "    coords={\"time\": dr_ann_q.time},\n",
    "    dims=[\"time\"],\n",
    "    )\n",
    "trend.plot(ax=axs, lw=1, color='k', ls=':')\n",
    "\n",
    "axs.set_title('')\n",
    "axs.set_xlabel('');\n",
    "axs.set_xlim(pd.Timestamp('1980-01-01'), pd.Timestamp('2100-01-01'));\n",
    "axs.set_ylabel('Annual mean flow [m3/s]');   \n",
    "\n",
    "#plt.yscale('log')\n",
    "#plt.legend();\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figure_path, f'Fig12_annual_series_{site}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fig 13. annual cycle plots at a specified site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- setup\n",
    "site='MROW'\n",
    "ensemble_name = \"low_high-emission\"\n",
    "skip_period = ['2040s']  # control, 2040s, 2080s, \n",
    "# ---\n",
    "\n",
    "gcm_plots = {gcm: list(set(meta['scen']).intersection(ensembles[ensemble_name]['scen'])) for gcm, meta in gcm_runs.items() if meta['cmip'] in ensembles[ensemble_name]['cmip'] }\n",
    "num_gcm = len(gcm_plots)\n",
    "\n",
    "\n",
    "emission_scen = {'low emission': ['ssp245','rcp45'], 'high emission': ['ssp585','rcp85']}\n",
    "emission_color = {'low emission': 'blue', 'high emission': 'red'}\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize=(6.5, 2.5), dpi=150)\n",
    "\n",
    "zorder=6\n",
    "for period, _ in periods.items():\n",
    "    \n",
    "    # skip periods\n",
    "    if period in skip_period:\n",
    "        continue\n",
    "        \n",
    "    if period=='control':\n",
    "\n",
    "        obs_flow = ds_seasonal_flow['obs'].sel(site=site).roll(dayofyear=92, roll_coords=False)#.plot(c='k',ls='--',lw=1.0)\n",
    "        plt.plot(np.arange(0,366), obs_flow, linestyle='--', linewidth=1.0, color='black', label='obs', zorder=6)\n",
    "            \n",
    "        for ix, retro in enumerate(retro_names):\n",
    "            sim_flow = ds_seasonal_flow[retro]['hist']['control'].sel(site=site).roll(dayofyear=92, roll_coords=False).values\n",
    "            plt.plot(np.arange(0,366), sim_flow, linestyle='-', linewidth=1.0, color='k', label='%s'%(retro), zorder=zorder)\n",
    "        \n",
    "        for ix, gcm in enumerate(list(gcm_plots.keys())):\n",
    "                \n",
    "            sim_flow = ds_seasonal_flow[gcm]['hist']['control'].sel(site=site).roll(dayofyear=92, roll_coords=False).values\n",
    "            if ix==0:\n",
    "                sim_flow_min = sim_flow\n",
    "                sim_flow_max = sim_flow\n",
    "            else:\n",
    "                sim_flow_max = np.maximum(sim_flow_max, sim_flow)\n",
    "                sim_flow_min = np.minimum(sim_flow_min, sim_flow)\n",
    "        zorder -=1        \n",
    "        plt.fill_between(np.arange(0,366), sim_flow_min, sim_flow_max, alpha=0.4, color='grey', label=period, zorder=zorder)\n",
    "\n",
    "    else:\n",
    "        for emission, scen_list in emission_scen.items():\n",
    "            ix = 0\n",
    "            for gcm, scen_list1 in gcm_plots.items():\n",
    "                for scen in scen_list1:\n",
    "                    if scen in scen_list:\n",
    "                        sim_flow = ds_seasonal_flow[gcm][scen][period].sel(site=site).roll(dayofyear=92, roll_coords=False).values\n",
    "                        if num_gcm==1:\n",
    "                            plt.plot(np.arange(0,366), sim_flow, linestyle='--', lw=0.75, label='%s'%(scen))\n",
    "                        else:\n",
    "                            if ix==0:\n",
    "                                sim_flow_min = sim_flow\n",
    "                                sim_flow_max = sim_flow\n",
    "                            else:\n",
    "                                sim_flow_max = np.maximum(sim_flow_max, sim_flow)\n",
    "                                sim_flow_min = np.minimum(sim_flow_min, sim_flow)\n",
    "                        ix+=1\n",
    "            plt.fill_between(np.arange(0,366), sim_flow_min, sim_flow_max, alpha=0.3, color=emission_color[emission], label=emission, zorder=zorder)    \n",
    "        zorder-=1\n",
    "    \n",
    "axs.set_title('')\n",
    "axs.set_xlabel('');\n",
    "axs.set_ylabel('Daily discharge [m3/s]');\n",
    "axs.set_xlim([0,367]);\n",
    "axs.set_xticks([1,32,62,93,124,152,183,213,244,274,305,336]); \n",
    "axs.set_xticklabels(['10/1','11/1','12/1','1/1','2/1','3/1','4/1','5/1','6/1','7/1','8/1','9/1'])\n",
    "plt.legend(fontsize='x-small')\n",
    "plt.title(f'{site}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figure_path, f'Fig13_seasonal_flow_ensemble_{site}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Flow duration curve at each site\n",
    "!!! This create hundreds of plot for indiviual sites !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. One ESM with one scenario (3 lines for control, 2040s, 2080s) and Obs (a dash line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# --- setup\n",
    "gcm_plot = 'CanESM5'\n",
    "scen_plot = 'ssp245'\n",
    "site_plot = ds_nrni_selected['site'].values # limit the sites of interest\n",
    "skip_period = []\n",
    "# ---\n",
    "\n",
    "for site in site_plot:\n",
    "    \n",
    "    fig, maiax = plt.subplots(1, figsize = (7, 5))\n",
    "    maxflow = 0\n",
    "    minflow = 10**6\n",
    "    \n",
    "    obs_prob=np.arange(1,float(len(ds_nrni_selected.sel(time=periods['control']['time'])['time'])+1))/(1+len(ds_nrni_selected.sel(time=periods['control']['time'])['time']))  #probability \n",
    "    obs_flow = ds_nrni_selected['streamflow'].sel(site=site, time=periods['control']['time']).values\n",
    "    #obs_flow = np.where(obs_flow<0.0, 1.0e-7,obs_flow)\n",
    "    obs_flow_sort =  obs_flow[np.argsort(obs_flow)[::-1]]\n",
    "    maiax.plot(obs_prob, obs_flow_sort, ls='--', lw=2.0, color='black', label='obs')\n",
    "\n",
    "    imax = np.where(obs_prob<0.9995)\n",
    "    maxflow = max(maxflow, max(obs_flow_sort[imax])) \n",
    "    minflow = min(minflow, min(obs_flow_sort[imax]))\n",
    "    \n",
    "    for period, _ in periods.items():\n",
    "        \n",
    "        if period in skip_period:\n",
    "                continue\n",
    "            \n",
    "        if period=='control':\n",
    "            scen_list=['hist']\n",
    "        else:\n",
    "            scen_list=[scen_plot]\n",
    "            \n",
    "        for scen in scen_list:\n",
    "            if scen=='hist' and period!='control':\n",
    "                continue\n",
    "                \n",
    "            sim_flow = ds_qsim_selected[gcm_plot][scen].sel(time=periods[period]['time'], site=site)['streamflow'].values\n",
    "            sim_flow_sort =  sim_flow[np.argsort(sim_flow)[::-1]]\n",
    "                \n",
    "            sim_prob = np.arange(1,float(len(sim_flow)+1))/(1+len(sim_flow)) #probability        \n",
    "\n",
    "            imax = np.where(sim_prob<0.9995)\n",
    "            maxflow = max(maxflow, max(sim_flow_sort[imax])) \n",
    "            minflow = min(minflow, min(sim_flow_sort[imax]))            \n",
    "            maiax.plot(sim_prob, sim_flow_sort, ls='-', lw=2.0, \n",
    "                    c=periods[period]['lc'], label='%s-%s'%(period, scen))\n",
    "\n",
    "    maiax.set_xscale('ppf')\n",
    "    maiax.set_yscale('log')\n",
    "    maiax.set_xlim([0.007, 0.9995])\n",
    "    maiax.set_ylim([minflow*0.95, maxflow*1.05])\n",
    "   #maiax.set_ylim([-10, maxflow*1.05])    \n",
    "    maiax.set_ylabel('Discharge [m3/s]'); maiax.set_xlabel('Non exceedance probability [-]')\n",
    "    maiax.legend(bbox_to_anchor=(0.975,0.975), loc=\"upper right\")\n",
    "    maiax.set_title(f'{gcm_plot} at {site}')\n",
    "    \n",
    "    fig.savefig(os.path.join(figure_path, 'per_site',f'FDC_{gcm_plot}_{scen_plot}_{site}.png'), dpi=100)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ESM ensemble - 3 filled bands for control, 2040s, 2080s) and obs (a dash line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# --- setup\n",
    "ensemble_name = \"cmip6\"\n",
    "site_plot = ds_nrni_selected['site'].values # limit the sites of interest\n",
    "skip_period = []\n",
    "# ---\n",
    "\n",
    "gcm_plots = {gcm: meta['scen'] for gcm, meta in gcm_runs.items() if meta['cmip'] in ensembles[ensemble_name]['cmip'] }\n",
    "num_gcm = len(gcm_plots)\n",
    "\n",
    "for site in site_plot:\n",
    "    \n",
    "    fig, maiax = plt.subplots(1, figsize = (7, 5))\n",
    "    maxflow = 0\n",
    "    minflow = 10**6\n",
    "    obs_prob=np.arange(1,float(len(ds_nrni_selected.sel(time=periods['control']['time'])['time'])+1))/(1+len(ds_nrni_selected.sel(time=periods['control']['time'])['time']))  #probability \n",
    "    obs_flow = ds_nrni_selected['streamflow'].sel(site=site, time=periods['control']['time']).values\n",
    "    #obs_flow = np.where(obs_flow<0.0, 1.0e-7,obs_flow)\n",
    "    obs_flow_sort =  obs_flow[np.argsort(obs_flow)[::-1]]\n",
    "    \n",
    "    imax = np.where(obs_prob<0.9995)\n",
    "    maxflow = max(maxflow, max(obs_flow_sort[imax]))     \n",
    "    minflow = min(minflow, min(obs_flow_sort[imax]))\n",
    "    maiax.plot(obs_prob, obs_flow_sort, linestyle='--', linewidth=1.5, color='black', label='obs', zorder=0)\n",
    "\n",
    "    zorder=6\n",
    "    for period, _ in periods.items(): # go through period from hist, early, mid, late\n",
    "        \n",
    "        # skip periods\n",
    "        if period in skip_period:\n",
    "            continue\n",
    "            \n",
    "        if period=='control':\n",
    "            \n",
    "            for ix, retro in enumerate(retro_names):\n",
    "                sim_flow = ds_qsim_selected[retro]['hist']['streamflow'].sel(site=site, time=periods['control']['time']).values\n",
    "                sim_flow_sort = sim_flow[np.argsort(sim_flow)[::-1]]\n",
    "                sim_prob = np.arange(1,float(len(sim_flow)+1))/(1+len(sim_flow)) #probability\n",
    " \n",
    "                plt.plot(sim_prob, sim_flow_sort, linestyle='-', linewidth=1.0, color='k', label='%s'%(retro), zorder=zorder)\n",
    "                \n",
    "            for ix, gcm in enumerate(list(gcm_plots.keys())):\n",
    "                \n",
    "                sim_flow = ds_qsim_selected[gcm]['hist'].sel(time=periods[period]['time'], site=site)['streamflow'].values\n",
    "                sim_flow_sort = sim_flow[np.argsort(sim_flow)[::-1]]\n",
    "                sim_prob = np.arange(1,float(len(sim_flow)+1))/(1+len(sim_flow)) #probability\n",
    "                \n",
    "                imax = np.where(sim_prob<0.9995)\n",
    "                maxflow = max(maxflow, max(sim_flow_sort[imax])) \n",
    "                minflow = min(minflow, min(sim_flow_sort[imax]))\n",
    "                if ix==0:\n",
    "                    sim_flow_sort_min = sim_flow_sort\n",
    "                    sim_flow_sort_max = sim_flow_sort\n",
    "                else:\n",
    "                    sim_flow_sort_max = np.maximum(sim_flow_sort_max, sim_flow_sort)\n",
    "                    sim_flow_sort_min = np.minimum(sim_flow_sort_min, sim_flow_sort)\n",
    "\n",
    "            plt.fill_between(sim_prob, sim_flow_sort_min, sim_flow_sort_max, alpha=0.4, color=periods[period]['lc'], label=f'{period}', zorder=zorder)\n",
    "        \n",
    "        else:\n",
    "            ix = 0\n",
    "            for gcm, scen_list in gcm_plots.items():\n",
    "                for scen in scen_list:\n",
    "               \n",
    "                    if scen=='hist': # history period is already plotted\n",
    "                        continue\n",
    "                    if scen not in gcm_runs[gcm]['scen']:\n",
    "                        continue\n",
    "                \n",
    "                    sim_flow = ds_qsim_selected[gcm][scen].sel(time=periods[period]['time'], site=site)['streamflow'].values\n",
    "                    sim_flow_sort =  sim_flow[np.argsort(sim_flow)[::-1]]\n",
    "                \n",
    "                    sim_prob = np.arange(1,float(len(sim_flow)+1))/(1+len(sim_flow)) #probability\n",
    "                    \n",
    "                    imax = np.where(sim_prob<0.9995)\n",
    "                    maxflow = max(maxflow, max(sim_flow_sort[imax]))\n",
    "                    minflow = min(minflow, min(sim_flow_sort[imax]))\n",
    "                    if ix==0:\n",
    "                        sim_flow_sort_min = sim_flow_sort\n",
    "                        sim_flow_sort_max = sim_flow_sort\n",
    "                    else:\n",
    "                        sim_flow_sort_max = np.maximum(sim_flow_sort_max, sim_flow_sort)\n",
    "                        sim_flow_sort_min = np.minimum(sim_flow_sort_min, sim_flow_sort)\n",
    "                    \n",
    "                    ix+=1\n",
    "\n",
    "            plt.fill_between(sim_prob, sim_flow_sort_min, sim_flow_sort_max, alpha=0.4, color=periods[period]['lc'], label=f'{period}', zorder=zorder)             \n",
    "\n",
    "        zorder-=1\n",
    "    maiax.tick_params(axis='x', which='major', labelsize=8)    \n",
    "    maiax.set_xscale('ppf')\n",
    "    maiax.set_yscale('log')\n",
    "    maiax.set_xlim([0.003, 0.991])\n",
    "    maiax.set_ylim([minflow*0.95, maxflow*1.05])\n",
    "    maiax.set_ylabel('Discharge [m3/s]'); maiax.set_xlabel('Exceedance probability [-]')\n",
    "    maiax.legend(bbox_to_anchor=(0.975,0.975), loc=\"upper right\")\n",
    "    maiax.set_title(f'ESM ensembles at {site}')\n",
    "    \n",
    "    fig.savefig(os.path.join(figure_path, 'per_site', 'FDC_%s_%s.png'%(ensemble_name, site)), dpi=200)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly seasonal cycle at each site "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESM ensemble - 3 filled bands for control, 2040s, 2080s) and obs (a dash line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# --- setup\n",
    "ensemble_name = \"cmip6-ssp370\"\n",
    "site_plot = ds_nrni_selected['site'].values # limit the sites of interest\n",
    "skip_period = []  # control, 2040s, 2080s, \n",
    "# ---\n",
    "\n",
    "gcm_plots = {gcm:  set(meta['scen']).intersection(ensembles[ensemble_name]['scen']) for gcm, meta in gcm_runs.items() if meta['cmip'] in ensembles[ensemble_name]['cmip'] }\n",
    "month = ['Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep']\n",
    "num_gcm = len(gcm_plots)\n",
    "\n",
    "ls = {'retro':'-',\n",
    "      'control':'-',\n",
    "      '2040s':'--',\n",
    "      '2080s':'--',\n",
    "     }\n",
    "\n",
    "for site in site_plot:\n",
    "    plt.figure(figsize = (7, 5))\n",
    "    \n",
    "    zorder=6\n",
    "    for period, _ in periods.items():\n",
    "        \n",
    "        # skip periods\n",
    "        if period in skip_period:\n",
    "            continue\n",
    "            \n",
    "        if period=='control':\n",
    "                \n",
    "            obs_flow = ds_nrni_selected['streamflow'].sel(site=site, time=periods['control']['time']).groupby(\"time.month\").mean(dim=\"time\").roll(month=3, roll_coords=False).values\n",
    "            plt.plot(month, obs_flow, linestyle='--', linewidth=1.0, color='black', label='obs', zorder=6)\n",
    "                \n",
    "            for ix, retro in enumerate(retro_names):\n",
    "                sim_flow = ds_qsim_selected[retro]['hist']['streamflow'].sel(site=site, time=periods['control']['time']).groupby(\"time.month\").mean(dim=\"time\").roll(month=3, roll_coords=False).values\n",
    "                plt.plot(month, sim_flow, linestyle='-', linewidth=1.0, color='k', label='%s'%(retro), zorder=zorder)\n",
    "            \n",
    "            for ix, gcm in enumerate(list(gcm_plots.keys())):\n",
    "                    \n",
    "                sim_flow = ds_qsim_selected[gcm]['hist']['streamflow'].sel(time=periods[period]['time'], site=site).groupby(\"time.month\").mean(dim=\"time\").roll(month=3, roll_coords=False).values\n",
    "                if ix==0:\n",
    "                    sim_flow_min = sim_flow\n",
    "                    sim_flow_max = sim_flow\n",
    "                else:\n",
    "                    sim_flow_max = np.maximum(sim_flow_max, sim_flow)\n",
    "                    sim_flow_min = np.minimum(sim_flow_min, sim_flow)\n",
    "            zorder -=1        \n",
    "            plt.fill_between(month, sim_flow_min, sim_flow_max, alpha=0.5, color=periods[period]['lc'], label=period, zorder=zorder)\n",
    "\n",
    "        else:\n",
    "            ix = 0\n",
    "            for gcm, scen_list in gcm_plots.items():\n",
    "                for scen in scen_list:\n",
    "                     \n",
    "                    if scen=='hist': # history period is already plotted\n",
    "                        continue\n",
    "                    if scen not in gcm_runs[gcm]['scen']:\n",
    "                        continue\n",
    "                        \n",
    "                    sim_flow = ds_qsim_selected[gcm][scen]['streamflow'].sel(time=periods[period]['time'], site=site).groupby(\"time.month\").mean(dim=\"time\").roll(month=3, roll_coords=False).values\n",
    "                    if num_gcm==1:\n",
    "                        plt.plot(month, sim_flow, linestyle=ls[period], lw=0.75, label='%s'%(scen))\n",
    "                    else:\n",
    "                        if ix==0:\n",
    "                            sim_flow_min = sim_flow\n",
    "                            sim_flow_max = sim_flow\n",
    "                        else:\n",
    "                            sim_flow_max = np.maximum(sim_flow_max, sim_flow)\n",
    "                            sim_flow_min = np.minimum(sim_flow_min, sim_flow)\n",
    "                    ix+=1\n",
    "                            \n",
    "            plt.fill_between(month, sim_flow_min, sim_flow_max, alpha=0.5, color=periods[period]['lc'], label=period, zorder=zorder)    \n",
    "        zorder-=1\n",
    "        \n",
    "    plt.ylabel('Discharge [m3/s]'); plt.xlabel('Month')\n",
    "    plt.legend()\n",
    "    plt.title(f'{site}')\n",
    "    plt.savefig(os.path.join(figure_path, 'per_site','Monthly_cycle_%s_%s.png'%(ensemble_name, site)), dpi=200)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual flood frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESM ensemble - 3 filled bands for control, 2040s, 2080s) and obs (a dash line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### annual flood frequency\n",
    "%matplotlib auto\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# --- setup\n",
    "ensemble_name = \"high-emission\"\n",
    "site_plot = ds_nrni_selected['site'].values # limit the sites of interest\n",
    "skip_period = []\n",
    "# ---\n",
    "\n",
    "gcm_plots = {gcm: meta['scen'] for gcm, meta in gcm_runs.items() if meta['cmip'] in ensembles[ensemble_name]['cmip'] }\n",
    "num_gcm = len(gcm_plots)\n",
    "\n",
    "for site in site_plot:\n",
    "\n",
    "    fig, maiax = plt.subplots(1, figsize = (7, 5))\n",
    "    maxflow = 0\n",
    "    minflow = 1000000\n",
    "    \n",
    "    # skip periods\n",
    "    if period in skip_period:\n",
    "        continue\n",
    "        \n",
    "    period='control'\n",
    "    scen = 'hist'\n",
    "    for ix, gcm in enumerate(list(gcm_plots.keys())):\n",
    "        if ix==0: #plot obs\n",
    "            obs_flow = ds_nrni_selected['streamflow'].sel(site=site, time=slice('1954-10-01','2004-09-30'))\n",
    "            if np.all(~np.isnan(obs_flow)) and np.all(obs_flow!=0):\n",
    "                obs_flow = obs_flow.rolling(time=7).mean()\n",
    "                ann_max_obs = obs_flow.resample(time=\"YS-OCT\").max().values\n",
    "                ann_max_obs_sort =  ann_max_obs[np.argsort(ann_max_obs)]\n",
    "                obs_prob=np.arange(1,float(len(ann_max_obs)+1))/(1+len(ann_max_obs))#*100  #probability \n",
    "                return_period = 1/(1-obs_prob)\n",
    "                plt.plot(return_period, ann_max_obs_sort, linestyle='--', linewidth=2.0, color='black', label='obs', zorder=0)\n",
    "                \n",
    "                imax = np.where((obs_prob<=0.98) & (obs_prob>=0.05))\n",
    "                maxflow = max(maxflow, max(ann_max_obs_sort[imax]))\n",
    "                minflow = min(minflow, min(ann_max_obs_sort[imax]))\n",
    "            \n",
    "        sim_flow = ds_qsim_selected[gcm][scen]['streamflow'].sel(site=site, time=slice('1954-10-01','2004-09-30')).rolling(time=7).mean()\n",
    "        ann_max_sim = sim_flow.resample(time=\"YS-OCT\").max().values # annual maximum series\n",
    "        ann_max_sim_sort = ann_max_sim[np.argsort(ann_max_sim)]\n",
    "        prob=np.arange(1,float(len(ann_max_sim)+1))/(1+len(ann_max_sim))#*100  #probability \n",
    "        return_period = 1/(1-prob)\n",
    "\n",
    "        imax = np.where((prob<=0.98) & (prob>=0.05))\n",
    "        maxflow = max(maxflow, max(ann_max_sim_sort[imax]))\n",
    "        minflow = min(minflow, min(ann_max_sim_sort[imax]))\n",
    "        \n",
    "        if ix==0:\n",
    "            sim_flow_sort_min = ann_max_sim_sort\n",
    "            sim_flow_sort_max = ann_max_sim_sort\n",
    "        else:\n",
    "            sim_flow_sort_max = np.maximum(sim_flow_sort_max, ann_max_sim_sort)\n",
    "            sim_flow_sort_min = np.minimum(sim_flow_sort_min, ann_max_sim_sort)\n",
    "\n",
    "    plt.fill_between(return_period, sim_flow_sort_min, sim_flow_sort_max, alpha=0.45, color=periods[period]['lc'], label=f'1955-2004', zorder=5)\n",
    "\n",
    "    ix = 0\n",
    "    period='2080s'\n",
    "    for gcm, scen_list in gcm_plots.items():\n",
    "        for scen in scen_list:\n",
    "            \n",
    "            if scen=='hist': # history period is already plotted\n",
    "                continue\n",
    "            if scen not in gcm_runs[gcm]['scen']:\n",
    "                continue\n",
    "                \n",
    "            sim_flow = ds_qsim_selected[gcm][scen]['streamflow'].sel(site=site, time=slice('2049-10-01','2099-09-30')).rolling(time=7).mean()\n",
    "            ann_max_sim = sim_flow.resample(time=\"YS-OCT\").max().values\n",
    "            ann_max_sim_sort = ann_max_sim[np.argsort(ann_max_sim)]                \n",
    "            prob=np.arange(1,float(len(ann_max_sim)+1))/(1+len(ann_max_sim))#*100  #probability \n",
    "            return_period = 1/(1-prob)\n",
    "            \n",
    "            imax = np.where((prob<=0.98) & (prob>=0.05))\n",
    "            maxflow = max(maxflow, max(ann_max_sim_sort[imax]))\n",
    "            minflow = min(minflow, min(ann_max_sim_sort[imax]))\n",
    "            \n",
    "            if ix==0:\n",
    "                sim_flow_sort_min = ann_max_sim_sort\n",
    "                sim_flow_sort_max = ann_max_sim_sort\n",
    "            else:\n",
    "                sim_flow_sort_max = np.maximum(sim_flow_sort_max, ann_max_sim_sort)\n",
    "                sim_flow_sort_min = np.minimum(sim_flow_sort_min, ann_max_sim_sort)\n",
    "            \n",
    "            ix+=1\n",
    "        \n",
    "    plt.fill_between(return_period, sim_flow_sort_min, sim_flow_sort_max, alpha=0.45, color=periods[period]['lc'], label=f'2049-2099')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    maiax.set_xscale('log') # ppf\n",
    "    maiax.set_yscale('linear')\n",
    "    plt.xticks([1,10,50],[1,10,50])\n",
    "    plt.xlim([0.95,55])\n",
    "    maiax.set_ylabel('Discharge [m3/s]'); maiax.set_xlabel('Return period [yr]')\n",
    "    maiax.legend(bbox_to_anchor=(0.01,0.975), loc=\"upper left\")\n",
    "    maiax.set_title(f'ESM ensembles at {site}')\n",
    "    fig.savefig(os.path.join(figure_path, 'per_site', f'AFFC_{ensemble_name}_{site}.png'), dpi=200)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
