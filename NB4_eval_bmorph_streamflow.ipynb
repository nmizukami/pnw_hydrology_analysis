{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB4: Analysis of bias corrected streamlfow from SUMMA+mizuRoute forced by retrospective forcing\n",
    "\n",
    "BMORPH bias-correction of retrospective SUMMA+mizuRoute streamflow simulation forced by gmet\n",
    "\n",
    "- training period: 1981-01-01 2000-12-31\n",
    "\n",
    "- BC applying periods: 1970/01-2020/12\n",
    "\n",
    "Analysis periods: control(1980/10-2004/09), and validation(200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import scale as mscale\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from scripts.units import cms2csf\n",
    "from scripts.utility import AutoVivification\n",
    "from scripts.utility import PPFScale\n",
    "mscale.register_scale(PPFScale)\n",
    "import scripts.metrics as metrics\n",
    "import scripts.colors as ccmap\n",
    "from scripts.utility import base_map\n",
    "\n",
    "print(\"\\nThe Python version: %s.%s.%s\" % sys.version_info[:3])\n",
    "print(xr.__name__, xr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create colormap\n",
    "cmap_gmet_control = LinearSegmentedColormap.from_list('custom1', \n",
    "                                             [(0.0, 'xkcd:white'),\n",
    "                                              (1.0, 'xkcd:blue')], N=256)\n",
    "\n",
    "cmap_gmet_bc = LinearSegmentedColormap.from_list('custom4', \n",
    "                                             [(0.0, 'xkcd:white'),\n",
    "                                              (1.0, 'xkcd:cyan')], N=256)\n",
    "\n",
    "cmap_gmet_raw = LinearSegmentedColormap.from_list('custom4', \n",
    "                                             [(0.0, 'xkcd:white'),\n",
    "                                              (1.0, 'xkcd:blue')], N=256)\n",
    "\n",
    "cmap_obs = LinearSegmentedColormap.from_list('custom3', \n",
    "                                             [(0.0, 'xkcd:white'),\n",
    "                                              (1.0, 'xkcd:black')], N=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "main_path  = '/glade/campaign/ral/hap/mizukami/archive/pnw_hydrology/final_archive_v1' # !!! This is top directory of the dataset.\n",
    "geo_path   = os.path.join(main_path, 'ancillary_data','geospatial_data')\n",
    "nrni_path  = os.path.join(main_path, 'ancillary_data')\n",
    "figure_path = 'NB4_figures'\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(figure_path, 'per_site'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retro_runs = {\n",
    "    'GMET':{'case':'GMET_hist'}\n",
    "}\n",
    "\n",
    "periods = {\n",
    "         'valid':   {'time':slice('2001-10-01', '2018-09-30'), 'lc':'xkcd:blue',   'cmap':cmap_gmet_control},\n",
    "         'control': {'time':slice('1980-10-01', '2004-09-30'), 'lc':'xkcd:blue',   'cmap':cmap_gmet_control},\n",
    "}\n",
    "\n",
    "flow_names = {'flow_scbc_u':{'alpha':1, 'legend_name':'SCBC'}, 'flow_raw':{'alpha':0.3, 'legend_name':'raw'}}\n",
    "\n",
    "# xxx_names: list of simulation name\n",
    "retro_names = list(retro_runs.keys())\n",
    "\n",
    "english_unit = False #otherwise flow is in english unit\n",
    "flow_unit='cms'\n",
    "if english_unit:\n",
    "    flow_unit='cfs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 geopackage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_site  = gpd.read_file(os.path.join(geo_path, 'PNW_flow_site.gpkg'))\n",
    "df_reach = gpd.read_file(os.path.join(geo_path, 'rivEndoMERITpfaf_PNW.gpkg'))\n",
    "df_huc12 = gpd.read_file(os.path.join(geo_path, 'HUC12_MERIT_PNW.gpkg'))\n",
    "df_huc12['geometry'] = df_huc12.geometry.simplify(0.05) # simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3. Read bmorph outputs\n",
    "\n",
    "Read mizuRoute output into xarray dataset and put it dictionary ds_route[gcm_case][period]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_bc_flow = AutoVivification()\n",
    "for retro_name in retro_runs.keys():\n",
    "    case = retro_runs[retro_name]['case']\n",
    "    ds_temp = xr.open_mfdataset(os.path.join(main_path, case, f'bmorph_site_univariate_daily.nc'))\n",
    "    print(retro_name)\n",
    "    for period in periods.keys():\n",
    "        ds_bc_flow[retro_name][period] = ds_temp.sel(time=periods[period]['time']).load()\n",
    "    ref_site = ds_bc_flow[retro_name][period].site.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Read Naturalized flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tmp = xr.open_dataset(os.path.join(nrni_path,'PNW_unimpaired_flow_1951-2018_latlon.nc')).sel(site=ref_site)\n",
    "for period in periods.keys():\n",
    "    ds_bc_flow['obs'][period] = ds_tmp.sel(time=periods[period]['time']).load()\n",
    "nrni_site = ds_tmp.site.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing flow metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_seasonal_flow = AutoVivification()\n",
    "for retro in retro_runs.keys():\n",
    "    for period in ds_bc_flow[retro].keys():\n",
    "        for flow_name in flow_names.keys(): \n",
    "            ds_seasonal_flow[retro][period][flow_name] = ds_bc_flow[retro][period][flow_name].groupby('time.dayofyear').mean()\n",
    "for period in periods.keys():\n",
    "   ds_seasonal_flow['obs'][period] = ds_bc_flow['obs'][period]['streamflow'].groupby('time.dayofyear').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_flow_metrics = AutoVivification()\n",
    "    \n",
    "for retro in retro_runs.keys():\n",
    "    for period in ds_bc_flow[retro].keys():\n",
    "        for flow_name in flow_names.keys(): \n",
    "    \n",
    "            ds1 = ds_bc_flow[retro][period][flow_name]\n",
    "                \n",
    "            ds_flow_metrics['annual_max'][retro][period][flow_name]      = metrics.annual_max(ds1.rolling(time=7, center=True).mean())\n",
    "            ds_flow_metrics['annual_min'][retro][period][flow_name]       = metrics.annual_min(ds1.rolling(time=7, center=True).mean())\n",
    "            ds_flow_metrics['ctr'][retro][period][flow_name]              = metrics.annual_centroid(ds1)\n",
    "            #ds_flow_metrics['BFI'][retro][period][flow_name]              = metrics.BFI(ds1)\n",
    "            ds_flow_metrics['FMS'][retro][period][flow_name]              = metrics.FMS(ds1)\n",
    "            ds_flow_metrics['FHV'][retro][period][flow_name]              = metrics.FHV(ds1)\n",
    "            ds_flow_metrics['FLV'][retro][period][flow_name]              = metrics.FLV(ds1)\n",
    "            #ds_flow_metrics['high_q_freq_dur'][retro][period][flow_name] = metrics.high_q_freq_dur(ds1)\n",
    "            #ds_flow_metrics['low_q_freq_dur'][retro][period][flow_name]  = metrics.low_q_freq_dur(ds1)\n",
    "            ds_flow_metrics['season_mean'][retro][period][flow_name]      = metrics.season_mean(ds1)\n",
    "        print(f'{retro}-{period}')\n",
    "\n",
    "for period in periods.keys():\n",
    "    ds1 = ds_bc_flow['obs'][period]['streamflow']\n",
    "                \n",
    "    ds_flow_metrics['annual_max']['obs'][period]      = metrics.annual_max(ds1.rolling(time=7, center=True).mean())\n",
    "    ds_flow_metrics['annual_min']['obs'][period]      = metrics.annual_min(ds1.rolling(time=7, center=True).mean())\n",
    "    ds_flow_metrics['ctr']['obs'][period]              = metrics.annual_centroid(ds1)\n",
    "    #ds_flow_metrics['BFI']['obs'][period]             = metrics.BFI(ds1)\n",
    "    ds_flow_metrics['FMS']['obs'][period]              = metrics.FMS(ds1)\n",
    "    ds_flow_metrics['FHV']['obs'][period]              = metrics.FHV(ds1)\n",
    "    ds_flow_metrics['FLV']['obs'][period]             = metrics.FLV(ds1)\n",
    "    #ds_flow_metrics['high_q_freq_dur']['obs'][period] = metrics.high_q_freq_dur(ds1)\n",
    "    #ds_flow_metrics['low_q_freq_dur']['obs'][period]  = metrics.low_q_freq_dur(ds1)\n",
    "    ds_flow_metrics['season_mean']['obs'][period]      = metrics.season_mean(ds1)\n",
    "    print(f'obs-{period}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error in bias-corrected flow during historical period (1980-2004)\n",
    "\n",
    "- bais at each site\n",
    "- seasonal bias at each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_lists = [\n",
    "    'annual_centroid',\n",
    "    'annual_min_day',\n",
    "    'annual_max_day',\n",
    "    'annual_min_flow',\n",
    "    'annual_max_flow',\n",
    "    'pbiasFHV',\n",
    "    'pbiasFLV',\n",
    "    'mean_high_q_dur',\n",
    "    'freq_high_q',\n",
    "    'alpha',\n",
    "    'beta',\n",
    "    'corr_seas',\n",
    "    'corr',\n",
    "    'kge',\n",
    "    'pbias_djf',\n",
    "    'pbias_mam',\n",
    "    'pbias_jja',\n",
    "    'pbias_son',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist_period = 'control' # 'valid' or 'control'\n",
    "\n",
    "error_metric = {}\n",
    "for metric in metric_lists:\n",
    "    error_metric[metric] = np.zeros((len(ref_site), len(retro_runs.keys()), len(flow_names.keys())))\n",
    "\n",
    "for r, site in enumerate(ref_site):\n",
    "    # nrni\n",
    "    sr_obs = ds_bc_flow['obs'][hist_period]['streamflow'].sel(site=site).values\n",
    "    sr_obs = np.where(sr_obs<0.0, 1.0e-7,sr_obs)\n",
    "\n",
    "    sr_seas_obs = ds_seasonal_flow['obs'][hist_period].sel(site=site).values\n",
    "    \n",
    "    sr_obs_centroid = ds_flow_metrics['ctr']['obs'][hist_period].sel(site=site)['ann_centroid_day'].values\n",
    "    sr_obs_max_day  = ds_flow_metrics['annual_max']['obs'][hist_period].sel(site=site)['ann_max_day'].values\n",
    "    sr_obs_max_flow = ds_flow_metrics['annual_max']['obs'][hist_period].sel(site=site)['ann_max_flow'].values\n",
    "    sr_obs_min_day  = ds_flow_metrics['annual_min']['obs'][hist_period].sel(site=site)['ann_min_day'].values\n",
    "    sr_obs_min_flow = ds_flow_metrics['annual_min']['obs'][hist_period].sel(site=site)['ann_min_flow'].values\n",
    "#    sr_obs_mean_high_q_dur = ds_flow_metrics['high_q_freq_dur']['obs'][hist_period].sel(site=site)['mean_high_q_dur'].values\n",
    "#    sr_obs_freq_high_q     = ds_flow_metrics['high_q_freq_dur']['obs'][hist_period].sel(site=site)['freq_high_q'].values\n",
    "    sr_obs_FHV      = ds_flow_metrics['FHV']['obs'][hist_period].sel(site=site)['FHV'].values\n",
    "    sr_obs_FLV      = ds_flow_metrics['FLV']['obs'][hist_period].sel(site=site)['FLV'].values\n",
    "    sr_obs_djf      = ds_flow_metrics['season_mean']['obs'][hist_period].sel(site=site, season='DJF').values\n",
    "    sr_obs_mam      = ds_flow_metrics['season_mean']['obs'][hist_period].sel(site=site, season='MAM').values\n",
    "    sr_obs_jja      = ds_flow_metrics['season_mean']['obs'][hist_period].sel(site=site, season='JJA').values\n",
    "    sr_obs_son      = ds_flow_metrics['season_mean']['obs'][hist_period].sel(site=site, season='SON').values\n",
    "        \n",
    "    for c, sim_name in enumerate(retro_runs.keys()):# sim_names includes both retro and gcms\n",
    "        for d, flow_name in enumerate(flow_names.keys()): \n",
    "            # simulated flow series\n",
    "            sr_sim = ds_bc_flow[sim_name][hist_period][flow_name].sel(site=site).values\n",
    "            sr_sim = np.where(sr_sim<0.0, 1.0e-7,sr_sim)\n",
    "            \n",
    "            sr_seas_sim = ds_seasonal_flow[sim_name][hist_period][flow_name].sel(site=site).values\n",
    "      \n",
    "            sr_centroid = ds_flow_metrics['ctr'][sim_name][hist_period][flow_name].sel(site=site)['ann_centroid_day'].values\n",
    "            sr_max_day  = ds_flow_metrics['annual_max'][sim_name][hist_period][flow_name].sel(site=site)['ann_max_day'].values\n",
    "            sr_max_flow = ds_flow_metrics['annual_max'][sim_name][hist_period][flow_name].sel(site=site)['ann_max_flow'].values\n",
    "            sr_min_day  = ds_flow_metrics['annual_min'][sim_name][hist_period][flow_name].sel(site=site)['ann_min_day'].values\n",
    "            sr_min_flow = ds_flow_metrics['annual_min'][sim_name][hist_period][flow_name].sel(site=site)['ann_min_flow'].values\n",
    "#            sr_mean_high_q_dur = ds_flow_metrics['high_q_freq_dur'][sim_name][hist_period][flow_name].sel(site=site)['mean_high_q_dur'].values\n",
    "#            sr_freq_high_q     = ds_flow_metrics['high_q_freq_dur'][sim_name][hist_period][flow_name].sel(site=site)['freq_high_q'].values\n",
    "            sr_FHV      = ds_flow_metrics['FHV'][sim_name][hist_period][flow_name].sel(site=site)['FHV'].values\n",
    "            sr_FLV      = ds_flow_metrics['FLV'][sim_name][hist_period][flow_name].sel(site=site)['FLV'].values\n",
    "            sr_djf      = ds_flow_metrics['season_mean'][sim_name][hist_period][flow_name].sel(site=site, season='DJF').values\n",
    "            sr_mam      = ds_flow_metrics['season_mean'][sim_name][hist_period][flow_name].sel(site=site, season='MAM').values\n",
    "            sr_jja      = ds_flow_metrics['season_mean'][sim_name][hist_period][flow_name].sel(site=site, season='JJA').values\n",
    "            sr_son      = ds_flow_metrics['season_mean'][sim_name][hist_period][flow_name].sel(site=site, season='SON').values\n",
    "\n",
    "            # compute error in flow metrics\n",
    "            error_metric['annual_centroid'][r,c,d] = metrics.bias(sr_obs_centroid, sr_centroid)\n",
    "            error_metric['annual_max_day'][r,c,d]  = metrics.bias(sr_obs_max_day, sr_max_day)\n",
    "            error_metric['annual_max_flow'][r,c,d] = metrics.pbias(sr_obs_max_flow, sr_max_flow)*100\n",
    "            error_metric['annual_min_day'][r,c,d]  = metrics.bias(sr_obs_min_day, sr_min_day)\n",
    "            error_metric['annual_min_flow'][r,c,d] = metrics.pbias(sr_obs_min_flow, sr_min_flow)*100\n",
    "#            error_metric['mean_high_q_dur'][r,c,d] = metrics.bias(sr_obs_mean_high_q_dur, sr_mean_high_q_dur)\n",
    "#            error_metric['freq_high_q'][r,c,d]     = metrics.bias(sr_obs_freq_high_q, sr_freq_high_q)\n",
    "            error_metric['pbiasFHV'][r,c,d]        = metrics.pbias(sr_obs_FHV, sr_FHV)*100\n",
    "            error_metric['pbiasFLV'][r,c,d]        = metrics.pbias(sr_obs_FLV, sr_FLV)*100\n",
    "            \n",
    "            error_metric['alpha'][r,c,d] = metrics.alpha(sr_obs, sr_sim)\n",
    "            error_metric['beta'][r,c,d]  = metrics.beta(sr_obs, sr_sim)\n",
    "            error_metric['corr'][r,c,d]  = metrics.corr(sr_obs, sr_sim)\n",
    "            error_metric['kge'][r,c,d]   = metrics.kge(sr_obs, sr_sim)\n",
    "    \n",
    "            error_metric['corr_seas'][r,c,d]  = metrics.corr(sr_seas_obs, sr_seas_sim)\n",
    "            \n",
    "            error_metric['pbias_djf'][r,c,d]  = metrics.pbias(sr_obs_djf, sr_djf)*100\n",
    "            error_metric['pbias_mam'][r,c,d]  = metrics.pbias(sr_obs_mam, sr_mam)*100\n",
    "            error_metric['pbias_jja'][r,c,d]  = metrics.pbias(sr_obs_jja, sr_jja)*100\n",
    "            error_metric['pbias_son'][r,c,d]  = metrics.pbias(sr_obs_son, sr_son)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_lists = [\n",
    "    'annual_centroid',\n",
    "    'annual_min_day',\n",
    "    'annual_max_day',\n",
    "    'annual_min_flow',\n",
    "    'annual_max_flow',\n",
    "    'pbiasFHV',\n",
    "    'pbiasFLV',\n",
    "    'mean_high_q_dur',\n",
    "    'freq_high_q',\n",
    "    'alpha',\n",
    "    'beta',\n",
    "    'corr_seas',\n",
    "    'corr',\n",
    "    'kge',\n",
    "    'pbias_djf',\n",
    "    'pbias_mam',\n",
    "    'pbias_jja',\n",
    "    'pbias_son',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hist_period = 'control' # 'valid' or 'control'\n",
    "\n",
    "error_metric = {}\n",
    "for metric in metric_lists:\n",
    "    error_metric[metric] = np.zeros((len(ref_site), len(retro_runs.keys()), len(flow_names.keys())))\n",
    "\n",
    "for r, site in enumerate(ref_site):\n",
    "    # nrni\n",
    "    sr_obs = ds_bc_flow['obs'][hist_period]['streamflow'].sel(site=site).values\n",
    "    sr_obs = np.where(sr_obs<0.0, 1.0e-7,sr_obs)\n",
    "\n",
    "    sr_seas_obs = ds_seasonal_flow['obs'][hist_period].sel(site=site).values\n",
    "    \n",
    "    sr_obs_centroid = ds_flow_metrics['ctr']['obs'][hist_period].sel(site=site)['ann_centroid_day'].values\n",
    "    sr_obs_max_day  = ds_flow_metrics['annual_max']['obs'][hist_period].sel(site=site)['ann_max_day'].values\n",
    "    sr_obs_max_flow = ds_flow_metrics['annual_max']['obs'][hist_period].sel(site=site)['ann_max_flow'].values\n",
    "    sr_obs_min_day  = ds_flow_metrics['annual_min']['obs'][hist_period].sel(site=site)['ann_min_day'].values\n",
    "    sr_obs_min_flow = ds_flow_metrics['annual_min']['obs'][hist_period].sel(site=site)['ann_min_flow'].values\n",
    "#    sr_obs_mean_high_q_dur = ds_flow_metrics['high_q_freq_dur']['obs'][hist_period].sel(site=site)['mean_high_q_dur'].values\n",
    "#    sr_obs_freq_high_q     = ds_flow_metrics['high_q_freq_dur']['obs'][hist_period].sel(site=site)['freq_high_q'].values\n",
    "    sr_obs_FHV      = ds_flow_metrics['FHV']['obs'][hist_period].sel(site=site)['FHV'].values\n",
    "    sr_obs_FLV      = ds_flow_metrics['FLV']['obs'][hist_period].sel(site=site)['FLV'].values\n",
    "    sr_obs_djf      = ds_flow_metrics['season_mean']['obs'][hist_period].sel(site=site, season='DJF').values\n",
    "    sr_obs_mam      = ds_flow_metrics['season_mean']['obs'][hist_period].sel(site=site, season='MAM').values\n",
    "    sr_obs_jja      = ds_flow_metrics['season_mean']['obs'][hist_period].sel(site=site, season='JJA').values\n",
    "    sr_obs_son      = ds_flow_metrics['season_mean']['obs'][hist_period].sel(site=site, season='SON').values\n",
    "        \n",
    "    for c, sim_name in enumerate(retro_runs.keys()):# sim_names includes both retro and gcms\n",
    "        for d, flow_name in enumerate(flow_names.keys()): \n",
    "            # simulated flow series\n",
    "            sr_sim = ds_bc_flow[sim_name][hist_period][flow_name].sel(site=site).values\n",
    "            sr_sim = np.where(sr_sim<0.0, 1.0e-7,sr_sim)\n",
    "            \n",
    "            sr_seas_sim = ds_seasonal_flow[sim_name][hist_period][flow_name].sel(site=site).values\n",
    "      \n",
    "            sr_centroid = ds_flow_metrics['ctr'][sim_name][hist_period][flow_name].sel(site=site)['ann_centroid_day'].values\n",
    "            sr_max_day  = ds_flow_metrics['annual_max'][sim_name][hist_period][flow_name].sel(site=site)['ann_max_day'].values\n",
    "            sr_max_flow = ds_flow_metrics['annual_max'][sim_name][hist_period][flow_name].sel(site=site)['ann_max_flow'].values\n",
    "            sr_min_day  = ds_flow_metrics['annual_min'][sim_name][hist_period][flow_name].sel(site=site)['ann_min_day'].values\n",
    "            sr_min_flow = ds_flow_metrics['annual_min'][sim_name][hist_period][flow_name].sel(site=site)['ann_min_flow'].values\n",
    "#            sr_mean_high_q_dur = ds_flow_metrics['high_q_freq_dur'][sim_name][hist_period][flow_name].sel(site=site)['mean_high_q_dur'].values\n",
    "#            sr_freq_high_q     = ds_flow_metrics['high_q_freq_dur'][sim_name][hist_period][flow_name].sel(site=site)['freq_high_q'].values\n",
    "            sr_FHV      = ds_flow_metrics['FHV'][sim_name][hist_period][flow_name].sel(site=site)['FHV'].values\n",
    "            sr_FLV      = ds_flow_metrics['FLV'][sim_name][hist_period][flow_name].sel(site=site)['FLV'].values\n",
    "            sr_djf      = ds_flow_metrics['season_mean'][sim_name][hist_period][flow_name].sel(site=site, season='DJF').values\n",
    "            sr_mam      = ds_flow_metrics['season_mean'][sim_name][hist_period][flow_name].sel(site=site, season='MAM').values\n",
    "            sr_jja      = ds_flow_metrics['season_mean'][sim_name][hist_period][flow_name].sel(site=site, season='JJA').values\n",
    "            sr_son      = ds_flow_metrics['season_mean'][sim_name][hist_period][flow_name].sel(site=site, season='SON').values\n",
    "\n",
    "            # compute error in flow metrics\n",
    "            error_metric['annual_centroid'][r,c,d] = metrics.bias(sr_obs_centroid, sr_centroid)\n",
    "            error_metric['annual_max_day'][r,c,d]  = metrics.bias(sr_obs_max_day, sr_max_day)\n",
    "            error_metric['annual_max_flow'][r,c,d] = metrics.pbias(sr_obs_max_flow, sr_max_flow)*100\n",
    "            error_metric['annual_min_day'][r,c,d]  = metrics.bias(sr_obs_min_day, sr_min_day)\n",
    "            error_metric['annual_min_flow'][r,c,d] = metrics.pbias(sr_obs_min_flow, sr_min_flow)*100\n",
    "#            error_metric['mean_high_q_dur'][r,c,d] = metrics.bias(sr_obs_mean_high_q_dur, sr_mean_high_q_dur)\n",
    "#            error_metric['freq_high_q'][r,c,d]     = metrics.bias(sr_obs_freq_high_q, sr_freq_high_q)\n",
    "            error_metric['pbiasFHV'][r,c,d]        = metrics.pbias(sr_obs_FHV, sr_FHV)*100\n",
    "            error_metric['pbiasFLV'][r,c,d]        = metrics.pbias(sr_obs_FLV, sr_FLV)*100\n",
    "            \n",
    "            error_metric['alpha'][r,c,d] = metrics.alpha(sr_obs, sr_sim)\n",
    "            error_metric['beta'][r,c,d]  = metrics.beta(sr_obs, sr_sim)\n",
    "            error_metric['corr'][r,c,d]  = metrics.corr(sr_obs, sr_sim)\n",
    "            error_metric['kge'][r,c,d]   = metrics.kge(sr_obs, sr_sim)\n",
    "    \n",
    "            error_metric['corr_seas'][r,c,d]  = metrics.corr(sr_seas_obs, sr_seas_sim)\n",
    "            \n",
    "            error_metric['pbias_djf'][r,c,d]  = metrics.pbias(sr_obs_djf, sr_djf)*100\n",
    "            error_metric['pbias_mam'][r,c,d]  = metrics.pbias(sr_obs_mam, sr_mam)*100\n",
    "            error_metric['pbias_jja'][r,c,d]  = metrics.pbias(sr_obs_jja, sr_jja)*100\n",
    "            error_metric['pbias_son'][r,c,d]  = metrics.pbias(sr_obs_son, sr_son)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 CDF plots for flow error in flow metrics - all the flow sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "retro = 'GMET'\n",
    "\n",
    "# 4 panel CDFs (alpha, beta, correlation and KGE)\n",
    "fig = plt.figure(figsize=(8.0, 7.0))\n",
    "fig.subplots_adjust(left=0.095,right=0.975,bottom=0.095,top=0.935,wspace=0.25,hspace=0.30)\n",
    "\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax2 = plt.subplot2grid((2, 2), (0, 1))\n",
    "ax3 = plt.subplot2grid((2, 2), (1, 0))\n",
    "ax4 = plt.subplot2grid((2, 2), (1, 1))\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 9 \n",
    "mpl.rcParams['ytick.labelsize'] = 9 \n",
    "mpl.rcParams['axes.labelsize'] = 12 \n",
    "\n",
    "clr=['r','k','b','m','c']\n",
    "lstyle=['-','-','-','-','-']\n",
    "\n",
    "ix_retro = list(retro_runs.keys()).index(retro)\n",
    "\n",
    "#panel a) alpha\n",
    "for c, case in enumerate(flow_names.keys()): # flow_names.keys()\n",
    "    idx = list(flow_names.keys()).index(case)\n",
    "    xdata = error_metric['alpha'][:,ix_retro,idx]\n",
    "    xdata_sort = np.sort(xdata)\n",
    "    prob_metric = np.arange(1,float(len(xdata)+1))/(1+len(xdata))\n",
    "    maxval = 1.1*np.max(xdata)\n",
    "    minval = 0.9*np.min(xdata)\n",
    "    ax1.plot(xdata_sort,prob_metric,c=clr[c],ls=lstyle[c],label=flow_names[case]['legend_name'],linewidth=1.25)\n",
    "    ax1.text(0.02,0.92, 'a)', transform=ax1.transAxes,)\n",
    "lgd = ax1.legend(frameon=True,loc=\"lower right\", handlelength=2, prop={'size':8})\n",
    "lgd.get_frame().set_facecolor('white')\n",
    "ax1.set_xlim(0.0, 2.0) #ratio\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(True)\n",
    "ax1.set_yticks(np.arange(0, 1, 0.25))\n",
    "ax1.set_xlabel(r'$\\alpha$')\n",
    "ax1.set_ylabel('CDF')\n",
    "\n",
    "#panel b) beta\n",
    "for c, case in enumerate(flow_names.keys()):\n",
    "    idx = list(flow_names.keys()).index(case)\n",
    "    xdata = error_metric['beta'][:,ix_retro,idx] #beta_array[:,idx]\n",
    "    xdata_sort = np.sort(xdata)\n",
    "    prob_metric = np.arange(1,float(len(xdata)+1))/(1+len(xdata))\n",
    "    maxval = 1.1*np.max(xdata)\n",
    "    minval = 0.9*np.min(xdata)\n",
    "    ax2.plot(xdata_sort,prob_metric,c=clr[c],ls=lstyle[c],label=case,linewidth=1.25)\n",
    "    ax2.text(0.02,0.92, 'b)', transform=ax2.transAxes,)\n",
    "ax2.set_xlim(0.0, 2.0) #ratio\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True)\n",
    "ax2.set_yticks(np.arange(0, 1, 0.25))\n",
    "ax2.set_xlabel(r'$\\beta$')\n",
    "ax2.set_ylabel('CDF')\n",
    "\n",
    "#panel c) correlation\n",
    "for c, case in enumerate(flow_names.keys()):\n",
    "    idx = list(flow_names.keys()).index(case)\n",
    "    xdata = error_metric['corr'][:,ix_retro,idx] #corr_array[:,idx]\n",
    "    xdata_sort = np.sort(xdata)\n",
    "    prob_metric = np.arange(1,float(len(xdata)+1))/(1+len(xdata))\n",
    "    maxval = 1.1*np.max(xdata)\n",
    "    minval = 0.9*np.min(xdata)\n",
    "    ax3.plot(xdata_sort,prob_metric,c=clr[c],ls=lstyle[c],label=case,linewidth=1.25)\n",
    "    ax3.text(0.02,0.92, 'c)', transform=ax3.transAxes,)\n",
    "ax3.set_xlim(0.0, 1.0) # corr\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.grid(True)\n",
    "ax3.set_yticks(np.arange(0, 1, 0.25))\n",
    "ax3.set_xlabel('Correlation')\n",
    "ax3.set_ylabel('CDF')\n",
    "\n",
    "#panel d) KGE\n",
    "for c, case in enumerate(flow_names.keys()):\n",
    "    idx = list(flow_names.keys()).index(case)\n",
    "    xdata = error_metric['kge'][:,ix_retro,idx] #kge_array[:,idx]\n",
    "    xdata_sort = np.sort(xdata)\n",
    "    prob_metric = np.arange(1,float(len(xdata)+1))/(1+len(xdata))\n",
    "    maxval = 1.1*np.max(xdata)\n",
    "    minval = 0.9*np.min(xdata)\n",
    "    ax4.plot(xdata_sort,prob_metric,c=clr[c],ls=lstyle[c],label=case,linewidth=1.25)\n",
    "    ax4.text(0.02,0.92, 'd)', transform=ax4.transAxes,)\n",
    "ax4.set_xlim(-0.2, 1.0)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.grid(True)\n",
    "ax4.set_yticks(np.arange(0, 1, 0.25))\n",
    "ax4.set_xlabel('KGE\\'')\n",
    "ax4.set_ylabel('CDF');\n",
    "\n",
    "plt.savefig(os.path.join(figure_path,'Fig1_KGE_cdf_bmorph_%s.png'%(hist_period)), dpi=300, bbox_extra_artists=(lgd,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2  Map of at-site error metrics for historical period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "retro = 'GMET'\n",
    "\n",
    "ix_sim = list(retro_runs.keys()).index(retro)\n",
    "\n",
    "metric_dic = {\n",
    "    'alpha': {'cmap': ccmap.cmap2, 'norm':ccmap.norm2, 'header':r'$\\alpha$'},\n",
    "    'beta':  {'cmap': ccmap.cmap2, 'norm':ccmap.norm2, 'header':r'$\\beta$'},\n",
    "    'corr':  {'cmap': ccmap.cmap3, 'norm':ccmap.norm3, 'header':'r'},\n",
    "}\n",
    "\n",
    "flow_type = {\n",
    "    'flow_raw':{'header':'orig flow'},\n",
    "    'flow_scbc_u':{'header':'scbc flow'},\n",
    "}\n",
    "        \n",
    "fig, axs = plt.subplots(nrows=len(metric_dic), ncols=len(flow_type), figsize=(6.0, 7.5), \n",
    "                        subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100)\n",
    "plt.subplots_adjust(left=0.01, bottom=0.01, right=0.9, top=0.925, wspace=0.02)\n",
    "\n",
    "for ix, (metric, meta) in enumerate(metric_dic.items()):\n",
    "    for jx, (bc_type, ftyp_meta) in enumerate(flow_type.items()):\n",
    "\n",
    "        df_metric= pd.DataFrame(data=error_metric[metric][:,ix_sim,:], index=ref_site, columns=list(flow_names.keys()))\n",
    "        df_metric.reset_index(level=0, inplace=True)\n",
    "        df_metric.rename(columns={'index':'location_name'},inplace=True)\n",
    "        df_metric_final = df_site.merge(df_metric, on=\"location_name\", how = 'inner')\n",
    "\n",
    "        base_map(axs[ix,jx], df_huc12)\n",
    "        df_metric_final.plot(ax=axs[ix,jx], markersize=10, cmap=meta['cmap'], norm=meta['norm'], column=bc_type, legend=False)\n",
    "        axs[ix,jx].set_title('%s: %s'%(meta['header'],ftyp_meta['header']))\n",
    "\n",
    "        if ix==0:\n",
    "            axs[ix,jx].add_patch(mpl.patches.Rectangle((-124.1, 43.25), 2.20, 2.45,\n",
    "                                                edgecolor='k',facecolor='None',lw=0.7)); # Willamette\n",
    "            axs[ix,jx].text(-122.3, 42.8, 'Willamette', fontsize=6)\n",
    "            axs[ix,jx].add_patch(mpl.patches.Ellipse((-121.7, 47.2), 1.8, 1.9,\n",
    "                                              edgecolor='k',facecolor='None',lw=0.7)); # Eastern Cascade\n",
    "            axs[ix,jx].text(-121.1, 47.9, 'Cascade', rotation=35, fontsize=6)                                                             \n",
    "            axs[ix,jx].add_patch(mpl.patches.Rectangle((-117.5, 42.2), 7.25, 2.9,\n",
    "                                             edgecolor='k',facecolor='None',lw=0.7)); # Snake\n",
    "            axs[ix,jx].text(-117.5, 41.7, 'Snake', fontsize=6)\n",
    "        if ix==1:\n",
    "            axs[ix,jx].add_patch(mpl.patches.Rectangle((-122.1, 43.2), 1.7, 2.0,\n",
    "                                                edgecolor='k',facecolor='None',lw=0.7)); # Deschutes\n",
    "            axs[ix,jx].text(-121.0, 42.6, 'Deschutes', fontsize=6)\n",
    "       \n",
    "    # add colorbar\n",
    "    fig1 = axs[ix,jx].get_figure()\n",
    "    sm = plt.cm.ScalarMappable(cmap=meta['cmap'], norm=meta['norm'])\n",
    "    # fake up the array of the scalar mappable. Urgh...\n",
    "    sm._A = []\n",
    "    fig.colorbar(sm, ax=axs[ix,jx], extend='both');\n",
    "\n",
    "fig.savefig(os.path.join(figure_path, f'Fig2_historical_metric_error_map_{retro}_{hist_period}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monthly seasonal cycle at each site <a id='seasonal_cycle'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. one or more bc_types and obs per period\n",
    "bc_type: 'raw', 'ibc', 'scbc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# --- setup\n",
    "retro = 'GMET'\n",
    "skip_period = []\n",
    "skip_bc_type = []  # 'raw','ibc', 'scbc'\n",
    "hist_period = 'valid'\n",
    "# ---\n",
    "\n",
    "month = ['Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep']\n",
    "\n",
    "for site in ref_site:\n",
    "    plt.figure(figsize = (7, 5))\n",
    "    obs_flow_plot=False\n",
    "\n",
    "    plot_title = f'{retro}_{hist_period}'\n",
    "        \n",
    "    # retrospective obs run -\n",
    "    obs_flow = ds_bc_flow['obs'][hist_period]['streamflow'].sel(site=site).groupby(\"time.month\").mean(dim=\"time\").roll(month=3, roll_coords=False).values\n",
    "    plt.plot(month, obs_flow, linestyle='--', linewidth=2.0, color='black', label='obs', zorder=0)\n",
    "        \n",
    "    if 'raw' not in skip_bc_type:\n",
    "        sim_flow = ds_bc_flow[retro][hist_period]['flow_raw'].sel(site=site).groupby(\"time.month\").mean(dim=\"time\").roll(month=3, roll_coords=False).values\n",
    "        plt.plot(month, sim_flow, ls=':', c=periods['control']['lc'], lw=1.25, label='%s raw'%(retro), zorder=0)\n",
    "        \n",
    "    if 'scbc' not in skip_bc_type:  \n",
    "        sim_flow = ds_bc_flow[retro][hist_period]['flow_scbc_u'].sel(site=site).groupby(\"time.month\").mean(dim=\"time\").roll(month=3, roll_coords=False).values\n",
    "        plt.plot(month, sim_flow, ls='-', c=periods['control']['lc'], lw=1.25, label='%s scbc'%(retro))\n",
    "        \n",
    "    if 'ibc' not in skip_bc_type:\n",
    "        sim_flow = ds_bc_flow[retro][hist_period]['flow_ibc_u'].sel(site=site).groupby(\"time.month\").mean(dim=\"time\").roll(month=3, roll_coords=False).values\n",
    "        plt.plot(month, sim_flow, ls='-.', c=periods['control']['lc'], lw=1.25, label='%s ibc'%(retro))    \n",
    "\n",
    "    plt.ylabel('Discharge [m3/s]'); plt.xlabel('Month')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.title(f'{plot_title} at {site}')\n",
    "    \n",
    "    plt.savefig(os.path.join(figure_path, 'per_site','Fig1_bc_monthly_cycle_%s_%s.png'%(plot_title, site)), dpi=200)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
