{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NB7 naturalized flow analysis over PNW\n",
    "\n",
    "- check data availability\n",
    "- basic flow time series check (long term seasonality and daily series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import os, sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from timeit import default_timer as timer\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import scripts.colors as ccmap\n",
    "from scripts.utility import AutoVivification\n",
    "import scripts.metrics as metrics\n",
    "from scripts.utility import base_map\n",
    "\n",
    "print(\"\\nThe Python version: %s.%s.%s\" % sys.version_info[:3])\n",
    "print(xr.__name__, xr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_start_length(dr: xr.DataArray,  dayofyear='wateryear'):\n",
    "    \"\"\"\n",
    "    Calculates day of year when valid data start and length of data.\n",
    "    Arguments\n",
    "    ---------\n",
    "    dr: xr.DataArray\n",
    "        2D DataArray containing daily time series with coordinates of 'site', and 'time'\n",
    "    Returns\n",
    "    -------\n",
    "    ds_ann_max: xr.Dataset\n",
    "        Dataset containing two 2D DataArrays 'flow_len' and 'flow_start' with coordinate of 'year', and 'site'\n",
    "    Notes\n",
    "    -------\n",
    "    dayofyear start with October 1st with dayofyear=\"wateryear\" or January 1st with dayofyear=\"calendar\".\n",
    "    \"\"\"\n",
    "    \n",
    "    dayofyear='wateryear'\n",
    "    if dayofyear=='wateryear':\n",
    "        smon=10; sday=1; emon=9; eday=30; yr_adj=1\n",
    "    elif dayofyear=='calendar':\n",
    "        smon=1; sday=1; emon=12; eday=31; yr_adj=0\n",
    "    else:\n",
    "        raise ValueError('Invalid argument for \"dayofyear\"')\n",
    "\n",
    "    years = np.unique(dr.time.dt.year.values)[:-1]\n",
    "\n",
    "    ds_flow_data = xr.Dataset(data_vars=dict(\n",
    "                    flow_len   =([\"year\", \"site\"], np.full((len(years),len(dr['site'])), np.nan, dtype='float32')),\n",
    "                    flow_start =([\"year\", \"site\"], np.full((len(years),len(dr['site'])), np.nan, dtype='float32')),\n",
    "                    ),\n",
    "                    coords=dict(year=years,\n",
    "                                site=dr['site'],),\n",
    "                    )\n",
    "\n",
    "    t_axis = dr.dims.index('time')\n",
    "\n",
    "    for yr in years:\n",
    "        time_slice=slice(f'{yr}-{smon}-{sday}',f'{yr+yr_adj}-{emon}-{eday}')\n",
    "        data_array = dr.sel(time=time_slice).values\n",
    "        for sidx, site in enumerate(dr['site'].values):\n",
    "            binary_array = np.where(~np.isnan(data_array[:,sidx]), 1, 0)\n",
    "            count_dups = metrics.myCount(binary_array)\n",
    "            if not count_dups:\n",
    "                ds_flow_data['flow_len'].loc[yr, site] = 0\n",
    "                ds_flow_data['flow_start'].loc[yr, site] = 0\n",
    "            else:\n",
    "                ds_flow_data['flow_len'].loc[yr, site] = np.sum(count_dups)\n",
    "                ds_flow_data['flow_start'].loc[yr, site] = np.where(binary_array==1)[0][0]+1 # used to np.sum\n",
    "    return ds_flow_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "main_path  = '/glade/campaign/ral/hap/mizukami/archive/pnw_hydrology/final_archive_v1' # !!! This is top directory of the dataset.\n",
    "geo_path   = os.path.join(main_path, 'ancillary_data','geospatial_data')\n",
    "nrni_path  = os.path.join(main_path, 'ancillary_data')\n",
    "figure_path = 'MB7_figures'\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(figure_path, 'per_site'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 geopackage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_huc12 = gpd.read_file(os.path.join(geo_path, 'HUC12_MERIT_PNW.gpkg'))\n",
    "df_huc12['geometry'] = df_huc12.geometry.simplify(0.05) # simplified\n",
    "df_site  = gpd.read_file(os.path.join(geo_path, 'PNW_flow_site.gpkg'))\n",
    "df_site = df_site[df_site['removed']==0]\n",
    "df_site = df_site.set_index('location_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Read naturalized flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nrni = xr.open_dataset(os.path.join(nrni_path,'PNW_unimpaired_flow_1951-2018_latlon.nc'))\n",
    "nrni_site = ds_nrni.site.values\n",
    "print('Number of flow sites: %d'%len(nrni_site))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. availability of data record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = df_site.index.values \n",
    "for loc_name in ds_nrni['site'].values: # there are 331 sites\n",
    "    if loc_name not in sites:\n",
    "        print(loc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals4=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70] \n",
    "cmap4 = plt.get_cmap('plasma_r', (16))\n",
    "cmap4.set_over('xkcd:dark blue')\n",
    "cmap4.set_under('xkcd:light yellow')\n",
    "norm4 = mpl.colors.BoundaryNorm(vals4, cmap4.N)\n",
    "\n",
    "vals6=[1950, 1955, 1960, 1965, 1970, 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010] \n",
    "cmap6 = plt.get_cmap('plasma', (14))\n",
    "cmap6.set_over('xkcd:dark blue')\n",
    "cmap6.set_under('xkcd:light yellow')\n",
    "norm6 = mpl.colors.BoundaryNorm(vals6, cmap6.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impaired_flow=ds_nrni['streamflow']\n",
    "#count = impaired_flow.where(~np.isnan(impaired_flow)).groupby('time.year').count(dim='time')\n",
    "#nyr_data = count.where(count>364).count(dim='year')\n",
    "ds_flow_len = flow_start_length(impaired_flow)\n",
    "\n",
    "years = ds_flow_len.year.values\n",
    "ds1 = xr.Dataset(data_vars=dict(\n",
    "                flow_len_yr   =([\"site\"], np.full(len(ds_flow_len['site']), np.nan, dtype='int')),\n",
    "                flow_start_yr =([\"site\"], np.full(len(ds_flow_len['site']), np.nan, dtype='int')),\n",
    "                ),\n",
    "                coords=dict(site=ds_flow_len['site'],),\n",
    "                )\n",
    "for sidx, site in enumerate(ds_flow_len['site'].values):\n",
    "    array1 = ds_flow_len['flow_len'].sel(site=site)\n",
    "    binary_array = np.where(array1>364, 1, 0)\n",
    "    #count_dups = myCount(binary_array)\n",
    "\n",
    "    valid_yr = np.where(binary_array==1)[0]\n",
    "    valid_yr_lists = consecutive(valid_yr)\n",
    "    length_yr=0\n",
    "    for valid_yr_list in valid_yr_lists:\n",
    "        if len(valid_yr_list)>length_yr:\n",
    "            length_yr=len(valid_yr_list)\n",
    "            first_yr= years[valid_yr_list[0]]\n",
    "    \n",
    "    if length_yr==0:\n",
    "        ds1['flow_len_yr'].loc[site] = 0\n",
    "        ds1['flow_start_yr'].loc[site] = 0\n",
    "    else:\n",
    "        #ix = np.argmax(count_dups)\n",
    "        #first_yr = years[np.where(binary_array==1)[0][0]]\n",
    "        ds1['flow_len_yr'].loc[site] = length_yr #count_dups[ix]\n",
    "        ds1['flow_start_yr'].loc[site] = first_yr# used to np.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Map of number of years with valid daily data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyr_data = ds1.to_dataframe()\n",
    "df_nyr_data.index.rename('location_name',inplace=True)\n",
    "df_final = df_site.merge(df_nyr_data, on=\"location_name\", how = 'inner')\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=2, figsize=(9.5, 4), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100,)\n",
    "fig.subplots_adjust(left=0.025, bottom=0.025, right=0.965, top=0.95, wspace=0.10, hspace=0.125)\n",
    "\n",
    "base_map(ax1[0], df_huc12)\n",
    "df_final.plot(ax=ax1[0], column='flow_start_yr', markersize=15, cmap=cmap6, norm=norm6, legend=True, legend_kwds={'extend':'neither', 'pad':0.02});\n",
    "ax1[0].set_extent([-125, -110, 41.5, 52.5])\n",
    "ax1[0].set_title('start year of consecutive valid daily data', fontsize=9)\n",
    "\n",
    "base_map(ax1[1], df_huc12)\n",
    "df_final.plot(ax=ax1[1], column='flow_len_yr', markersize=15, cmap=cmap4, norm=norm4, legend=True, legend_kwds={'extend':'neither', 'pad':0.02});\n",
    "ax1[1].set_extent([-125, -110, 41.5, 52.5])\n",
    "ax1[1].set_title('consecutive years with complete valid daily data', fontsize=9)\n",
    "\n",
    "fig.savefig(os.path.join(figure_path, f'Fig_nyr_valid_nat_flow.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time series during the calibration periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "start_date = '1980-10-01'\n",
    "end_date   = '2004-09-30'\n",
    "\n",
    "for site, data in df_site.iterrows():\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(7.5, 6.5))\n",
    "    if site not in impaired_flow['site'].values:\n",
    "        continue\n",
    "    impaired_flow.sel(site=site).sel(time=slice(start_date,end_date)).plot(ax=ax[0], color='k', linewidth=0.8, label='daily nat. flow')\n",
    "    ax[0].set_ylabel('streamflow [m3/s]')\n",
    "    ax[0].set_xlabel('')\n",
    "    ax[0].legend();\n",
    "    impaired_flow.sel(site=site).sel(time=slice(start_date,end_date)).groupby(\"time.dayofyear\").mean().roll(dayofyear=92, roll_coords=False).plot(ax=ax[1], color='k', linewidth=0.8, label='nat. flow')\n",
    "    ax[1].set_title('')\n",
    "    ax[1].set_ylabel('streamflow [m3/s]')\n",
    "    ax[1].set_xlabel('day since Oct 1st')\n",
    "    fig.savefig(os.path.join(figure_path, 'per_site','nat_flow_%s_%s_%s.png'%(site, start_date, end_date)), dpi=100)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
