{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NB1 Evaluation of retrospective streamflow simulation at naturalized flow sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import scale as mscale\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy\n",
    "\n",
    "from scripts.units import cms2csf\n",
    "from scripts.utility import AutoVivification\n",
    "from scripts.utility import PPFScale\n",
    "mscale.register_scale(PPFScale)\n",
    "import scripts.metrics as metrics\n",
    "import scripts.colors as color\n",
    "from scripts.utility import base_map\n",
    "\n",
    "print(\"\\nThe Python version: %s.%s.%s\" % sys.version_info[:3])\n",
    "print(xr.__name__, xr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dataset(ds, siteID):\n",
    "    # extract the reachID orders\n",
    "    x = ds['site'].values\n",
    "    # Find the indices of the reordered array\n",
    "    # From: https://stackoverflow.com/questions/8251541/numpy-for-every-element-in-one-array-find-the-index-in-another-array\n",
    "    index = np.argsort(x)\n",
    "    sorted_x = x[index]\n",
    "    sorted_index = np.searchsorted(sorted_x, siteID)\n",
    "\n",
    "    remap_order = np.take(index, sorted_index, mode=\"clip\")\n",
    "\n",
    "    # Reorder pio according to the orginal\n",
    "    return ds.isel(dict(site=remap_order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "main_path  = '/glade/campaign/ral/hap/mizukami/archive/pnw_hydrology/final_archive_v1' # !!! This is top directory of the dataset.\n",
    "geo_path   = os.path.join(main_path, 'ancillary_data','geospatial_data')\n",
    "nrni_path  = os.path.join(main_path, 'ancillary_data')\n",
    "figure_path = 'NB1_figures'\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "os.makedirs(os.path.join(figure_path, 'per_site'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for time series\n",
    "cal_period = slice('1991-10-01', '2001-09-30')\n",
    "val_period = slice('2001-10-01', '2010-09-30')\n",
    "\n",
    "# for skill metrics computation\n",
    "analysis_period = val_period #slice('1971-10-01', '2010-09-30')\n",
    "\n",
    "ds_sim = {}\n",
    "case_meta = {\n",
    "    'GMET': {'label':'SUMMA-mizuRoute', 'color':'red'},\n",
    "}\n",
    "\n",
    "sim_case = list(case_meta.keys())\n",
    "all_case = sim_case+['obs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 geospatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 SUMMA HRU (gpkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_huc12 = gpd.read_file(os.path.join(geo_path, 'HUC12_MERIT_PNW.gpkg'))\n",
    "df_huc12['geometry'] = df_huc12.geometry.simplify(0.01) # simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Naturalized flow site (gpkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_site = gpd.read_file(os.path.join(geo_path, 'PNW_flow_site.gpkg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Link between river network reach ID and site name\n",
    "reach id co-located with flow site has less probably because some reach has more than one sites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merit_id = pd.read_csv(os.path.join(geo_path, 'PNW_flow_site.csv'))\n",
    "df_merit_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Naturalized flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nrni = xr.open_dataset(os.path.join(nrni_path,'PNW_unimpaired_flow_1951-2018_latlon.nc'))\n",
    "nrni_site = ds_nrni.site.values\n",
    "print('Number of nrni sites: %d'%len(nrni_site))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Read retrospective SUMMA simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_summa = {}\n",
    "for case,_ in case_meta.items():\n",
    "    nclist=glob.glob(os.path.join(main_path, f'{case}_hist', 'mizuRoute_daily_site.nc'))\n",
    "    ds_summa[case] = xr.open_mfdataset(nclist).load()\n",
    "    ds_summa[case] = ds_summa[case].assign_coords(seg=ds_summa[case]['site'])\n",
    "    ds_summa[case] = ds_summa[case].drop_vars('site')\n",
    "    ds_summa[case] = ds_summa[case].rename({'seg':'site'})\n",
    "flow_site = ds_summa[case].site.values\n",
    "print('Number of SUMMA sites: %d'%len(ds_summa[case].reachID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reformat xarray dataset to panda dataframe\n",
    "Find site where naturalized flow exist (summa site has all the sites in the meta data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common site between summa site (include all the sites) and nrni_site (site from naturalized flow data)\n",
    "common_site = np.asarray(list(set(flow_site).intersection(nrni_site)))\n",
    "num_site = len(common_site)\n",
    "common_site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select common sites only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow site meta dataframe\n",
    "df_site_selected = df_site.loc[df_site['location_name'].isin(common_site)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select common sites from NRNI data\n",
    "ds_nrni_selected = ds_nrni.where(ds_nrni.site.isin(common_site), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select common sites from VIC data\n",
    "ds_sim_selected = {}\n",
    "for case in sim_case:\n",
    "    ds_sim_selected[case] = ds_sim[case].where(ds_sim[case].site.isin(common_site), drop=True)\n",
    "    # March order of site with order of NRNI data\n",
    "    ds_sim_selected[case] = reorder_dataset(ds_sim_selected[case], ds_nrni_selected.site.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance metrics for all the common sites - SUMMA vs unimpaird flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute skill metrics based on daily data (VIC vs NRNI and SUMMA vs NRNI)\n",
    "prob=np.arange(1,float(len(ds_nrni_selected['time'].sel(time=analysis_period))+1))/(1+len(ds_nrni_selected['time'].sel(time=analysis_period))) #probability\n",
    "for d in range(len(prob)):\n",
    "    idx50=d\n",
    "    if prob[d] > 0.5: break\n",
    "for d in range(len(prob)):\n",
    "    idx10=d\n",
    "    if prob[d] > 0.1: break\n",
    "for d in range(len(prob)):\n",
    "    idx90=d\n",
    "    if prob[d] > 0.9: break\n",
    "for d in range(len(prob)):\n",
    "    idx98=d\n",
    "    if prob[d] > 0.98: break\n",
    "\n",
    "alpha_array = np.zeros((num_site, len(sim_case)))\n",
    "beta_array  = np.zeros((num_site, len(sim_case)))\n",
    "corr_array  = np.zeros((num_site, len(sim_case)))\n",
    "kge_array   = np.zeros((num_site, len(sim_case)))\n",
    "pbiasFHV90_array = np.zeros((num_site, len(sim_case)))\n",
    "pbiasFHV98_array = np.zeros((num_site, len(sim_case)))\n",
    "pbiasFLV10_array = np.zeros((num_site, len(sim_case)))\n",
    "\n",
    "for r, site in enumerate(common_site):\n",
    "    for c, case in enumerate(sim_case): \n",
    "        sr_sim = ds_sim_selected[case].sel(time=analysis_period).sel(site=site)['streamflow'].values\n",
    "        sr_sim = np.where(sr_sim<0.0, 1.0e-7,sr_sim)\n",
    "        sr_sim_sort = np.sort(sr_sim)\n",
    "        if c == 0:\n",
    "            sr_obs = ds_nrni_selected.sel(time=analysis_period).sel(site=site)['streamflow'].values\n",
    "            sr_obs = np.where(sr_obs<0.0, 1.0e-7,sr_obs)\n",
    "            sr_obs_sort =  np.sort(sr_obs)\n",
    "            #qthresh90 = np.percentile(sr_obs, 90)\n",
    "\n",
    "        alpha_array[r,c] = metrics.alpha(sr_obs, sr_sim)\n",
    "        beta_array[r,c]  = metrics.beta(sr_obs, sr_sim)\n",
    "        corr_array[r,c]  = metrics.corr(sr_obs, sr_sim)\n",
    "        kge_array[r,c]   = metrics.kge(sr_obs, sr_sim)\n",
    "        #pbias90_array[r,c]    = metrics.pbias(sr_obs[sr_obs>qthresh90], sr_sim[sr_obs>qthresh90])*100\n",
    "        pbiasFHV98_array[r,c] = metrics.pbias(sr_obs_sort[idx98:], sr_sim_sort[idx98:])*100\n",
    "        pbiasFHV90_array[r,c] = metrics.pbias(sr_obs_sort[idx90:], sr_sim_sort[idx90:])*100\n",
    "        pbiasFLV10_array[r,c] = metrics.pbias(sr_obs_sort[:idx10], sr_sim_sort[:idx10])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 CDF plots for flow performance statistics - all the flow sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# 4 panel CDFs (alpha, beta, correlation and KGE)\n",
    "fig = plt.figure(figsize=(8.0, 7.0))\n",
    "fig.subplots_adjust(left=0.095,right=0.975,bottom=0.095,top=0.935,wspace=0.25,hspace=0.30)\n",
    "\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax2 = plt.subplot2grid((2, 2), (0, 1))\n",
    "ax3 = plt.subplot2grid((2, 2), (1, 0))\n",
    "ax4 = plt.subplot2grid((2, 2), (1, 1))\n",
    "\n",
    "ax1.tick_params(labelsize=8)\n",
    "ax2.tick_params(labelsize=8)\n",
    "ax3.tick_params(labelsize=8)\n",
    "ax4.tick_params(labelsize=8)\n",
    "\n",
    "clr=['k','r','b','m','c']\n",
    "lstyle=['-','-','-','-','-']\n",
    "\n",
    "plot_case = sim_case\n",
    "\n",
    "#panel a) alpha\n",
    "for c, case in enumerate(plot_case):\n",
    "    idx = sim_case.index(case)\n",
    "    xdata = alpha_array[:,idx]\n",
    "    xdata_sort = np.sort(xdata)\n",
    "    prob_metric = np.arange(1,float(len(xdata)+1))/(1+len(xdata))\n",
    "    maxval = 1.1*np.max(xdata)\n",
    "    minval = 0.9*np.min(xdata)\n",
    "    ax1.plot(xdata_sort,prob_metric,c=clr[c],ls=lstyle[c],label=case_meta[case]['label'],linewidth=1.25)\n",
    "lgd = ax1.legend(frameon=True,loc=\"best\", handlelength=2, prop={'size':8})\n",
    "lgd.get_frame().set_facecolor('white')\n",
    "ax1.set_xlim(0.0, 2.0) #ratio\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(True)\n",
    "ax1.set_yticks(np.arange(0, 1, 0.25))\n",
    "ax1.set_xlabel(r'$\\frac{\\sigma_{sim}}{\\sigma_{obs}}$')\n",
    "ax1.set_ylabel('CDF')\n",
    "\n",
    "#panel b) beta\n",
    "for c, case in enumerate(plot_case):\n",
    "    idx = sim_case.index(case)\n",
    "    xdata = beta_array[:,idx]\n",
    "    xdata_sort = np.sort(xdata)\n",
    "    prob_metric = np.arange(1,float(len(xdata)+1))/(1+len(xdata))\n",
    "    maxval = 1.1*np.max(xdata)\n",
    "    minval = 0.9*np.min(xdata)\n",
    "    ax2.plot(xdata_sort,prob_metric,c=clr[c],ls=lstyle[c],label=case,linewidth=1.25)\n",
    "ax2.set_xlim(0.0, 2.0) #ratio\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True)\n",
    "ax2.set_yticks(np.arange(0, 1, 0.25))\n",
    "ax2.set_xlabel(r'$\\frac{\\mu_{sim}}{\\mu_{obs}}$')\n",
    "ax2.set_ylabel('CDF')\n",
    "\n",
    "#panel c) correlation\n",
    "for c, case in enumerate(plot_case):\n",
    "    idx = sim_case.index(case)\n",
    "    xdata = corr_array[:,idx]\n",
    "    xdata_sort = np.sort(xdata)\n",
    "    prob_metric = np.arange(1,float(len(xdata)+1))/(1+len(xdata))\n",
    "    maxval = 1.1*np.max(xdata)\n",
    "    minval = 0.9*np.min(xdata)\n",
    "    ax3.plot(xdata_sort,prob_metric,c=clr[c],ls=lstyle[c],label=case,linewidth=1.25)\n",
    "ax3.set_xlim(0.0, 1.0) # corr\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.grid(True)\n",
    "ax3.set_yticks(np.arange(0, 1, 0.25))\n",
    "ax3.set_xlabel('Correlation')\n",
    "ax3.set_ylabel('CDF')\n",
    "\n",
    "#panel d) KGE\n",
    "for c, case in enumerate(plot_case):\n",
    "    idx = sim_case.index(case)\n",
    "    xdata = kge_array[:,idx]\n",
    "    xdata_sort = np.sort(xdata)\n",
    "    prob_metric = np.arange(1,float(len(xdata)+1))/(1+len(xdata))\n",
    "    maxval = 1.1*np.max(xdata)\n",
    "    minval = 0.9*np.min(xdata)\n",
    "    ax4.plot(xdata_sort,prob_metric,c=clr[c],ls=lstyle[c],label=case,linewidth=1.25)\n",
    "ax4.set_xlim(-0.2, 1.0)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.grid(True)\n",
    "ax4.set_yticks(np.arange(0, 1, 0.25))\n",
    "ax4.set_xlabel('KGE')\n",
    "ax4.set_ylabel('CDF');\n",
    "\n",
    "plt.savefig(os.path.join(figure_path, 'fig1_KGE_cdf.png'), dpi=300, bbox_extra_artists=(lgd,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 PDF plots for high/low flow metrics - all the flow sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF high flow bias\n",
    "plot_case = sim_case\n",
    "fig, ax = plt.subplots(2,1, figsize=(6.0, 6.0), dpi=150)\n",
    "plt.subplots_adjust(left=0.015, bottom=0.015, right=0.975, top=0.96, hspace=0.25, wspace=0.1)\n",
    "\n",
    "clr=['k','r','b','m','c']\n",
    "lstyle=['-','-','-','-','-']\n",
    "\n",
    "for c, case in enumerate(plot_case):\n",
    "    idx = sim_case.index(case)\n",
    "    y, x = np.histogram(pbiasFHV90_array[:,idx], bins = np.arange(-100, 110, 10), density=False)\n",
    "    ax[0].plot(x[:-1], y, c=clr[c],ls=lstyle[c],label=case_meta[case]['label'],linewidth=1.25)\n",
    "    \n",
    "ax[0].axvline(x = 0, color = 'k', ls='--',lw=0.5, label = '')\n",
    "lgd = ax[0].legend(frameon=True,loc=\"best\", handlelength=2, prop={'size':8})\n",
    "lgd.get_frame().set_facecolor('white')\n",
    "ax[0].set_xlim(-105, 105) #ratio\n",
    "ax[0].set_ylim(0, 50)\n",
    "ax[0].set_xlabel(r'bias FDC>90%')\n",
    "ax[0].set_ylabel('count');\n",
    "\n",
    "for c, case in enumerate(plot_case):\n",
    "    idx = sim_case.index(case)\n",
    "    y, x = np.histogram(pbiasFHV98_array[:,idx], bins = np.arange(-100, 110, 10), density=False)\n",
    "    ax[1].plot(x[:-1], y, c=clr[c],ls=lstyle[c],label=case_meta[case]['label'],linewidth=1.25)\n",
    "\n",
    "ax[1].axvline(x = 0, color = 'k', ls='--',lw=0.5, label = '')\n",
    "ax[1].set_xlim(-105, 105) #ratio\n",
    "ax[1].set_ylim(0, 50)\n",
    "ax[1].set_xlabel(r'bias FDC>98%')\n",
    "ax[1].set_ylabel('count');\n",
    "\n",
    "plt.savefig(os.path.join(figure_path, 'Fig2_FDC_bias_pdf.png'), bbox_extra_artists=(lgd,), bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Mapping of flow skill statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'GMET' # e.g.,'GMET'\n",
    "\n",
    "df_metric= pd.DataFrame(data=beta_array, index=common_site, columns=sim_case)\n",
    "df_metric.reset_index(level=0, inplace=True)\n",
    "df_metric.rename(columns={'index':'location_name'},inplace=True)\n",
    "df_metric_final = df_site_selected.merge(df_metric, on=\"location_name\", how = 'inner')\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(5.5, 6), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100)\n",
    "plt.subplots_adjust(left=0.015, bottom=0.015, right=0.975, top=0.975)\n",
    "\n",
    "base_map(ax1,df_huc12)\n",
    "df_metric_final.plot(ax=ax1, column=case, markersize=25, \n",
    "                     cmap=color.cmap2, norm=color.norm2, \n",
    "                     zorder=2, legend=True, \n",
    "                     legend_kwds={'extend':'both', 'pad':0.02, 'shrink': 0.825});\n",
    "ax1.set_title('beta')\n",
    "\n",
    "fig.savefig(os.path.join(figure_path, f'Fig3_beta_{case}.png'))\n",
    "\n",
    "print(df_metric_final[case].describe())\n",
    "\n",
    "df_metric_final[case] = (df_metric_final[case]-1)*100\n",
    "for percent in np.arange(100):\n",
    "    if np.count_nonzero(np.abs(df_metric_final[case].values)<percent)/np.count_nonzero(~np.isnan(df_metric_final[case].values))>0.80:\n",
    "        print(\"%d%% or less bias at 75%% of sites\"%percent)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'GMET' # e.g.,'GMET'\n",
    "\n",
    "df_metric= pd.DataFrame(data=alpha_array, index=common_site, columns=sim_case)\n",
    "df_metric.reset_index(level=0, inplace=True)\n",
    "df_metric.rename(columns={'index':'location_name'},inplace=True)\n",
    "df_metric_final = df_site_selected.merge(df_metric, on=\"location_name\", how = 'inner')\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(5.5, 6), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100)\n",
    "plt.subplots_adjust(left=0.015, bottom=0.015, right=0.975, top=0.975)\n",
    "\n",
    "base_map(ax1,df_huc12)\n",
    "df_metric_final.plot(ax=ax1, column=case, markersize=25, \n",
    "                     cmap=color.cmap2, norm=color.norm2, zorder=2, legend=True, \n",
    "                     legend_kwds={'extend':'both', 'pad':0.02, 'shrink': 0.825});\n",
    "ax1.set_title('alpha')\n",
    "\n",
    "fig.savefig(os.path.join(figure_path, f'Fig4_alpha_{case}.png'), dpi=200)\n",
    "\n",
    "print(df_metric_final[case].describe())\n",
    "\n",
    "df_metric_final[case] = (df_metric_final[case]-1)*100\n",
    "for percent in np.arange(100):\n",
    "    if np.count_nonzero(np.abs(df_metric_final[case].values)<percent)/np.count_nonzero(~np.isnan(df_metric_final[case].values))>0.80:\n",
    "        print(\"%d%% or less bias at 75%% of sites\"%percent)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'GMET' # e.g.,'GMET'\n",
    "\n",
    "df_metric= pd.DataFrame(data=corr_array, index=common_site, columns=sim_case)\n",
    "df_metric.reset_index(level=0, inplace=True)\n",
    "df_metric.rename(columns={'index':'location_name'},inplace=True)\n",
    "df_metric_final = df_site_selected.merge(df_metric, on=\"location_name\", how = 'inner')\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(5.5, 6), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100)\n",
    "plt.subplots_adjust(left=0.015, bottom=0.015, right=0.975, top=0.975)\n",
    "\n",
    "base_map(ax1,df_huc12)\n",
    "df_metric_final.plot(ax=ax1, column=case, markersize=25, \n",
    "                     cmap=color.cmap3, norm=color.norm3, legend=True, \n",
    "                     legend_kwds={'extend':'both', 'pad':0.02, 'shrink': 0.825});\n",
    "ax1.set_title('corr')\n",
    "\n",
    "fig.savefig(os.path.join(figure_path, f'Fig5_corr_{case}.png'), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 KGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'GMET' # e.g.,'GMET'\n",
    "\n",
    "df_metric= pd.DataFrame(data=kge_array, index=common_site, columns=sim_case)\n",
    "df_metric.reset_index(level=0, inplace=True)\n",
    "df_metric.rename(columns={'index':'location_name'},inplace=True)\n",
    "df_metric_final = df_site_selected.merge(df_metric, on=\"location_name\", how = 'inner')\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(5.5, 6), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100)\n",
    "plt.subplots_adjust(left=0.015, bottom=0.015, right=0.975, top=0.975)\n",
    "\n",
    "base_map(ax1,df_huc12)\n",
    "df_metric_final.plot(ax=ax1, column=case, markersize=22, cmap=color.cmap3, norm=color.norm3, legend=True, \n",
    "                     legend_kwds={'extend':'both', 'pad':0.02, 'shrink': 0.825});\n",
    "ax1.set_extent([-125, -110, 41.5, 52.5])\n",
    "ax1.set_title('kge')\n",
    "\n",
    "ax1.add_patch(mpl.patches.Rectangle((-122.1, 43.2), 1.75, 2,\n",
    "                                 edgecolor='k',facecolor='None',lw=0.8));\n",
    "ax1.add_patch(mpl.patches.Ellipse((-111.1, 44.3), 1.2, 0.9,\n",
    "                                 edgecolor='k',facecolor='None',lw=0.8));\n",
    "\n",
    "fig.savefig(os.path.join(figure_path, f'Fig6_kge_{case}.png'), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5 FDC %bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'GMET' # e.g.,'GMET'\n",
    "\n",
    "df_pbiasFHV = pd.DataFrame(data=pbiasFHV98_array, index=common_site, columns=sim_case)\n",
    "df_pbiasFHV.reset_index(level=0, inplace=True)\n",
    "df_pbiasFHV.rename(columns={'index':'location_name'},inplace=True)\n",
    "df_pbiasFHV_final = df_site_selected.merge(df_pbiasFHV, on=\"location_name\", how = 'inner')\n",
    "\n",
    "fig = plt.figure(figsize=(5.5, 6), dpi=100)\n",
    "ax1 = fig.add_subplot(1,1,1, projection=ccrs.PlateCarree())\n",
    "plt.subplots_adjust(left=0.015, bottom=0.015, right=0.975, top=0.975)\n",
    "\n",
    "base_map(ax1,df_huc12)\n",
    "df_pbiasFHV_final.plot(ax=ax1, column=case, markersize=25, \n",
    "                       cmap=color.cmap_bias1, norm=color.norm_bias1, legend=True, zorder=2, \n",
    "                       legend_kwds={'extend':'both', 'pad':0.02, 'shrink': 0.800, \n",
    "                                    'ticks': [-60, -50, -40, -30, -20, -10, 10, 20, 30, 40, 50, 60]});\n",
    "ax1.set_title('pbias_FHV_q98')\n",
    "\n",
    "fig.savefig(os.path.join(figure_path, f'Fig7_pbiasFHV_{case}.png'), dpi=200)\n",
    "\n",
    "print(df_pbiasFHV_final[case].describe())\n",
    "\n",
    "for percent in np.arange(100):\n",
    "    if np.count_nonzero(np.abs(df_pbiasFHV_final[case].values)<percent)/np.count_nonzero(~np.isnan(df_pbiasFHV_final[case].values))>0.80:\n",
    "        print(\"%d%% or less bias at 75%% of sites\"%percent)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.6 all maps together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'GMET' # e.g.,'GMET'\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(7.0, 8.5), subplot_kw={\"projection\": ccrs.PlateCarree()}, dpi=100)\n",
    "plt.subplots_adjust(left=0.015, bottom=0.015, right=0.975, top=0.96, hspace=0.15, wspace=0.1)\n",
    "\n",
    "array_collection = {\n",
    "    'alpha': {'array':alpha_array, 'cmap':color.cmap2, 'norm':color.norm2, 'header':r'a) $\\alpha$'},\n",
    "    'beta': {'array':beta_array, 'cmap':color.cmap2, 'norm':color.norm2, 'header':r'b) $\\beta$'},\n",
    "    'corr': {'array':corr_array, 'cmap':color.cmap3, 'norm':color.norm3, 'header':'c) r'},\n",
    "    'kge': {'array':kge_array, 'cmap':color.cmap3, 'norm':color.norm3, 'header':'d) KGE'},\n",
    "    'pbias_FHV': {'array':pbiasFHV98_array, 'cmap':color.cmap_bias1, 'norm':color.norm_bias1, 'header':'e) %bias Flow >98% in FDC'},\n",
    "    'pbias_FLV': {'array':pbiasFLV10_array, 'cmap':color.cmap_bias2, 'norm':color.norm_bias2, 'header':'f) %bias Flow <10% in FDC'},\n",
    "}\n",
    "\n",
    "for ix, (metric, meta) in enumerate(array_collection.items()):\n",
    "    row = ix // 2\n",
    "    col = ix % 2\n",
    "    \n",
    "    df_metric = pd.DataFrame(data=meta['array'], index=common_site, columns=sim_case)\n",
    "    df_metric.reset_index(level=0, inplace=True)\n",
    "    df_metric.rename(columns={'index':'location_name'},inplace=True)\n",
    "    df_metric_final = df_site_selected.merge(df_metric, on=\"location_name\", how = 'inner')\n",
    "\n",
    "    base_map(ax[row, col],df_huc12)\n",
    "    \n",
    "    if metric == 'pbias_FHV':\n",
    "        legend_kwds = {'extend':'both', 'pad':0.02, 'shrink': 0.95,\n",
    "                       'ticks': [-60, -50, -40, -30, -20, -10, 10, 20, 30, 40, 50, 60]}\n",
    "    elif metric == 'pbias_FLV':\n",
    "        legend_kwds = {'extend':'both', 'pad':0.02, 'shrink': 0.95,\n",
    "                       'ticks': list(np.delete(np.arange(-80,90, 10),8))}\n",
    "    else:\n",
    "        legend_kwds = {'extend':'both', 'pad':0.02, 'shrink': 0.95,}        \n",
    "    \n",
    "    df_metric_final.plot(ax=ax[row, col], column=case, markersize=7, \n",
    "                   cmap=meta['cmap'], norm=meta['norm'], legend=True, zorder=2, \n",
    "                   legend_kwds=legend_kwds);\n",
    "    \n",
    "    if ix==3:\n",
    "        ax[row, col].add_patch(mpl.patches.Ellipse((-122.5, 47.5), 2.0, 1.0, angle=-30,\n",
    "                                          edgecolor='None',facecolor='xkcd:grey',lw=0.7, alpha=0.5)); # Eastern Cascade\n",
    "        ax[row, col].text(-121.5, 47.7, 'Puget Sound', rotation=35, fontsize=6)                                                             \n",
    "        #ax[row, col].add_patch(mpl.patches.Rectangle((-117.5, 42.2), 7.25, 2.9,\n",
    "        #                                 edgecolor='k',facecolor='None',lw=0.7)); # Snake\n",
    "        ax[row, col].add_patch(mpl.patches.Ellipse((-111.1, 44.3), 1.27, 0.9,\n",
    "                                         edgecolor='None',facecolor='xkcd:grey',lw=0.7, alpha=0.5));# Upper Snake\n",
    "        ax[row, col].text(-113.7, 45, 'Upper Snake', fontsize=6)\n",
    "        ax[row, col].add_patch(mpl.patches.Rectangle((-122.1, 43.2), 1.7, 2.0,\n",
    "                                            edgecolor='None',facecolor='xkcd:grey',lw=0.7, alpha=0.5)); # Deschutes\n",
    "        ax[row, col].text(-121.0, 42.6, 'Deschutes', fontsize=6)\n",
    "    \n",
    "    ax[row, col].set_title(meta['header'], fontsize=10)\n",
    "    cbar = ax[row, col].get_figure().axes[-1]  # Access the colorbar axis (usually the last axis)\n",
    "    cbar.tick_params(labelsize=9)   # Set colorbar tick label font siz\n",
    "\n",
    "for jx in range(ix+1,3*2):\n",
    "    row = jx // 2\n",
    "    col = jx % 2\n",
    "    fig.delaxes(ax[row][col])\n",
    "    \n",
    "fig.savefig(os.path.join(figure_path,f'Fig8_metrics_collection_{case}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Seasonal flow plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute flow statistics based on daily data (VIC, SUMMA, NRNI)    \n",
    "djf_mean_array = np.zeros((num_site, len(all_case)))\n",
    "mam_mean_array = np.zeros((num_site, len(all_case)))\n",
    "jja_mean_array = np.zeros((num_site, len(all_case)))\n",
    "son_mean_array = np.zeros((num_site, len(all_case)))\n",
    "\n",
    "diff_djf_array = np.zeros((num_site, len(sim_case)))\n",
    "diff_mam_array = np.zeros((num_site, len(sim_case)))\n",
    "diff_jja_array = np.zeros((num_site, len(sim_case)))\n",
    "diff_son_array = np.zeros((num_site, len(sim_case)))\n",
    "\n",
    "for c, case in enumerate(all_case): \n",
    "    if case=='obs':\n",
    "        season_flow = ds_nrni_selected['streamflow'].groupby('time.season').mean('time')\n",
    "    else:\n",
    "        season_flow = ds_sim_selected[case]['streamflow'].groupby('time.season').mean('time')\n",
    "    for r, site in enumerate(common_site):\n",
    "        djf_mean_array[r,c] = season_flow.sel(site=site, season='DJF').values\n",
    "        jja_mean_array[r,c] = season_flow.sel(site=site, season='JJA').values\n",
    "        mam_mean_array[r,c] = season_flow.sel(site=site, season='MAM').values\n",
    "        son_mean_array[r,c] = season_flow.sel(site=site, season='SON').values\n",
    "\n",
    "for c, case in enumerate(sim_case):         \n",
    "    diff_jja_array[:,c] = jja_mean_array[:,c] - jja_mean_array[:,-1]\n",
    "    diff_mam_array[:,c] = mam_mean_array[:,c] - mam_mean_array[:,-1]\n",
    "    diff_djf_array[:,c] = djf_mean_array[:,c] - djf_mean_array[:,-1]\n",
    "    diff_son_array[:,c] = son_mean_array[:,c] - son_mean_array[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# 4 panel CDFs (Seasonal mean)\n",
    "fig = plt.figure(figsize=(7.5, 6.5))\n",
    "fig.subplots_adjust(left=0.095,right=0.975,bottom=0.095,top=0.935,wspace=0.25,hspace=0.25)\n",
    "\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax2 = plt.subplot2grid((2, 2), (0, 1))\n",
    "ax3 = plt.subplot2grid((2, 2), (1, 0))\n",
    "ax4 = plt.subplot2grid((2, 2), (1, 1))\n",
    "\n",
    "ax1.tick_params(labelsize=8)\n",
    "ax2.tick_params(labelsize=8)\n",
    "ax3.tick_params(labelsize=8)\n",
    "ax4.tick_params(labelsize=8)\n",
    "\n",
    "plot_case = sim_case\n",
    "\n",
    "#panel a) DJF\n",
    "for c, case in enumerate(plot_case):\n",
    "    ax1.scatter(djf_mean_array[:,-1], djf_mean_array[:,c],s=17, c=case_meta[case]['color'], label=case_meta[case]['label'], alpha=0.4)\n",
    "ax1.plot([0, 4000], [0, 4000], 'black', linewidth=0.5)\n",
    "lgd = ax1.legend(frameon=True,loc=\"upper left\", handlelength=2, prop={'size':8})\n",
    "lgd.get_frame().set_facecolor('white')\n",
    "ax2.set_xlim(2*10**-1, 2*10**4)\n",
    "ax2.set_ylim(5*10**-3, 2*10**4)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylabel('DJF sim [cms]')\n",
    "ax1.set_xlabel('DJF obs [cms]')\n",
    "\n",
    "#panel b) MAM\n",
    "for c, case in enumerate(plot_case):\n",
    "    ax2.scatter(mam_mean_array[:,-1], mam_mean_array[:,c], s=17, c=case_meta[case]['color'],label=case_meta[case]['label'], alpha=0.4)\n",
    "ax2.plot([0, 12000], [0, 12000], 'black', linewidth=0.5)\n",
    "ax2.set_xlim(2*10**-1, 2*10**4)\n",
    "ax2.set_ylim(5*10**-3, 2*10**4)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel('MAM sim [cms]')\n",
    "ax2.set_xlabel('MAM obs [cms]')\n",
    "\n",
    "#panel c) JJA\n",
    "for c, case in enumerate(plot_case):\n",
    "    ax3.scatter(jja_mean_array[:,-1], jja_mean_array[:,c], s=17, c=case_meta[case]['color'], label=case_meta[case]['label'], alpha=0.4)\n",
    "ax3.plot([0, 16000], [0, 16000], 'black', linewidth=0.5)\n",
    "ax3.set_xlim(2*10**-2, 2*10**4)\n",
    "ax3.set_ylim(5*10**-3, 2*10**4)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_ylabel('JJA sim [cms]')\n",
    "ax3.set_xlabel('JJA obs [cms]')\n",
    "\n",
    "#panel d) SON\n",
    "for c, case in enumerate(plot_case):\n",
    "    ax4.scatter(son_mean_array[:,-1],son_mean_array[:,c], s=17, c=case_meta[case]['color'],label=case_meta[case]['label'], alpha=0.4)\n",
    "ax4.plot([0, 4000], [0, 4000], 'black', linewidth=0.5)\n",
    "ax4.set_xlim(2*10**-2, 1*10**4)\n",
    "ax4.set_ylim(5*10**-3, 1*10**4)\n",
    "ax4.set_xscale('log')\n",
    "ax4.set_yscale('log')\n",
    "ax4.set_ylabel('SON sim')\n",
    "ax4.set_xlabel('SON obs [cms]');\n",
    "\n",
    "fig.suptitle('Seasonal flow at sites: %s %s'%(analysis_period.start, analysis_period.stop), fontsize='medium');\n",
    "plt.savefig(os.path.join(figure_path, 'Fig9_seasonal_flow_scatter.png'), format='png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time series plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. summary flow plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "\n",
    "def is_aj(month):\n",
    "    return (month >= 4) & (month <= 7)\n",
    "\n",
    "# ---- setup for summary plot\n",
    "period_name = 'validation'\n",
    "# cal period plot -> slice('1997-10-01', '2001-09-30') for both\n",
    "# val period plot -> slice('2001-10-01', '2005-09-30') for daily, and  slice('2001-10-01', '2010-09-30') for month\n",
    "if period_name == 'calibration':\n",
    "    daily_period = slice('1997-10-01', '2001-09-30')   \n",
    "    month_period = slice('1991-10-01', '2001-09-30')\n",
    "elif period_name == 'validation':\n",
    "    daily_period = slice('2001-10-01', '2005-09-30')   \n",
    "    month_period = slice('2001-10-01', '2010-09-30')\n",
    "\n",
    "obj_plot = ['GMET']\n",
    "\n",
    "head_title = f'{period_name} period'\n",
    "\n",
    "# --- loop through sites\n",
    "for idx, data in df_site_selected.iterrows():\n",
    "    site = data['location_name']\n",
    "    # get daily flow \n",
    "    ds_sim_daily ={}\n",
    "    for case in obj_plot:\n",
    "        ds_sim_daily[case] = ds_sim[case].sel(site=site)['streamflow'].sel(time=daily_period)\n",
    "    ds_obs_daily = ds_nrni_selected.sel(site=site)['streamflow'].sel(time=daily_period)\n",
    "    \n",
    "    # get monthly flow \n",
    "    ds_sim_month ={}\n",
    "    for case in obj_plot:\n",
    "        ds_sim_month[case] = ds_sim[case].sel(site=site)['streamflow'].sel(time=month_period).resample(time='1ME').mean()\n",
    "    ds_obs_month = ds_nrni_selected.sel(site=site)['streamflow'].sel(time=month_period).resample(time='1ME').mean()\n",
    "\n",
    "    # get monthly climatological flow\n",
    "    ds_sim_month_clim ={}\n",
    "    ds_sim_month_cal_clim ={}\n",
    "    for case in obj_plot:\n",
    "        ds_sim_month_clim[case]     = ds_sim[case].sel(site=site)['streamflow'].sel(time=month_period).groupby('time.month').mean('time')\n",
    "        ds_sim_month_cal_clim[case] = ds_sim[case].sel(site=site)['streamflow'].sel(time=cal_period).groupby('time.month').mean('time')\n",
    "    ds_obs_month_clim = ds_nrni_selected.sel(site=site)['streamflow'].sel(time=month_period).groupby('time.month').mean('time')\n",
    "    ds_obs_month_cal_clim = ds_nrni_selected.sel(site=site)['streamflow'].sel(time=cal_period).groupby('time.month').mean('time')\n",
    "    \n",
    "    ds_sim_ann_wy ={}\n",
    "    for case in obj_plot:\n",
    "        ds_sim_ann_wy[case] = ds_sim[case].sel(site=site)['streamflow'].sel(time=month_period).resample(time='YS-OCT').mean()\n",
    "    ds_obs_ann_wy = ds_nrni_selected.sel(site=site)['streamflow'].sel(time=month_period).resample(time='YS-OCT').mean()\n",
    "\n",
    "    ds_sim_AJ_wy ={}\n",
    "    for case in obj_plot:\n",
    "        ds_sim_AJ_wy[case] = ds_sim_month[case].sel(time=is_aj(ds_sim_month[case]['time.month'])).resample(time='YS-OCT').mean()\n",
    "    ds_obs_AJ_wy = ds_obs_month.sel(time=is_aj(ds_obs_month['time.month'])).resample(time='YS-OCT').mean()\n",
    "\n",
    "    # ----- creating figure\n",
    "    fig = plt.figure(figsize=(6.5, 9.5))\n",
    "\n",
    "    AX = mpl.gridspec.GridSpec(4,2)\n",
    "    AX.update(wspace = 0.5, hspace = 0.5)\n",
    "    ax1  = plt.subplot(AX[0,:])\n",
    "    ax2 = plt.subplot(AX[1,:])\n",
    "    ax3 = plt.subplot(AX[2,:])\n",
    "    ax4 = plt.subplot(AX[3,0])\n",
    "    ax5 = plt.subplot(AX[3,1])\n",
    "\n",
    "    # plot monthly\n",
    "    for case in obj_plot:\n",
    "        ds_sim_month[case].plot(ax=ax1, c=case_meta[case]['color'], linewidth=1.0, label=case_meta[case]['label'])\n",
    "    ds_obs_month.plot(ax=ax1, color='k', linestyle='dashed', linewidth=0.8, label='obs')\n",
    "    #ax1.axvspan(pd.to_datetime(cal_period.start), pd.to_datetime(cal_period.stop), alpha=0.2, color='gray')  # this is shading period between two datetime\n",
    "    \n",
    "    # plot daily calibration period\n",
    "    for case in obj_plot:\n",
    "        ds_sim_daily[case].rolling(time=7, center=True).mean().plot(ax=ax2, c=case_meta[case]['color'], linewidth=1.0, label=None, add_legend=False)\n",
    "    ds_obs_daily.rolling(time=7, center=True).mean().plot(ax=ax2, color='k', linestyle='dashed', linewidth=0.8, add_legend=False)\n",
    "    #ax2.axvspan(pd.to_datetime(cal_period.start), pd.to_datetime(cal_period.stop), alpha=0.2, color='gray') # this is shading period between two datetime\n",
    "\n",
    "    # plot monthly long term averages for period\n",
    "    for case in obj_plot:\n",
    "        ds_sim_month_clim[case].plot(ax=ax3, c=case_meta[case]['color'], linewidth=1.0, label=None, add_legend=False)\n",
    "        #ds_sim_month_cal_clim[case].plot(ax=ax3, c=meta[case]['color'], linewidth=1.5, linestyle='solid', label=None, add_legend=False) \n",
    "    ds_obs_month_clim.plot(ax=ax3, color='k', linestyle='dashed', linewidth=0.8, add_legend=False)\n",
    "\n",
    "    # plot scatter for water year mean flow\n",
    "    axmax1 = np.max(ds_obs_ann_wy.values)\n",
    "    ax4.scatter(-10,-10, s=12, c='k', marker='x', label='entire')\n",
    "    ax4.scatter(-10,-10, s=10, c='k', marker='o', label='calib')\n",
    "    for case in obj_plot:\n",
    "        axmax1= np.max([axmax1, np.max(ds_sim_ann_wy[case].values)])\n",
    "        ax4.scatter(ds_sim_ann_wy[case].values, ds_obs_ann_wy.values, s=12, c=case_meta[case]['color'], marker='x', alpha=1.0)\n",
    "        ax4.scatter(ds_sim_ann_wy[case].sel(time=cal_period).values, ds_obs_ann_wy.sel(time=cal_period).values, \n",
    "                    s=10, c=case_meta[case]['color'])\n",
    "    ax4.plot((0, axmax1*1.05), (0, axmax1*1.05), c='orange', linestyle=':', label=None)\n",
    "#    ax4.annotate('corr: '+str(round(corr_WY[0], 3)), xy=(axmax*0.97, axmax*0.10), horizontalalignment='right')\n",
    "\n",
    "    # plot scatter for spring runoff period (Apr-Jul)\n",
    "    axmax = np.max(ds_obs_AJ_wy.values)\n",
    "    for case in obj_plot:\n",
    "        axmax= np.max([axmax, np.max(ds_sim_AJ_wy[case].values)])\n",
    "        ax5.scatter(ds_sim_AJ_wy[case].values, ds_obs_AJ_wy.values, s=12, c=case_meta[case]['color'], marker='x', alpha=1.0)\n",
    "        ax5.scatter(ds_sim_AJ_wy[case].sel(time=cal_period).values, ds_obs_AJ_wy.sel(time=cal_period).values, s=10, c=case_meta[case]['color'])\n",
    "    ax5.plot((0, axmax*1.05), (0, axmax*1.05), c='orange', linestyle=':', label=None)\n",
    "#    ax5.annotate('corr: '+str(round(corr_AJ[0], 3)), xy=(axmax*0.97, axmax*0.10), horizontalalignment='right')\n",
    "\n",
    "    # other plot details\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('Flow, Monthly (cms)')\n",
    "    ax2.set_title('')\n",
    "    ax2.set_xlabel('')\n",
    "    ax2.set_ylabel('Flow, Daily (cms)')\n",
    "    ax3.set_title('',fontsize=\"small\")\n",
    "    ax3.set_ylabel('Flow, Monthly (cms)')\n",
    "    ax3.set_xlabel('Month')\n",
    "    ax4.set_ylabel('WY Obs (cms)')\n",
    "    ax4.set_xlabel('WY Sim (cms)')\n",
    "    if ~np.isnan(axmax1):\n",
    "        ax4.set_xlim([0, axmax1*1.05])\n",
    "        ax4.set_ylim([0, axmax1*1.05])\n",
    "    if ~np.isnan(axmax):\n",
    "        ax5.set_xlim([0, axmax*1.05])\n",
    "        ax5.set_ylim([0, axmax*1.05])\n",
    "    ax5.set_ylabel('AMJ Obs (cms)')\n",
    "    ax5.set_xlabel('AMJ Sim (cms)')\n",
    "    ax1.legend(loc='best', fontsize=\"x-small\")\n",
    "    #ax4.legend(loc='best', fontsize=\"small\")\n",
    "    #ax2.legend().remove()\n",
    "    ax1.set_title(head_title + ': ' +site, fontsize=12)\n",
    "    plotFname=os.path.join(os.path.join(figure_path, 'per_site', f'NB1_fig11_summary_hydrograph_{period_name}_{site}.png'))\n",
    "    plt.savefig(plotFname, dpi=200, bbox_inches='tight')\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
