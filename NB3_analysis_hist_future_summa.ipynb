{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB3 - Analysis on SUMMA outputs forced by GMET and ICAR climate projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy\n",
    "\n",
    "from scripts.utility import AutoVivification\n",
    "import scripts.colors as ccmap\n",
    "\n",
    "print(\"\\nThe Python version: %s.%s.%s\" % sys.version_info[:3])\n",
    "print(xr.__name__, xr.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask\n",
    "**Without Dask, loading netcdf takes much longer. This setup is a machine specific (here for NCAR Casper HPC). Please adjust this section, depending on your machine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = PBSCluster(processes=2, memory=\"100GB\", queue='casper',\n",
    "                  walltime='00:30:00')\n",
    "cluster.scale(jobs=12)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "main_path  = '/glade/campaign/ral/hap/mizukami/archive/pnw_hydrology/final_archive_v1' # !!! This is top directory of the dataset.\n",
    "geo_path   = os.path.join(main_path, 'ancillary_data','geospatial_data')\n",
    "nrni_path  = os.path.join(main_path, 'ancillary_data')\n",
    "figure_path = 'NB3_figures'\n",
    "os.makedirs(figure_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mete dictironaries\n",
    "gcm_runs = {\n",
    "            'CanESM5':             {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},\n",
    "            'CMCC-CM2-SR5':        {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},    \n",
    "            'NorESM2-MM':          {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},\n",
    "            'MIROC-ES2L':          {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},\n",
    "            'MPI-M.MPI-ESM1-2-LR': {'scen':['hist', 'ssp245', 'ssp370', 'ssp585'], 'cmip':6},\n",
    "            'CanESM2':             {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "            'CCSM4':               {'scen':['hist', 'rcp85'], 'cmip':5},\n",
    "            'CMCC-CM':             {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "            'CNRM-CM5':            {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "            'MIROC5':              {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "            'MRI-CGCM3':           {'scen':['hist', 'rcp45',  'rcp85'], 'cmip':5},\n",
    "           }\n",
    "\n",
    "retro_runs = {\n",
    "            'GMET':{'period':'control'}\n",
    "            }\n",
    "\n",
    "scens = {\n",
    "         'hist':   {'time':slice('1975-01-01', '2004-12-31'), 'period':['control']},\n",
    "         'ssp245': {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "         'ssp370': {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "         'ssp585': {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "         'rcp45':  {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "         'rcp85':  {'time':slice('2005-01-01', '2099-12-31'), 'period':['2040s','2080s']},\n",
    "        }\n",
    "\n",
    "periods = {\n",
    "         'control':  {'name':'WY1980-2004', 'time':slice('1980-10-01', '2004-09-30'), 'lc':'xkcd:blue'},\n",
    "         '2040s':    {'name':'WY2030-2060', 'time':slice('2029-10-01', '2060-09-30'), 'lc':'xkcd:orange'},\n",
    "         '2080s':    {'name':'WY2070-2099', 'time':slice('2069-10-01', '2099-09-30'), 'lc':'xkcd:magenta'},\n",
    "          }\n",
    "\n",
    "ensembles = {\n",
    "             'cmip-hist':     {'cmip':[5,6], 'scen':['hist']},\n",
    "             'cmip6-hist':    {'cmip':[6],   'scen':['hist']},\n",
    "             'cmip5-hist':    {'cmip':[5],   'scen':['hist']},\n",
    "             'cmip6-ssp245':  {'cmip':[6],   'scen':['hist', 'ssp245']},\n",
    "             'cmip6-ssp585':  {'cmip':[6],   'scen':['hist', 'ssp585']},\n",
    "             'cmip5-rcp85':   {'cmip':[5],   'scen':['hist', 'rcp85']},\n",
    "             'cmip6':         {'cmip':[6],   'scen':['hist', 'ssp245', 'ssp370', 'ssp585']},\n",
    "             'cmip5':         {'cmip':[5],   'scen':['hist', 'rcp45','rcp85']},\n",
    "             'high-emission': {'cmip':[5,6], 'scen':['ssp585','rcp85']},\n",
    "            }\n",
    "\n",
    "mean_ensemble_name='cmip-hist' # select from ensembles dictionary\n",
    "\n",
    "sims   =  {**retro_runs, **gcm_runs}\n",
    "gcm_names   = list(gcm_runs.keys())\n",
    "retro_names = list(retro_runs.keys())\n",
    "sim_names   = list(sims.keys())\n",
    "\n",
    "# including variables\n",
    "summa_variables = {\n",
    "    'scalarTotalRunoff_mean':{'scale':1, 'mon_agg':'sum'},\n",
    "    'scalarTotalET_mean':    {'scale':1, 'mon_agg':'sum'},\n",
    "    'scalarSWE':             {'scale':1, 'mon_agg':'mean'},\n",
    "}\n",
    "met_variables = {\n",
    "    'prec': {'scale':1,      'mon_agg':'sum'},\n",
    "}\n",
    "variables = {**summa_variables, **met_variables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 geospatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_huc12 = gpd.read_file(os.path.join(geo_path, 'HUC12_MERIT_PNW.gpkg'))\n",
    "df_huc12['geometry'] = df_huc12.geometry.simplify(0.01) # simplified\n",
    "# clean attributes\n",
    "df_huc12.drop(columns=['SourceData','SourceOrig','LoadDate','NonContr_1','NonContrib','HUC12','HUType','pfaf150','pfaf_merit','PERIM_GEO'], inplace=True)\n",
    "df_huc12 = df_huc12.rename(columns={'HUCIDXint':'hruId'})\n",
    "df_huc12 = df_huc12.set_index('hruId')\n",
    "\n",
    "df_site  = pd.read_csv(os.path.join(geo_path, 'PNW_flow_site.csv'), index_col='location_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Read summa outputs\n",
    "\n",
    "Read summa daily output, aggregate it to monthly and store it in dictionary ds_summa[sim_case][scenario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# read SUMMA variables per HUC12 over the entire PWN. \n",
    "def summa_preprocess(ds):\n",
    "    ds = ds[[*summa_variables]]\n",
    "    for var, meta in summa_variables.items():\n",
    "        ds[var] = ds[var]*meta['scale']\n",
    "    return ds\n",
    "\n",
    "def met_preprocess(ds):\n",
    "    ds = ds[[*met_variables]]\n",
    "    for var, meta in met_variables.items():\n",
    "        ds[var] = ds[var]*meta['scale']\n",
    "    return ds\n",
    "\n",
    "# get GCM sim\n",
    "ds_summa = AutoVivification()\n",
    "for gcm_name, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        analysis_period = scens[scen]['time']\n",
    "\n",
    "        if scen=='hist' and meta['cmip']==5: # for cmip5 historical period, use rcp85 data\n",
    "            case = f'{gcm_name}_rcp85'\n",
    "        elif scen=='hist' and meta['cmip']==6: # for cmip6 historical period, use ssp585 data\n",
    "            case = f'{gcm_name}_ssp585'\n",
    "        else: # for future period\n",
    "            case = f'{gcm_name}_{scen}'\n",
    "        \n",
    "        nclist=glob.glob(os.path.join(main_path, case, f'{case}_summa_daily.nc'))\n",
    "        ds_tmp = xr.open_mfdataset(nclist, data_vars='minimal', parallel=True, preprocess=summa_preprocess, chunks='auto')\n",
    "        ds_tmp = ds_tmp.sel(time=analysis_period).resample(time='MS').mean()\n",
    "        for var, meta_var in summa_variables.items():\n",
    "            if meta_var['mon_agg']=='sum':\n",
    "                ds_tmp[var] = ds_tmp[var]*30       \n",
    "        ds_summa[gcm_name][scen] = ds_tmp.load()\n",
    "        \n",
    "        nclist=glob.glob(os.path.join(main_path, case, f'{case}_daily_t_p.nc'))\n",
    "        ds_tmp = xr.open_mfdataset(nclist, data_vars='minimal', parallel=True, preprocess=met_preprocess, chunks='auto')\n",
    "        ds_tmp = ds_tmp.sel(time=analysis_period).resample(time='MS').mean()\n",
    "        for var, meta_var in met_variables.items():\n",
    "            if meta_var['mon_agg']=='sum':\n",
    "                ds_tmp[var] = ds_tmp[var]*30\n",
    "        ds_summa[gcm_name][scen] = ds_summa[gcm_name][scen].merge(ds_tmp.load())\n",
    "        \n",
    "        print(f'{gcm_name}_{scen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# read basin mean SUMMA variables. SUMMA simulation forced by ESMs\n",
    "\n",
    "ds_summa_basin = AutoVivification()\n",
    "for gcm_name, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        analysis_period = scens[scen]['time']\n",
    "\n",
    "        if scen=='hist' and meta['cmip']==5: # for cmip5 historical period, use rcp85 data\n",
    "            case = f'{gcm_name}_rcp85'\n",
    "        elif scen=='hist' and meta['cmip']==6: # for cmip6 historical period, use ssp585 data\n",
    "            case = f'{gcm_name}_ssp585'\n",
    "        else: # for future period\n",
    "            case = f'{gcm_name}_{scen}'\n",
    "        \n",
    "        nclist=glob.glob(os.path.join(main_path, case, f'{case}_summa_daily_basin_mean.nc'))\n",
    "        ds_tmp = xr.open_mfdataset(nclist, data_vars='minimal', parallel=True, preprocess=summa_preprocess, chunks='auto')\n",
    "        ds_tmp = ds_tmp.sel(time=analysis_period).resample(time='MS').mean()\n",
    "        for var, meta_var in summa_variables.items():\n",
    "            if meta_var['mon_agg']=='sum':\n",
    "                ds_tmp[var] = ds_tmp[var]*30\n",
    "        ds_summa_basin[gcm_name][scen] = ds_tmp.load()\n",
    "\n",
    "        nclist=glob.glob(os.path.join(main_path, case, f'{case}_daily_t_p_basin_mean.nc'))\n",
    "        ds_tmp = xr.open_mfdataset(nclist, data_vars='minimal', parallel=True, preprocess=met_preprocess, chunks='auto')\n",
    "        ds_tmp = ds_tmp.sel(time=analysis_period).resample(time='MS').mean()\n",
    "        for var, meta_var in met_variables.items():\n",
    "            if meta_var['mon_agg']=='sum':\n",
    "                ds_tmp[var] = ds_tmp[var]*30\n",
    "        ds_summa_basin[gcm_name][scen] = ds_summa_basin[gcm_name][scen].merge(ds_tmp.load())\n",
    "        \n",
    "        print(f'{gcm_name}_{scen}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute annual and seasonal mean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "water fluxes and temperature - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_summa_annual = AutoVivification()\n",
    "for case, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        for period in scens[scen]['period']:\n",
    "            ds_summa_annual[case][scen][period] = ds_summa[case][scen].drop_vars('scalarSWE').sel(time=periods[period]['time']).mean('time')\n",
    "            for var, _ in variables.items():\n",
    "                if var not in ['airtemp_mean', 'scalarSWE', 'hru']:\n",
    "                    ds_summa_annual[case][scen][period][var] = ds_summa_annual[case][scen][period][var]*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snow water equivalent - annual max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for case, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        for period in scens[scen]['period']:\n",
    "            ds_summa_annual_SWEmax        = ds_summa[case][scen]['scalarSWE'].sel(time=periods[period]['time']).resample(time='YS').max('time', skipna=False).mean('time')\n",
    "            ds_summa_annual_SWEmax        = ds_summa_annual_SWEmax.rename('SWEmax')\n",
    "            ds_summa_annual[case][scen][period] = ds_summa_annual[case][scen][period].merge(ds_summa_annual_SWEmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "seasonal mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_summa_season = AutoVivification()\n",
    "for case, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        for period in scens[scen]['period']:\n",
    "            ds_summa_season[case][scen][period] = ds_summa[case][scen].sel(time=periods[period]['time']).groupby(\"time.season\").mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "emsemble mean of annual mean over period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_name='high-emission'\n",
    "\n",
    "# -------------------\n",
    "print('Computing ensemble mean.....')\n",
    "# -------------------\n",
    "gcm_plots = {gcm: meta['scen'] for gcm, meta in gcm_runs.items() if meta['cmip'] in ensembles[ensemble_name]['cmip'] }\n",
    "\n",
    "ds_ens_mean_annual = {}\n",
    "count = 0 \n",
    "for gcm_name, scen_list in gcm_plots.items():\n",
    "    if count==0:\n",
    "        ds_ens_mean_annual['control'] = ds_summa_annual[gcm_name]['hist']['control']\n",
    "    else:\n",
    "        ds_ens_mean_annual['control'] = ds_ens_mean_annual['control'] + ds_summa_annual[gcm_name]['hist']['control']\n",
    "    count+=1\n",
    "# emsemble mean\n",
    "ds_ens_mean_annual['control'] = ds_ens_mean_annual['control']/count\n",
    "\n",
    "count = 0 \n",
    "for gcm_name, scen_list in gcm_plots.items():\n",
    "    for scen in scen_list:\n",
    "        if scen=='hist':\n",
    "            continue\n",
    "        if count==0:\n",
    "            ds_ens_mean_annual['2040s']  = ds_summa_annual[gcm_name][scen]['2040s']\n",
    "            ds_ens_mean_annual['2080s']  = ds_summa_annual[gcm_name][scen]['2080s']\n",
    "        else:\n",
    "            ds_ens_mean_annual['2040s']  = ds_ens_mean_annual['2040s'] + ds_summa_annual[gcm_name][scen]['2040s']\n",
    "            ds_ens_mean_annual['2080s']  = ds_ens_mean_annual['2080s'] + ds_summa_annual[gcm_name][scen]['2080s']\n",
    "        count+=1\n",
    "        \n",
    "# emsemble mean\n",
    "ds_ens_mean_annual['2040s'] = ds_ens_mean_annual['2040s']/count\n",
    "ds_ens_mean_annual['2080s'] = ds_ens_mean_annual['2080s']/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Annual mean change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each future period for each GCM and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = {'prec':           'pdiff',\n",
    "            'scalarTotalET_mean':     'pdiff',\n",
    "            'scalarTotalRunoff_mean': 'pdiff',\n",
    "            'SWEmax':                 'diff'}\n",
    "\n",
    "ds_summa_change = AutoVivification()\n",
    "for case, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        for period in scens[scen]['period']:\n",
    "            if period == 'hist':\n",
    "                continue\n",
    "            for var, method in var_list.items():\n",
    "                ds_summa_change[case][scen][period][var] = ds_summa_annual[case][scen][period][var] - ds_summa_annual[case]['hist']['control'][var]\n",
    "                if method == 'pdiff':\n",
    "                    ds_summa_change[case][scen][period][var] = ds_summa_change[case][scen][period][var]/ds_summa_annual[case]['hist']['control'][var]*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each future period for one emsemble mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ens_mean_annual_change = AutoVivification()\n",
    "for period in periods.keys():\n",
    "    if period == 'control':\n",
    "        continue\n",
    "    for var, method in var_list.items():\n",
    "        ds_ens_mean_annual_change[period][var] = ds_ens_mean_annual[period][var] - ds_ens_mean_annual['control'][var]\n",
    "        if method == 'pdiff':\n",
    "            ds_ens_mean_annual_change[period][var] = ds_ens_mean_annual_change[period][var]/ds_ens_mean_annual['control'][var]*100  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some local plot setups\n",
    "\n",
    "cm = {'general'  : mpl.colormaps['Spectral_r'],\n",
    "      'diff1':     ccmap.cmap_summa_diff,\n",
    "      'diff2':     ccmap.cmap_summa_swe_diff}\n",
    "\n",
    "cbar_kwrgs = {\"orientation\":\"horizontal\", \"shrink\":0.92, \"pad\":0.03, 'extend':'both'}\n",
    "\n",
    "style_kwargs = {'add_labels': False, 'xticks':[], 'yticks':[], 'cbar_kwargs': cbar_kwrgs}\n",
    "\n",
    "hruVar = {'prec':           {'name':'Precip', 'vmin':20, 'vmax':2000, 'cm':cm['general'], 'extend':'both', 'unit':'mm',  **style_kwargs},\n",
    "          'scalarTotalET_mean':     {'name':'ET',     'vmin':20, 'vmax':2000, 'cm':cm['general'], 'extend':'both', 'unit':'mm',  **style_kwargs},\n",
    "          'scalarTotalRunoff_mean': {'name':'Runoff', 'vmin':20, 'vmax':2000, 'cm':cm['general'], 'extend':'both', 'unit':'mm',  **style_kwargs},\n",
    "          'SWEmax':                 {'name':'SWEmax', 'vmin':20, 'vmax':2000, 'cm':cm['general'], 'extend':'max',  'unit':'mm',  **style_kwargs}\n",
    "         } \n",
    "\n",
    "hruVar_diff = {'prec':           {'name':'Precip', 'vmin':-40,  'vmax':40,  'cm':cm['diff1'], 'extend':'both', 'unit':'%', **style_kwargs},\n",
    "               'scalarTotalET_mean':     {'name':'ET',     'vmin':-40,  'vmax':40,  'cm':cm['diff1'], 'extend':'both', 'unit':'%', **style_kwargs},\n",
    "               'scalarTotalRunoff_mean': {'name':'Runoff', 'vmin':-40,  'vmax':40,  'cm':cm['diff1'], 'extend':'both', 'unit':'%', **style_kwargs},\n",
    "               'SWEmax':                 {'name':'SWEmax', 'vmin':-150, 'vmax':0,   'cm':cm['diff2'], 'extend':'both', 'unit':'mm', **style_kwargs}\n",
    "               } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Individual GCM and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summa = AutoVivification()\n",
    "for case, _ in gcm_runs.items():    \n",
    "    df_summa[case] = df_huc12\n",
    "    for var, _ in hruVar.items():\n",
    "        df_var = ds_summa_annual[case]['hist']['control'][var].to_dataframe()\n",
    "        df_summa[case] = df_summa[case].merge(df_var,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summa_diff = AutoVivification()\n",
    "for case, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        for period in scens[scen]['period']:\n",
    "            if period == 'control':\n",
    "                continue\n",
    "            df_summa_diff[case][scen][period] = df_huc12\n",
    "            for var, _ in hruVar.items():\n",
    "                df_var = ds_summa_change[case][scen][period][var].to_dataframe()\n",
    "                df_summa_diff[case][scen][period] = df_summa_diff[case][scen][period].merge(df_var, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ylabel(ax, text, fontsize=12):\n",
    "    return ax.text(-0.07, 0.55, text, va='center', ha='center',\n",
    "        rotation='vertical', rotation_mode='anchor',\n",
    "        transform=ax.transAxes, fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_case='CanESM5'\n",
    "scen='ssp245'\n",
    "\n",
    "nrows=3; ncols=4\n",
    "fig1, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(8.5, 8.25))\n",
    "plt.subplots_adjust(left=0.0275, bottom=0.020, right=0.985, top=0.935, hspace=0.1, wspace=0.1)\n",
    "\n",
    "for col, (var, _) in enumerate(hruVar.items()):\n",
    "    df_summa[plot_case].plot(ax=ax[0, col], column=var, cmap=hruVar[var]['cm'], norm=mpl.colors.LogNorm(vmin=hruVar[var]['vmin'], vmax=hruVar[var]['vmax']), legend=False)\n",
    "    df_summa_diff[plot_case][scen]['2040s'].plot(ax=ax[1, col], column=var, cmap=hruVar_diff[var]['cm'], vmin=hruVar_diff[var]['vmin'], vmax=hruVar_diff[var]['vmax'], legend=False)\n",
    "    df_summa_diff[plot_case][scen]['2080s'].plot(ax=ax[2, col], column=var, cmap=hruVar_diff[var]['cm'], vmin=hruVar_diff[var]['vmin'], vmax=hruVar_diff[var]['vmax'], legend=False)\n",
    "\n",
    "    ax[0,col].set_xticks([])\n",
    "    ax[0,col].set_yticks([])\n",
    "    ax[0,col].set_title('%s [%s]'%(hruVar[var]['name'], hruVar[var]['unit']), fontsize=9);\n",
    "    ax[1,col].set_title('%s change [%s]'%(hruVar_diff[var]['name'], hruVar_diff[var]['unit']), fontsize=9);\n",
    "\n",
    "    points = ax[0,col].collections[-1]\n",
    "    cbar = plt.colorbar(points, ax=ax[0,col], **cbar_kwrgs);\n",
    "    cbar.ax.tick_params(labelsize=7)\n",
    "    \n",
    "    points = ax[1,col].collections[-1]\n",
    "    cbar = plt.colorbar(points, ax=ax[1,col], **cbar_kwrgs);\n",
    "    cbar.ax.tick_params(labelsize=7)\n",
    "    \n",
    "    points = ax[2,col].collections[-1]\n",
    "    cbar = plt.colorbar(points, ax=ax[2,col], **cbar_kwrgs);\n",
    "    cbar.ax.tick_params(labelsize=7)\n",
    "    \n",
    "add_ylabel(ax[0, 0], 'control', fontsize=9)\n",
    "add_ylabel(ax[1, 0], '2040s', fontsize=9)\n",
    "add_ylabel(ax[2, 0], '2080s', fontsize=9)\n",
    "    \n",
    "fig1.suptitle(f'{plot_case}-{scen}', fontsize=10, y=0.985);\n",
    "plt.savefig(os.path.join('NB3_figures', f'NB13_annual_map_{plot_case}_{scen}.png'), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_mean = df_huc12\n",
    "for var, _ in hruVar.items():\n",
    "    df_var = ds_ens_mean_annual['control'][var].to_dataframe()\n",
    "    df_ens_mean = df_ens_mean.merge(df_var,left_index=True, right_index=True)\n",
    "\n",
    "df_ens_mean_diff = AutoVivification()\n",
    "for period in periods.keys():\n",
    "    if period == 'control':\n",
    "        continue\n",
    "    df_ens_mean_diff[period] = df_huc12\n",
    "    for var, _ in hruVar.items():\n",
    "        df_var = ds_ens_mean_annual_change[period][var].to_dataframe()\n",
    "        df_ens_mean_diff[period] = df_ens_mean_diff[period].merge(df_var, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows=3; ncols=4\n",
    "fig1, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(8.5, 8.25))\n",
    "plt.subplots_adjust(left=0.0275, bottom=0.020, right=0.985, top=0.935, hspace=0.1, wspace=0.1)\n",
    "\n",
    "for col, (var, _) in enumerate(hruVar.items()):\n",
    "    df_ens_mean.plot(ax=ax[0, col], column=var, cmap=hruVar[var]['cm'], norm=mpl.colors.LogNorm(vmin=hruVar[var]['vmin'], vmax=hruVar[var]['vmax']), legend=False)\n",
    "    df_ens_mean_diff['2040s'].plot(ax=ax[1, col], column=var, cmap=hruVar_diff[var]['cm'], vmin=hruVar_diff[var]['vmin'], vmax=hruVar_diff[var]['vmax'], legend=False)\n",
    "    df_ens_mean_diff['2080s'].plot(ax=ax[2, col], column=var, cmap=hruVar_diff[var]['cm'], vmin=hruVar_diff[var]['vmin'], vmax=hruVar_diff[var]['vmax'], legend=False)\n",
    "\n",
    "    ax[0,col].set_xticks([])\n",
    "    ax[0,col].set_yticks([])\n",
    "    ax[0,col].set_title('%s [%s]'%(hruVar[var]['name'], hruVar[var]['unit']), fontsize=9);\n",
    "    ax[1,col].set_title('%s change [%s]'%(hruVar_diff[var]['name'], hruVar_diff[var]['unit']), fontsize=9);\n",
    "\n",
    "    points = ax[0,col].collections[-1]\n",
    "    cbar = plt.colorbar(points, ax=ax[0,col], **cbar_kwrgs);\n",
    "    cbar.ax.tick_params(labelsize=7)\n",
    "    \n",
    "    points = ax[1,col].collections[-1]\n",
    "    cbar = plt.colorbar(points, ax=ax[1,col], **cbar_kwrgs);\n",
    "    cbar.ax.tick_params(labelsize=7)\n",
    "    \n",
    "    points = ax[2,col].collections[-1]\n",
    "    cbar = plt.colorbar(points, ax=ax[2,col], **cbar_kwrgs);\n",
    "    cbar.ax.tick_params(labelsize=7)\n",
    "    \n",
    "add_ylabel(ax[0, 0], 'control', fontsize=9)\n",
    "add_ylabel(ax[1, 0], 'WY2030-2060', fontsize=9)\n",
    "add_ylabel(ax[2, 0], 'WY2070-2099', fontsize=9)\n",
    "    \n",
    "fig1.suptitle(f'{ensemble_name}', fontsize=10, y=0.985);\n",
    "plt.savefig(os.path.join('NB3_figures', f'Fig2_annual_map_{ensemble_name}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basin analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin = 'LIB'   # e.g., 'KAC', 'DWR', 'FAL', 'HGH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_plot_list = ['prec','scalarTotalRunoff_mean', 'scalarTotalET_mean','scalarSWE','runoff_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read shapefiles and extract hrus within a basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_area  = df_site['area_sqkm'][basin]*1000000 #sq-meter\n",
    "print('----- read regional huc12 gpkg')\n",
    "\n",
    "ds_monthly_region        = AutoVivification()\n",
    "ds_seasonal_month_region = AutoVivification()\n",
    "\n",
    "for case, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        ds_monthly_region[case][scen] = ds_summa_basin[case][scen].sel(site=basin, drop=True).load()\n",
    "        for period in scens[scen]['period']:\n",
    "            ds_seasonal_month_region[case][scen][period] = ds_monthly_region[case][scen].sel(time=periods[period]['time']).groupby(\"time.season\").mean(dim=\"time\")\n",
    "    print(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mean = AutoVivification()\n",
    "\n",
    "for period, period_meta in periods.items():     \n",
    "    count=0 \n",
    "    for case, _ in gcm_runs.items():\n",
    "        if period=='control':\n",
    "            scen_list=['hist']\n",
    "        else:\n",
    "            scen_list=list(ds_monthly_region[case].keys())\n",
    "            scen_list.remove('hist')\n",
    "        for scen in scen_list: \n",
    "            ds_tmp = ds_monthly_region[case][scen].sel(time=periods[period]['time']).mean()\n",
    "            ds_tmp['runoff_ratio'] = ds_tmp['scalarTotalRunoff_mean']/ds_tmp['prec']\n",
    "            \n",
    "            for ix, var in enumerate(var_plot_list):\n",
    "                if var not in ['scalarSWE', 'runoff_ratio']:\n",
    "                    ds_tmp[var] = ds_tmp[var]*12\n",
    "            \n",
    "            for var in var_plot_list:\n",
    "                if count==0:\n",
    "                    var_mean[period][var] = ds_tmp[var].values\n",
    "                else:\n",
    "                    var_mean[period][var] = var_mean[period][var]+ ds_tmp[var].values\n",
    "            count+=1\n",
    "    \n",
    "    for var in var_plot_list:\n",
    "        var_mean[period][var] = var_mean[period][var]/count\n",
    "        \n",
    "for period, _ in periods.items():\n",
    "    print('%s'%period)\n",
    "    for var in var_plot_list:\n",
    "        print('%s %.2f'%(var, var_mean[period][var]))\n",
    "\n",
    "df = pd.DataFrame({'date':pd.date_range(start='1980-01-01',end='2098-01-01',freq='YS-JAN'),\n",
    "                   'precp':np.nan, 'scalarTotalRunoff_mean':np.nan, 'scalarTotalET_mean':np.nan, 'scalarSWE':np.nan, 'runoff_ratio':np.nan})\n",
    "df['date'] = df['date'].apply(pd.Timestamp)\n",
    "df = df.set_index('date')\n",
    "\n",
    "for period in ['control','2040s','2080s']:\n",
    "    date_selected = pd.date_range(start=periods[period]['time'].start,end=periods[period]['time'].stop,freq='YS-JAN')\n",
    "    m2 = df.index.isin(date_selected)\n",
    "    for var in df.columns:\n",
    "        df.loc[m2, var] = var_mean[period][var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var = ['scalarTotalRunoff_mean','scalarTotalET_mean','scalarSWE', 'runoff_ratio']\n",
    "\n",
    "mpl.rcParams['axes.labelsize'] = 9 \n",
    "mpl.rcParams['xtick.labelsize'] = 7 \n",
    "mpl.rcParams['ytick.labelsize'] = 7 \n",
    "mpl.rcParams['ytick.labelsize'] = 7 \n",
    "\n",
    "fig1, ax = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(6.5, 6.0), dpi=150)\n",
    "\n",
    "slope_list = {key: [] for key in plot_var}\n",
    "intsect_list = {key: [] for key in plot_var}\n",
    "\n",
    "for case, meta in gcm_runs.items():\n",
    "    for scen in meta['scen']:\n",
    "        if scen=='hist':\n",
    "            c='xkcd:gray'; lw=0.15            \n",
    "        elif scen=='ssp245' or scen=='rcp45':\n",
    "            c='#005AB5'; lw=0.15\n",
    "        elif scen=='ssp370':\n",
    "            continue\n",
    "            c='xkcd:green'; lw=0.15\n",
    "        elif scen=='ssp585' or scen=='rcp85':\n",
    "            c='#DC3220'; lw=0.15         \n",
    "            \n",
    "        if scen == 'hist':\n",
    "            ds_ann = ds_monthly_region[case][scen].sel(time=slice('1980-01-01','2005-12-31')).resample(time=\"YS-JAN\").mean()\n",
    "            ds_ann['scalarSWE'] = ds_monthly_region[case][scen]['scalarSWE'].sel(time=slice('1980-01-01','2005-12-31')).resample(time=\"YS-JAN\").max()\n",
    "        else:\n",
    "            ds_ann = ds_monthly_region[case][scen].sel(time=slice('2005-01-01','2098-12-31')).resample(time=\"YS-JAN\").mean()\n",
    "            ds_ann['scalarSWE'] = ds_monthly_region[case][scen]['scalarSWE'].sel(time=slice('2005-01-01','2098-12-31')).resample(time=\"YS-JAN\").max()\n",
    "        ds_ann['runoff_ratio'] = ds_ann['scalarTotalRunoff_mean']/ds_ann['prec']\n",
    "        \n",
    "        for ix, var in enumerate(plot_var):\n",
    "            if var not in ['scalarSWE', 'runoff_ratio']:\n",
    "                ds_ann[var] = ds_ann[var]*12\n",
    "            ds_ann[var].plot(ax=ax[ix], c=c, lw=lw)\n",
    "            if scen=='hist':\n",
    "                continue\n",
    "            years = np.arange(len(ds_ann.time))\n",
    "            slope, intsect = np.polyfit(years, ds_ann[var].values, 1)\n",
    "            slope_list[var].append(slope)\n",
    "            intsect_list[var].append(intsect)\n",
    "            \n",
    "        ax[ix].set_xlim(pd.Timestamp('1979-01-01'), pd.Timestamp('2100-01-01'));\n",
    "\n",
    "for ix, var in enumerate(plot_var):\n",
    "    slope_ave =  np.sum(slope_list[var])/len(slope_list[var])\n",
    "    intsect_ave = np.sum(intsect_list[var])/len(intsect_list[var])\n",
    "    trend = xr.DataArray(\n",
    "        slope_ave * years + intsect_ave,\n",
    "        coords={\"time\": ds_ann.time},\n",
    "        dims=[\"time\"],\n",
    "    )\n",
    "    trend.plot(ax=ax[ix], lw=1, color='k', ls=':')\n",
    "        \n",
    "#for ix, var in enumerate(plot_var):\n",
    "#    df[var].plot(ax=ax[ix], c='xkcd:dark gray', ls='--', lw=1, legend=False, zorder=5)\n",
    "        \n",
    "ax[0].set_ylabel('total RO [mm]')\n",
    "ax[1].set_ylabel('total ET [mm]')\n",
    "ax[2].set_ylabel('SWE [mm]') #, fontsize='x-small'\n",
    "ax[3].set_ylabel('RO ratio [-]')\n",
    "\n",
    "ax[0].set_xlabel('');\n",
    "ax[1].set_xlabel('');\n",
    "ax[2].set_xlabel('');\n",
    "ax[3].set_xlabel('');\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('NB3_figures', f'Fig3_annual_series_{basin}.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
